{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model2lstm.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ajay7545/EEGClassification/blob/master/model2lstm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aof-LJk1kVGl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1uCyK0FpS5h",
        "colab_type": "code",
        "outputId": "df1d183d-0574-4e1f-97f9-0e880b3782ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "source": [
        "\n",
        "from random import shuffle\n",
        "\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import io\n",
        "import numpy as np\n",
        "import os\n",
        "import collections\n",
        "\n",
        "from tensor2tensor import models\n",
        "from tensor2tensor import problems\n",
        "from tensor2tensor.layers import common_layers\n",
        "from tensor2tensor.utils import trainer_lib\n",
        "from tensor2tensor.utils import t2t_model\n",
        "from tensor2tensor.utils import registry\n",
        "from tensor2tensor.utils import metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.python import keras\n",
        "from tensorflow.python.keras.models import Sequential, Model\n",
        "from tensorflow.python.keras.layers import Input, Dense, core,TimeDistributed,AveragePooling1D\n",
        "\n",
        "from tensorflow.python.keras.layers import LSTM, Dense, Dropout, Activation\n",
        "from sklearn.preprocessing import minmax_scale\n",
        "from sklearn import preprocessing\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from pandas import read_csv\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from numpy import delete\n",
        "from numpy import savetxt\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0626 11:52:23.926454 140609155762048 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/tensor2tensor/utils/expert_utils.py:68: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "W0626 11:52:24.995739 140609155762048 lazy_loader.py:50] \n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "W0626 11:52:26.871931 140609155762048 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/tensor2tensor/utils/adafactor.py:27: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0626 11:52:26.873590 140609155762048 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/tensor2tensor/utils/multistep_optimizer.py:32: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
            "\n",
            "W0626 11:52:27.041411 140609155762048 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/mesh_tensorflow/ops.py:4237: The name tf.train.CheckpointSaverListener is deprecated. Please use tf.estimator.CheckpointSaverListener instead.\n",
            "\n",
            "W0626 11:52:27.042807 140609155762048 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/mesh_tensorflow/ops.py:4260: The name tf.train.SessionRunHook is deprecated. Please use tf.estimator.SessionRunHook instead.\n",
            "\n",
            "W0626 11:52:27.120329 140609155762048 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/tensor2tensor/utils/trainer_lib.py:105: The name tf.OptimizerOptions is deprecated. Please use tf.compat.v1.OptimizerOptions instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2VWoKT-pZr7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TNThn6FpvLw",
        "colab_type": "code",
        "outputId": "1f8ed0b2-87b2-4c1b-df97-12a64024253c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df1.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14979, 15)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QtNSBpcAqdV1",
        "colab_type": "code",
        "outputId": "988b81ce-2865-41fa-8507-5d7fc676a8e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        }
      },
      "source": [
        "df=pd.read_csv('drive/My Drive/COLAB Files/EEG Eye State.csv')\n",
        "df.columns = ['A','B','C','D','E','F','G','H','I','J','K','L','M','N','O']\n",
        "df.head(2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>A</th>\n",
              "      <th>B</th>\n",
              "      <th>C</th>\n",
              "      <th>D</th>\n",
              "      <th>E</th>\n",
              "      <th>F</th>\n",
              "      <th>G</th>\n",
              "      <th>H</th>\n",
              "      <th>I</th>\n",
              "      <th>J</th>\n",
              "      <th>K</th>\n",
              "      <th>L</th>\n",
              "      <th>M</th>\n",
              "      <th>N</th>\n",
              "      <th>O</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4324.62</td>\n",
              "      <td>4004.62</td>\n",
              "      <td>4293.85</td>\n",
              "      <td>4148.72</td>\n",
              "      <td>4342.05</td>\n",
              "      <td>4586.67</td>\n",
              "      <td>4097.44</td>\n",
              "      <td>4638.97</td>\n",
              "      <td>4210.77</td>\n",
              "      <td>4226.67</td>\n",
              "      <td>4207.69</td>\n",
              "      <td>4279.49</td>\n",
              "      <td>4632.82</td>\n",
              "      <td>4384.10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4327.69</td>\n",
              "      <td>4006.67</td>\n",
              "      <td>4295.38</td>\n",
              "      <td>4156.41</td>\n",
              "      <td>4336.92</td>\n",
              "      <td>4583.59</td>\n",
              "      <td>4096.92</td>\n",
              "      <td>4630.26</td>\n",
              "      <td>4207.69</td>\n",
              "      <td>4222.05</td>\n",
              "      <td>4206.67</td>\n",
              "      <td>4282.05</td>\n",
              "      <td>4628.72</td>\n",
              "      <td>4389.23</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         A        B        C        D  ...        L        M        N  O\n",
              "0  4324.62  4004.62  4293.85  4148.72  ...  4279.49  4632.82  4384.10  0\n",
              "1  4327.69  4006.67  4295.38  4156.41  ...  4282.05  4628.72  4389.23  0\n",
              "\n",
              "[2 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blUKoJQprS5v",
        "colab_type": "code",
        "outputId": "2bd5cfcd-c391-4d04-9844-d38eaaf5e27d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14979, 15)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUZ3skFusfsw",
        "colab_type": "code",
        "outputId": "fa7abbf2-1360-4ffa-f8fd-8ff70a5d2b67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "y=df['O']\n",
        "print(len(y))\n",
        "print(y.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "14979\n",
            "(14979,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kAdzPlbosrR7",
        "colab_type": "code",
        "outputId": "70befebe-fa1e-4f1f-fc7a-b833247067f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "df.drop(['O'], axis = 1, inplace = True)\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>A</th>\n",
              "      <th>B</th>\n",
              "      <th>C</th>\n",
              "      <th>D</th>\n",
              "      <th>E</th>\n",
              "      <th>F</th>\n",
              "      <th>G</th>\n",
              "      <th>H</th>\n",
              "      <th>I</th>\n",
              "      <th>J</th>\n",
              "      <th>K</th>\n",
              "      <th>L</th>\n",
              "      <th>M</th>\n",
              "      <th>N</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4324.62</td>\n",
              "      <td>4004.62</td>\n",
              "      <td>4293.85</td>\n",
              "      <td>4148.72</td>\n",
              "      <td>4342.05</td>\n",
              "      <td>4586.67</td>\n",
              "      <td>4097.44</td>\n",
              "      <td>4638.97</td>\n",
              "      <td>4210.77</td>\n",
              "      <td>4226.67</td>\n",
              "      <td>4207.69</td>\n",
              "      <td>4279.49</td>\n",
              "      <td>4632.82</td>\n",
              "      <td>4384.10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4327.69</td>\n",
              "      <td>4006.67</td>\n",
              "      <td>4295.38</td>\n",
              "      <td>4156.41</td>\n",
              "      <td>4336.92</td>\n",
              "      <td>4583.59</td>\n",
              "      <td>4096.92</td>\n",
              "      <td>4630.26</td>\n",
              "      <td>4207.69</td>\n",
              "      <td>4222.05</td>\n",
              "      <td>4206.67</td>\n",
              "      <td>4282.05</td>\n",
              "      <td>4628.72</td>\n",
              "      <td>4389.23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4328.72</td>\n",
              "      <td>4011.79</td>\n",
              "      <td>4296.41</td>\n",
              "      <td>4155.90</td>\n",
              "      <td>4343.59</td>\n",
              "      <td>4582.56</td>\n",
              "      <td>4097.44</td>\n",
              "      <td>4630.77</td>\n",
              "      <td>4217.44</td>\n",
              "      <td>4235.38</td>\n",
              "      <td>4210.77</td>\n",
              "      <td>4287.69</td>\n",
              "      <td>4632.31</td>\n",
              "      <td>4396.41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4326.15</td>\n",
              "      <td>4011.79</td>\n",
              "      <td>4292.31</td>\n",
              "      <td>4151.28</td>\n",
              "      <td>4347.69</td>\n",
              "      <td>4586.67</td>\n",
              "      <td>4095.90</td>\n",
              "      <td>4627.69</td>\n",
              "      <td>4210.77</td>\n",
              "      <td>4244.10</td>\n",
              "      <td>4212.82</td>\n",
              "      <td>4288.21</td>\n",
              "      <td>4632.82</td>\n",
              "      <td>4398.46</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4321.03</td>\n",
              "      <td>4004.62</td>\n",
              "      <td>4284.10</td>\n",
              "      <td>4153.33</td>\n",
              "      <td>4345.64</td>\n",
              "      <td>4587.18</td>\n",
              "      <td>4093.33</td>\n",
              "      <td>4616.92</td>\n",
              "      <td>4202.56</td>\n",
              "      <td>4232.82</td>\n",
              "      <td>4209.74</td>\n",
              "      <td>4281.03</td>\n",
              "      <td>4628.21</td>\n",
              "      <td>4389.74</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         A        B        C        D  ...        K        L        M        N\n",
              "0  4324.62  4004.62  4293.85  4148.72  ...  4207.69  4279.49  4632.82  4384.10\n",
              "1  4327.69  4006.67  4295.38  4156.41  ...  4206.67  4282.05  4628.72  4389.23\n",
              "2  4328.72  4011.79  4296.41  4155.90  ...  4210.77  4287.69  4632.31  4396.41\n",
              "3  4326.15  4011.79  4292.31  4151.28  ...  4212.82  4288.21  4632.82  4398.46\n",
              "4  4321.03  4004.62  4284.10  4153.33  ...  4209.74  4281.03  4628.21  4389.74\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_h4KfOC0tBur",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#inputs = datalist[:, :-1]\n",
        "#output = datalist[:, -1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s44qKilqtxGm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_runs = 10\n",
        "num_runs = num_runs + 1\n",
        "\n",
        "train_loss_list = []\n",
        "train_accuracy_list = []\n",
        "\n",
        "val_loss_list = []\n",
        "val_accuracy_list = []\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQ8bEUXYvPaB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGSWkRumtxKj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmyJlLOMtxYN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKeWhot4txbN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Train_inputs, Test_inputs, train_output, test_output = train_test_split(df,y, test_size=0.20, shuffle=True, random_state=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UghiA9YvtxFV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "std_scale = preprocessing.StandardScaler().fit(Train_inputs)\n",
        "train_inputs = std_scale.transform(Train_inputs)\n",
        "test_inputs = std_scale.transform(Test_inputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a94hdCyYv6VN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "trintf=np.asarray(train_inputs)\n",
        "trouttf=np.asarray(train_output)\n",
        "tsintf=np.asarray(test_inputs)\n",
        "tsouttf=np.asarray(test_output)\n",
        "\n",
        "#train_inputs_tf = tf.convert_to_tensor(train_inputs, np.float32)\n",
        "#train_output_tf = tf.convert_to_tensor(train_output, np.float32)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pd5wzqQtyx37",
        "colab_type": "code",
        "outputId": "1f6908a2-3ce6-44cd-a833-9b5e58788033",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(trintf.shape)\n",
        "print(11983*14)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(11983, 14)\n",
            "167762\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLHPy3bLyx0h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6AVrFdn0yxy0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0lk3qO8Rv6Y-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "trintf=trintf.reshape(11983,1,14)\n",
        "trouttf=trouttf.reshape(11983,1,1)\n",
        "tsintf=tsintf.reshape(2996,1,14)\n",
        "tsouttf=tsouttf.reshape(2996,1,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4yEv0tuAv6by",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 1\n",
        "training_split = 0.25\n",
        "num_fields = 14"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMWJ_L3SzSqJ",
        "colab_type": "code",
        "outputId": "4770f8f1-2815-41b9-a17c-55a0bb900487",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(100,return_sequences=True,implementation=2))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(LSTM(100,return_sequences=True,implementation=2))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='mean_squared_error', optimizer='rmsprop', metrics=['accuracy'])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0626 11:53:02.094851 140609155762048 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYc2C0uBzStI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ObrEK8-Kv6TA",
        "colab_type": "code",
        "outputId": "3e8b1448-0a5e-439b-890a-1f5cf9fb1f88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = model.fit(trintf, trouttf, epochs=700, batch_size= 128,verbose=1,validation_data=(tsintf, tsouttf))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 11983 samples, validate on 2996 samples\n",
            "Epoch 1/700\n",
            "11983/11983 [==============================] - 2s 164us/sample - loss: 0.0967 - acc: 0.8686 - val_loss: 0.0872 - val_acc: 0.8858\n",
            "Epoch 2/700\n",
            "11983/11983 [==============================] - 2s 171us/sample - loss: 0.0968 - acc: 0.8692 - val_loss: 0.0869 - val_acc: 0.8845\n",
            "Epoch 3/700\n",
            "11983/11983 [==============================] - 2s 159us/sample - loss: 0.0963 - acc: 0.8691 - val_loss: 0.0866 - val_acc: 0.8858\n",
            "Epoch 4/700\n",
            "11983/11983 [==============================] - 2s 162us/sample - loss: 0.0950 - acc: 0.8690 - val_loss: 0.0863 - val_acc: 0.8818\n",
            "Epoch 5/700\n",
            "11983/11983 [==============================] - 2s 166us/sample - loss: 0.0963 - acc: 0.8678 - val_loss: 0.0854 - val_acc: 0.8855\n",
            "Epoch 6/700\n",
            "11983/11983 [==============================] - 2s 171us/sample - loss: 0.0951 - acc: 0.8707 - val_loss: 0.0853 - val_acc: 0.8875\n",
            "Epoch 7/700\n",
            "11983/11983 [==============================] - 2s 166us/sample - loss: 0.0940 - acc: 0.8716 - val_loss: 0.0846 - val_acc: 0.8902\n",
            "Epoch 8/700\n",
            "11983/11983 [==============================] - 2s 166us/sample - loss: 0.0943 - acc: 0.8712 - val_loss: 0.0842 - val_acc: 0.8875\n",
            "Epoch 9/700\n",
            "11983/11983 [==============================] - 2s 171us/sample - loss: 0.0943 - acc: 0.8707 - val_loss: 0.0842 - val_acc: 0.8845\n",
            "Epoch 10/700\n",
            "11983/11983 [==============================] - 2s 180us/sample - loss: 0.0933 - acc: 0.8757 - val_loss: 0.0829 - val_acc: 0.8905\n",
            "Epoch 11/700\n",
            "11983/11983 [==============================] - 2s 176us/sample - loss: 0.0941 - acc: 0.8724 - val_loss: 0.0829 - val_acc: 0.8929\n",
            "Epoch 12/700\n",
            "11983/11983 [==============================] - 2s 169us/sample - loss: 0.0928 - acc: 0.8725 - val_loss: 0.0829 - val_acc: 0.8922\n",
            "Epoch 13/700\n",
            "11983/11983 [==============================] - 2s 170us/sample - loss: 0.0922 - acc: 0.8768 - val_loss: 0.0830 - val_acc: 0.8922\n",
            "Epoch 14/700\n",
            "11983/11983 [==============================] - 2s 159us/sample - loss: 0.0917 - acc: 0.8767 - val_loss: 0.0824 - val_acc: 0.8912\n",
            "Epoch 15/700\n",
            "11983/11983 [==============================] - 2s 164us/sample - loss: 0.0925 - acc: 0.8716 - val_loss: 0.0819 - val_acc: 0.8919\n",
            "Epoch 16/700\n",
            "11983/11983 [==============================] - 2s 170us/sample - loss: 0.0907 - acc: 0.8777 - val_loss: 0.0815 - val_acc: 0.8912\n",
            "Epoch 17/700\n",
            "11983/11983 [==============================] - 2s 162us/sample - loss: 0.0894 - acc: 0.8798 - val_loss: 0.0812 - val_acc: 0.8939\n",
            "Epoch 18/700\n",
            "11983/11983 [==============================] - 2s 162us/sample - loss: 0.0898 - acc: 0.8795 - val_loss: 0.0804 - val_acc: 0.8942\n",
            "Epoch 19/700\n",
            "11983/11983 [==============================] - 2s 174us/sample - loss: 0.0908 - acc: 0.8757 - val_loss: 0.0808 - val_acc: 0.8915\n",
            "Epoch 20/700\n",
            "11983/11983 [==============================] - 2s 172us/sample - loss: 0.0889 - acc: 0.8799 - val_loss: 0.0799 - val_acc: 0.8952\n",
            "Epoch 21/700\n",
            "11983/11983 [==============================] - 2s 171us/sample - loss: 0.0886 - acc: 0.8787 - val_loss: 0.0805 - val_acc: 0.8922\n",
            "Epoch 22/700\n",
            "11983/11983 [==============================] - 2s 169us/sample - loss: 0.0898 - acc: 0.8780 - val_loss: 0.0798 - val_acc: 0.8975\n",
            "Epoch 23/700\n",
            "11983/11983 [==============================] - 2s 183us/sample - loss: 0.0884 - acc: 0.8791 - val_loss: 0.0791 - val_acc: 0.8985\n",
            "Epoch 24/700\n",
            "11983/11983 [==============================] - 2s 178us/sample - loss: 0.0891 - acc: 0.8797 - val_loss: 0.0791 - val_acc: 0.8959\n",
            "Epoch 25/700\n",
            "11983/11983 [==============================] - 2s 172us/sample - loss: 0.0881 - acc: 0.8817 - val_loss: 0.0791 - val_acc: 0.8962\n",
            "Epoch 26/700\n",
            "11983/11983 [==============================] - 2s 158us/sample - loss: 0.0874 - acc: 0.8794 - val_loss: 0.0782 - val_acc: 0.8992\n",
            "Epoch 27/700\n",
            "11983/11983 [==============================] - 2s 172us/sample - loss: 0.0879 - acc: 0.8810 - val_loss: 0.0780 - val_acc: 0.8995\n",
            "Epoch 28/700\n",
            "11983/11983 [==============================] - 2s 189us/sample - loss: 0.0862 - acc: 0.8835 - val_loss: 0.0783 - val_acc: 0.8965\n",
            "Epoch 29/700\n",
            "11983/11983 [==============================] - 2s 175us/sample - loss: 0.0859 - acc: 0.8866 - val_loss: 0.0776 - val_acc: 0.8985\n",
            "Epoch 30/700\n",
            "11983/11983 [==============================] - 2s 172us/sample - loss: 0.0856 - acc: 0.8847 - val_loss: 0.0780 - val_acc: 0.8952\n",
            "Epoch 31/700\n",
            "11983/11983 [==============================] - 2s 174us/sample - loss: 0.0855 - acc: 0.8839 - val_loss: 0.0770 - val_acc: 0.9002\n",
            "Epoch 32/700\n",
            "11983/11983 [==============================] - 2s 169us/sample - loss: 0.0876 - acc: 0.8836 - val_loss: 0.0765 - val_acc: 0.8989\n",
            "Epoch 33/700\n",
            "11983/11983 [==============================] - 2s 175us/sample - loss: 0.0843 - acc: 0.8865 - val_loss: 0.0765 - val_acc: 0.9019\n",
            "Epoch 34/700\n",
            "11983/11983 [==============================] - 2s 178us/sample - loss: 0.0867 - acc: 0.8847 - val_loss: 0.0763 - val_acc: 0.9002\n",
            "Epoch 35/700\n",
            "11983/11983 [==============================] - 2s 163us/sample - loss: 0.0850 - acc: 0.8853 - val_loss: 0.0762 - val_acc: 0.9005\n",
            "Epoch 36/700\n",
            "11983/11983 [==============================] - 2s 164us/sample - loss: 0.0862 - acc: 0.8828 - val_loss: 0.0763 - val_acc: 0.8965\n",
            "Epoch 37/700\n",
            "11983/11983 [==============================] - 2s 164us/sample - loss: 0.0844 - acc: 0.8865 - val_loss: 0.0760 - val_acc: 0.8989\n",
            "Epoch 38/700\n",
            "11983/11983 [==============================] - 2s 177us/sample - loss: 0.0860 - acc: 0.8819 - val_loss: 0.0752 - val_acc: 0.8999\n",
            "Epoch 39/700\n",
            "11983/11983 [==============================] - 2s 178us/sample - loss: 0.0849 - acc: 0.8853 - val_loss: 0.0748 - val_acc: 0.8995\n",
            "Epoch 40/700\n",
            "11983/11983 [==============================] - 2s 169us/sample - loss: 0.0849 - acc: 0.8876 - val_loss: 0.0752 - val_acc: 0.9015\n",
            "Epoch 41/700\n",
            "11983/11983 [==============================] - 2s 170us/sample - loss: 0.0829 - acc: 0.8887 - val_loss: 0.0745 - val_acc: 0.9032\n",
            "Epoch 42/700\n",
            "11983/11983 [==============================] - 2s 171us/sample - loss: 0.0848 - acc: 0.8842 - val_loss: 0.0745 - val_acc: 0.9009\n",
            "Epoch 43/700\n",
            "11983/11983 [==============================] - 2s 160us/sample - loss: 0.0833 - acc: 0.8857 - val_loss: 0.0741 - val_acc: 0.9022\n",
            "Epoch 44/700\n",
            "11983/11983 [==============================] - 2s 176us/sample - loss: 0.0820 - acc: 0.8874 - val_loss: 0.0737 - val_acc: 0.9035\n",
            "Epoch 45/700\n",
            "11983/11983 [==============================] - 2s 172us/sample - loss: 0.0839 - acc: 0.8882 - val_loss: 0.0744 - val_acc: 0.8999\n",
            "Epoch 46/700\n",
            "11983/11983 [==============================] - 2s 169us/sample - loss: 0.0835 - acc: 0.8875 - val_loss: 0.0733 - val_acc: 0.9032\n",
            "Epoch 47/700\n",
            "11983/11983 [==============================] - 2s 162us/sample - loss: 0.0814 - acc: 0.8933 - val_loss: 0.0734 - val_acc: 0.9055\n",
            "Epoch 48/700\n",
            "11983/11983 [==============================] - 2s 173us/sample - loss: 0.0818 - acc: 0.8878 - val_loss: 0.0726 - val_acc: 0.9045\n",
            "Epoch 49/700\n",
            "11983/11983 [==============================] - 2s 177us/sample - loss: 0.0826 - acc: 0.8896 - val_loss: 0.0729 - val_acc: 0.9049\n",
            "Epoch 50/700\n",
            "11983/11983 [==============================] - 2s 168us/sample - loss: 0.0810 - acc: 0.8918 - val_loss: 0.0727 - val_acc: 0.9039\n",
            "Epoch 51/700\n",
            "11983/11983 [==============================] - 2s 175us/sample - loss: 0.0817 - acc: 0.8887 - val_loss: 0.0723 - val_acc: 0.9035\n",
            "Epoch 52/700\n",
            "11983/11983 [==============================] - 2s 175us/sample - loss: 0.0793 - acc: 0.8959 - val_loss: 0.0719 - val_acc: 0.9049\n",
            "Epoch 53/700\n",
            "11983/11983 [==============================] - 2s 173us/sample - loss: 0.0807 - acc: 0.8913 - val_loss: 0.0715 - val_acc: 0.9075\n",
            "Epoch 54/700\n",
            "11983/11983 [==============================] - 2s 162us/sample - loss: 0.0819 - acc: 0.8898 - val_loss: 0.0716 - val_acc: 0.9035\n",
            "Epoch 55/700\n",
            "11983/11983 [==============================] - 2s 166us/sample - loss: 0.0795 - acc: 0.8929 - val_loss: 0.0717 - val_acc: 0.9022\n",
            "Epoch 56/700\n",
            "11983/11983 [==============================] - 2s 160us/sample - loss: 0.0808 - acc: 0.8909 - val_loss: 0.0711 - val_acc: 0.9049\n",
            "Epoch 57/700\n",
            "11983/11983 [==============================] - 2s 167us/sample - loss: 0.0807 - acc: 0.8920 - val_loss: 0.0711 - val_acc: 0.9059\n",
            "Epoch 58/700\n",
            "11983/11983 [==============================] - 2s 161us/sample - loss: 0.0806 - acc: 0.8928 - val_loss: 0.0708 - val_acc: 0.9052\n",
            "Epoch 59/700\n",
            "11983/11983 [==============================] - 2s 159us/sample - loss: 0.0790 - acc: 0.8959 - val_loss: 0.0702 - val_acc: 0.9062\n",
            "Epoch 60/700\n",
            "11983/11983 [==============================] - 2s 162us/sample - loss: 0.0788 - acc: 0.8944 - val_loss: 0.0703 - val_acc: 0.9052\n",
            "Epoch 61/700\n",
            "11983/11983 [==============================] - 2s 171us/sample - loss: 0.0809 - acc: 0.8889 - val_loss: 0.0706 - val_acc: 0.9055\n",
            "Epoch 62/700\n",
            "11983/11983 [==============================] - 2s 166us/sample - loss: 0.0797 - acc: 0.8928 - val_loss: 0.0703 - val_acc: 0.9049\n",
            "Epoch 63/700\n",
            "11983/11983 [==============================] - 2s 172us/sample - loss: 0.0786 - acc: 0.8934 - val_loss: 0.0709 - val_acc: 0.9065\n",
            "Epoch 64/700\n",
            "11983/11983 [==============================] - 2s 169us/sample - loss: 0.0782 - acc: 0.8957 - val_loss: 0.0699 - val_acc: 0.9092\n",
            "Epoch 65/700\n",
            "11983/11983 [==============================] - 2s 171us/sample - loss: 0.0786 - acc: 0.8956 - val_loss: 0.0698 - val_acc: 0.9085\n",
            "Epoch 66/700\n",
            "11983/11983 [==============================] - 2s 172us/sample - loss: 0.0775 - acc: 0.8980 - val_loss: 0.0700 - val_acc: 0.9072\n",
            "Epoch 67/700\n",
            "11983/11983 [==============================] - 2s 170us/sample - loss: 0.0761 - acc: 0.8979 - val_loss: 0.0695 - val_acc: 0.9085\n",
            "Epoch 68/700\n",
            "11983/11983 [==============================] - 2s 170us/sample - loss: 0.0789 - acc: 0.8938 - val_loss: 0.0688 - val_acc: 0.9089\n",
            "Epoch 69/700\n",
            "11983/11983 [==============================] - 2s 175us/sample - loss: 0.0777 - acc: 0.8969 - val_loss: 0.0690 - val_acc: 0.9109\n",
            "Epoch 70/700\n",
            "11983/11983 [==============================] - 2s 168us/sample - loss: 0.0776 - acc: 0.8959 - val_loss: 0.0687 - val_acc: 0.9122\n",
            "Epoch 71/700\n",
            "11983/11983 [==============================] - 2s 164us/sample - loss: 0.0777 - acc: 0.8961 - val_loss: 0.0691 - val_acc: 0.9082\n",
            "Epoch 72/700\n",
            "11983/11983 [==============================] - 2s 166us/sample - loss: 0.0773 - acc: 0.8983 - val_loss: 0.0695 - val_acc: 0.9072\n",
            "Epoch 73/700\n",
            "11983/11983 [==============================] - 2s 162us/sample - loss: 0.0772 - acc: 0.8969 - val_loss: 0.0685 - val_acc: 0.9089\n",
            "Epoch 74/700\n",
            "11983/11983 [==============================] - 2s 163us/sample - loss: 0.0763 - acc: 0.8984 - val_loss: 0.0692 - val_acc: 0.9079\n",
            "Epoch 75/700\n",
            "11983/11983 [==============================] - 2s 170us/sample - loss: 0.0764 - acc: 0.8978 - val_loss: 0.0696 - val_acc: 0.9055\n",
            "Epoch 76/700\n",
            "11983/11983 [==============================] - 2s 177us/sample - loss: 0.0774 - acc: 0.8956 - val_loss: 0.0676 - val_acc: 0.9085\n",
            "Epoch 77/700\n",
            "11983/11983 [==============================] - 2s 173us/sample - loss: 0.0749 - acc: 0.8993 - val_loss: 0.0677 - val_acc: 0.9099\n",
            "Epoch 78/700\n",
            "11983/11983 [==============================] - 2s 183us/sample - loss: 0.0758 - acc: 0.8993 - val_loss: 0.0673 - val_acc: 0.9085\n",
            "Epoch 79/700\n",
            "11983/11983 [==============================] - 2s 184us/sample - loss: 0.0748 - acc: 0.9005 - val_loss: 0.0673 - val_acc: 0.9105\n",
            "Epoch 80/700\n",
            "11983/11983 [==============================] - 2s 169us/sample - loss: 0.0751 - acc: 0.9009 - val_loss: 0.0677 - val_acc: 0.9052\n",
            "Epoch 81/700\n",
            "11983/11983 [==============================] - 2s 175us/sample - loss: 0.0746 - acc: 0.9019 - val_loss: 0.0671 - val_acc: 0.9112\n",
            "Epoch 82/700\n",
            "11983/11983 [==============================] - 2s 170us/sample - loss: 0.0753 - acc: 0.8989 - val_loss: 0.0669 - val_acc: 0.9102\n",
            "Epoch 83/700\n",
            "11983/11983 [==============================] - 2s 165us/sample - loss: 0.0737 - acc: 0.9018 - val_loss: 0.0679 - val_acc: 0.9079\n",
            "Epoch 84/700\n",
            "11983/11983 [==============================] - 2s 171us/sample - loss: 0.0755 - acc: 0.8999 - val_loss: 0.0672 - val_acc: 0.9102\n",
            "Epoch 85/700\n",
            "11983/11983 [==============================] - 2s 167us/sample - loss: 0.0748 - acc: 0.9010 - val_loss: 0.0668 - val_acc: 0.9102\n",
            "Epoch 86/700\n",
            "11983/11983 [==============================] - 2s 162us/sample - loss: 0.0749 - acc: 0.8994 - val_loss: 0.0660 - val_acc: 0.9132\n",
            "Epoch 87/700\n",
            "11983/11983 [==============================] - 2s 178us/sample - loss: 0.0745 - acc: 0.8986 - val_loss: 0.0668 - val_acc: 0.9099\n",
            "Epoch 88/700\n",
            "11983/11983 [==============================] - 2s 171us/sample - loss: 0.0732 - acc: 0.9003 - val_loss: 0.0659 - val_acc: 0.9126\n",
            "Epoch 89/700\n",
            "11983/11983 [==============================] - 2s 169us/sample - loss: 0.0734 - acc: 0.9010 - val_loss: 0.0653 - val_acc: 0.9112\n",
            "Epoch 90/700\n",
            "11983/11983 [==============================] - 2s 175us/sample - loss: 0.0729 - acc: 0.9024 - val_loss: 0.0662 - val_acc: 0.9132\n",
            "Epoch 91/700\n",
            "11983/11983 [==============================] - 2s 163us/sample - loss: 0.0735 - acc: 0.9007 - val_loss: 0.0653 - val_acc: 0.9129\n",
            "Epoch 92/700\n",
            "11983/11983 [==============================] - 2s 161us/sample - loss: 0.0736 - acc: 0.9009 - val_loss: 0.0655 - val_acc: 0.9112\n",
            "Epoch 93/700\n",
            "11983/11983 [==============================] - 2s 165us/sample - loss: 0.0745 - acc: 0.9014 - val_loss: 0.0664 - val_acc: 0.9099\n",
            "Epoch 94/700\n",
            "11983/11983 [==============================] - 2s 171us/sample - loss: 0.0740 - acc: 0.9021 - val_loss: 0.0655 - val_acc: 0.9126\n",
            "Epoch 95/700\n",
            "11983/11983 [==============================] - 2s 181us/sample - loss: 0.0721 - acc: 0.9026 - val_loss: 0.0652 - val_acc: 0.9126\n",
            "Epoch 96/700\n",
            "11983/11983 [==============================] - 2s 177us/sample - loss: 0.0720 - acc: 0.9043 - val_loss: 0.0641 - val_acc: 0.9142\n",
            "Epoch 97/700\n",
            "11983/11983 [==============================] - 2s 171us/sample - loss: 0.0705 - acc: 0.9048 - val_loss: 0.0644 - val_acc: 0.9129\n",
            "Epoch 98/700\n",
            "11983/11983 [==============================] - 2s 170us/sample - loss: 0.0735 - acc: 0.9008 - val_loss: 0.0641 - val_acc: 0.9146\n",
            "Epoch 99/700\n",
            "11983/11983 [==============================] - 2s 166us/sample - loss: 0.0729 - acc: 0.9019 - val_loss: 0.0645 - val_acc: 0.9139\n",
            "Epoch 100/700\n",
            "11983/11983 [==============================] - 2s 171us/sample - loss: 0.0706 - acc: 0.9079 - val_loss: 0.0652 - val_acc: 0.9102\n",
            "Epoch 101/700\n",
            "11983/11983 [==============================] - 2s 165us/sample - loss: 0.0705 - acc: 0.9043 - val_loss: 0.0643 - val_acc: 0.9112\n",
            "Epoch 102/700\n",
            "11983/11983 [==============================] - 2s 161us/sample - loss: 0.0725 - acc: 0.9025 - val_loss: 0.0639 - val_acc: 0.9142\n",
            "Epoch 103/700\n",
            "11983/11983 [==============================] - 2s 169us/sample - loss: 0.0709 - acc: 0.9042 - val_loss: 0.0633 - val_acc: 0.9162\n",
            "Epoch 104/700\n",
            "11983/11983 [==============================] - 2s 177us/sample - loss: 0.0723 - acc: 0.9029 - val_loss: 0.0631 - val_acc: 0.9169\n",
            "Epoch 105/700\n",
            "11983/11983 [==============================] - 2s 165us/sample - loss: 0.0721 - acc: 0.9029 - val_loss: 0.0639 - val_acc: 0.9115\n",
            "Epoch 106/700\n",
            "11983/11983 [==============================] - 2s 175us/sample - loss: 0.0717 - acc: 0.9032 - val_loss: 0.0636 - val_acc: 0.9152\n",
            "Epoch 107/700\n",
            "11983/11983 [==============================] - 2s 162us/sample - loss: 0.0719 - acc: 0.9041 - val_loss: 0.0636 - val_acc: 0.9119\n",
            "Epoch 108/700\n",
            "11983/11983 [==============================] - 2s 168us/sample - loss: 0.0709 - acc: 0.9051 - val_loss: 0.0631 - val_acc: 0.9136\n",
            "Epoch 109/700\n",
            "11983/11983 [==============================] - 2s 159us/sample - loss: 0.0697 - acc: 0.9074 - val_loss: 0.0625 - val_acc: 0.9169\n",
            "Epoch 110/700\n",
            "11983/11983 [==============================] - 2s 163us/sample - loss: 0.0711 - acc: 0.9046 - val_loss: 0.0636 - val_acc: 0.9149\n",
            "Epoch 111/700\n",
            "11983/11983 [==============================] - 2s 174us/sample - loss: 0.0711 - acc: 0.9060 - val_loss: 0.0627 - val_acc: 0.9142\n",
            "Epoch 112/700\n",
            "11983/11983 [==============================] - 2s 180us/sample - loss: 0.0708 - acc: 0.9051 - val_loss: 0.0621 - val_acc: 0.9172\n",
            "Epoch 113/700\n",
            "11983/11983 [==============================] - 2s 174us/sample - loss: 0.0705 - acc: 0.9047 - val_loss: 0.0621 - val_acc: 0.9172\n",
            "Epoch 114/700\n",
            "11983/11983 [==============================] - 2s 170us/sample - loss: 0.0709 - acc: 0.9018 - val_loss: 0.0630 - val_acc: 0.9162\n",
            "Epoch 115/700\n",
            "11983/11983 [==============================] - 2s 162us/sample - loss: 0.0694 - acc: 0.9058 - val_loss: 0.0621 - val_acc: 0.9162\n",
            "Epoch 116/700\n",
            "11983/11983 [==============================] - 2s 171us/sample - loss: 0.0700 - acc: 0.9063 - val_loss: 0.0619 - val_acc: 0.9179\n",
            "Epoch 117/700\n",
            "11983/11983 [==============================] - 2s 163us/sample - loss: 0.0701 - acc: 0.9056 - val_loss: 0.0625 - val_acc: 0.9122\n",
            "Epoch 118/700\n",
            "11983/11983 [==============================] - 2s 175us/sample - loss: 0.0689 - acc: 0.9075 - val_loss: 0.0617 - val_acc: 0.9146\n",
            "Epoch 119/700\n",
            "11983/11983 [==============================] - 2s 178us/sample - loss: 0.0694 - acc: 0.9075 - val_loss: 0.0622 - val_acc: 0.9132\n",
            "Epoch 120/700\n",
            "11983/11983 [==============================] - 2s 170us/sample - loss: 0.0695 - acc: 0.9078 - val_loss: 0.0613 - val_acc: 0.9115\n",
            "Epoch 121/700\n",
            "11983/11983 [==============================] - 2s 175us/sample - loss: 0.0697 - acc: 0.9065 - val_loss: 0.0615 - val_acc: 0.9122\n",
            "Epoch 122/700\n",
            "11983/11983 [==============================] - 2s 168us/sample - loss: 0.0694 - acc: 0.9090 - val_loss: 0.0617 - val_acc: 0.9136\n",
            "Epoch 123/700\n",
            "11983/11983 [==============================] - 2s 174us/sample - loss: 0.0692 - acc: 0.9078 - val_loss: 0.0612 - val_acc: 0.9162\n",
            "Epoch 124/700\n",
            "11983/11983 [==============================] - 2s 165us/sample - loss: 0.0680 - acc: 0.9107 - val_loss: 0.0616 - val_acc: 0.9166\n",
            "Epoch 125/700\n",
            "11983/11983 [==============================] - 2s 171us/sample - loss: 0.0676 - acc: 0.9114 - val_loss: 0.0612 - val_acc: 0.9166\n",
            "Epoch 126/700\n",
            "11983/11983 [==============================] - 2s 176us/sample - loss: 0.0675 - acc: 0.9111 - val_loss: 0.0613 - val_acc: 0.9152\n",
            "Epoch 127/700\n",
            "11983/11983 [==============================] - 2s 168us/sample - loss: 0.0679 - acc: 0.9095 - val_loss: 0.0604 - val_acc: 0.9166\n",
            "Epoch 128/700\n",
            "11983/11983 [==============================] - 2s 171us/sample - loss: 0.0676 - acc: 0.9098 - val_loss: 0.0617 - val_acc: 0.9166\n",
            "Epoch 129/700\n",
            "11983/11983 [==============================] - 2s 174us/sample - loss: 0.0689 - acc: 0.9081 - val_loss: 0.0598 - val_acc: 0.9176\n",
            "Epoch 130/700\n",
            "11983/11983 [==============================] - 2s 186us/sample - loss: 0.0676 - acc: 0.9081 - val_loss: 0.0600 - val_acc: 0.9149\n",
            "Epoch 131/700\n",
            "11983/11983 [==============================] - 2s 176us/sample - loss: 0.0647 - acc: 0.9141 - val_loss: 0.0610 - val_acc: 0.9149\n",
            "Epoch 132/700\n",
            "11983/11983 [==============================] - 2s 174us/sample - loss: 0.0687 - acc: 0.9060 - val_loss: 0.0613 - val_acc: 0.9149\n",
            "Epoch 133/700\n",
            "11983/11983 [==============================] - 2s 165us/sample - loss: 0.0677 - acc: 0.9097 - val_loss: 0.0595 - val_acc: 0.9209\n",
            "Epoch 134/700\n",
            "11983/11983 [==============================] - 2s 178us/sample - loss: 0.0692 - acc: 0.9058 - val_loss: 0.0597 - val_acc: 0.9189\n",
            "Epoch 135/700\n",
            "11983/11983 [==============================] - 2s 170us/sample - loss: 0.0686 - acc: 0.9082 - val_loss: 0.0600 - val_acc: 0.9189\n",
            "Epoch 136/700\n",
            "11983/11983 [==============================] - 2s 176us/sample - loss: 0.0685 - acc: 0.9093 - val_loss: 0.0594 - val_acc: 0.9176\n",
            "Epoch 137/700\n",
            "11983/11983 [==============================] - 2s 179us/sample - loss: 0.0674 - acc: 0.9092 - val_loss: 0.0593 - val_acc: 0.9166\n",
            "Epoch 138/700\n",
            "11983/11983 [==============================] - 2s 171us/sample - loss: 0.0661 - acc: 0.9110 - val_loss: 0.0594 - val_acc: 0.9182\n",
            "Epoch 139/700\n",
            "11983/11983 [==============================] - 2s 169us/sample - loss: 0.0658 - acc: 0.9141 - val_loss: 0.0593 - val_acc: 0.9182\n",
            "Epoch 140/700\n",
            "11983/11983 [==============================] - 2s 172us/sample - loss: 0.0664 - acc: 0.9121 - val_loss: 0.0591 - val_acc: 0.9176\n",
            "Epoch 141/700\n",
            "11983/11983 [==============================] - 2s 169us/sample - loss: 0.0679 - acc: 0.9096 - val_loss: 0.0586 - val_acc: 0.9186\n",
            "Epoch 142/700\n",
            "11983/11983 [==============================] - 2s 170us/sample - loss: 0.0665 - acc: 0.9117 - val_loss: 0.0580 - val_acc: 0.9202\n",
            "Epoch 143/700\n",
            "11983/11983 [==============================] - 2s 158us/sample - loss: 0.0668 - acc: 0.9119 - val_loss: 0.0590 - val_acc: 0.9196\n",
            "Epoch 144/700\n",
            "11983/11983 [==============================] - 2s 163us/sample - loss: 0.0659 - acc: 0.9129 - val_loss: 0.0587 - val_acc: 0.9186\n",
            "Epoch 145/700\n",
            "11983/11983 [==============================] - 2s 176us/sample - loss: 0.0652 - acc: 0.9109 - val_loss: 0.0596 - val_acc: 0.9179\n",
            "Epoch 146/700\n",
            "11983/11983 [==============================] - 2s 176us/sample - loss: 0.0653 - acc: 0.9117 - val_loss: 0.0588 - val_acc: 0.9209\n",
            "Epoch 147/700\n",
            "11983/11983 [==============================] - 2s 175us/sample - loss: 0.0658 - acc: 0.9113 - val_loss: 0.0584 - val_acc: 0.9179\n",
            "Epoch 148/700\n",
            "11983/11983 [==============================] - 2s 175us/sample - loss: 0.0662 - acc: 0.9116 - val_loss: 0.0581 - val_acc: 0.9202\n",
            "Epoch 149/700\n",
            "11983/11983 [==============================] - 2s 165us/sample - loss: 0.0669 - acc: 0.9101 - val_loss: 0.0583 - val_acc: 0.9216\n",
            "Epoch 150/700\n",
            "11983/11983 [==============================] - 2s 175us/sample - loss: 0.0647 - acc: 0.9138 - val_loss: 0.0573 - val_acc: 0.9232\n",
            "Epoch 151/700\n",
            "11983/11983 [==============================] - 2s 184us/sample - loss: 0.0650 - acc: 0.9121 - val_loss: 0.0572 - val_acc: 0.9229\n",
            "Epoch 152/700\n",
            "11983/11983 [==============================] - 2s 169us/sample - loss: 0.0667 - acc: 0.9125 - val_loss: 0.0571 - val_acc: 0.9246\n",
            "Epoch 153/700\n",
            "11983/11983 [==============================] - 2s 182us/sample - loss: 0.0650 - acc: 0.9151 - val_loss: 0.0580 - val_acc: 0.9216\n",
            "Epoch 154/700\n",
            "11983/11983 [==============================] - 2s 174us/sample - loss: 0.0632 - acc: 0.9173 - val_loss: 0.0571 - val_acc: 0.9212\n",
            "Epoch 155/700\n",
            "11983/11983 [==============================] - 2s 178us/sample - loss: 0.0655 - acc: 0.9110 - val_loss: 0.0574 - val_acc: 0.9212\n",
            "Epoch 156/700\n",
            "11983/11983 [==============================] - 2s 185us/sample - loss: 0.0643 - acc: 0.9143 - val_loss: 0.0570 - val_acc: 0.9242\n",
            "Epoch 157/700\n",
            "11983/11983 [==============================] - 2s 162us/sample - loss: 0.0634 - acc: 0.9162 - val_loss: 0.0571 - val_acc: 0.9209\n",
            "Epoch 158/700\n",
            "11983/11983 [==============================] - 2s 180us/sample - loss: 0.0645 - acc: 0.9138 - val_loss: 0.0577 - val_acc: 0.9209\n",
            "Epoch 159/700\n",
            "11983/11983 [==============================] - 2s 177us/sample - loss: 0.0651 - acc: 0.9133 - val_loss: 0.0560 - val_acc: 0.9236\n",
            "Epoch 160/700\n",
            "11983/11983 [==============================] - 2s 169us/sample - loss: 0.0637 - acc: 0.9162 - val_loss: 0.0572 - val_acc: 0.9222\n",
            "Epoch 161/700\n",
            "11983/11983 [==============================] - 2s 165us/sample - loss: 0.0643 - acc: 0.9155 - val_loss: 0.0577 - val_acc: 0.9219\n",
            "Epoch 162/700\n",
            "11983/11983 [==============================] - 2s 157us/sample - loss: 0.0633 - acc: 0.9155 - val_loss: 0.0568 - val_acc: 0.9232\n",
            "Epoch 163/700\n",
            "11983/11983 [==============================] - 2s 161us/sample - loss: 0.0653 - acc: 0.9139 - val_loss: 0.0576 - val_acc: 0.9209\n",
            "Epoch 164/700\n",
            "11983/11983 [==============================] - 2s 180us/sample - loss: 0.0653 - acc: 0.9126 - val_loss: 0.0570 - val_acc: 0.9229\n",
            "Epoch 165/700\n",
            "11983/11983 [==============================] - 2s 170us/sample - loss: 0.0632 - acc: 0.9150 - val_loss: 0.0564 - val_acc: 0.9226\n",
            "Epoch 166/700\n",
            "11983/11983 [==============================] - 2s 177us/sample - loss: 0.0634 - acc: 0.9149 - val_loss: 0.0561 - val_acc: 0.9236\n",
            "Epoch 167/700\n",
            "11983/11983 [==============================] - 2s 170us/sample - loss: 0.0629 - acc: 0.9174 - val_loss: 0.0564 - val_acc: 0.9222\n",
            "Epoch 168/700\n",
            "11983/11983 [==============================] - 2s 176us/sample - loss: 0.0628 - acc: 0.9170 - val_loss: 0.0561 - val_acc: 0.9229\n",
            "Epoch 169/700\n",
            "11983/11983 [==============================] - 2s 165us/sample - loss: 0.0642 - acc: 0.9142 - val_loss: 0.0562 - val_acc: 0.9212\n",
            "Epoch 170/700\n",
            "11983/11983 [==============================] - 2s 173us/sample - loss: 0.0624 - acc: 0.9170 - val_loss: 0.0569 - val_acc: 0.9222\n",
            "Epoch 171/700\n",
            "11983/11983 [==============================] - 2s 174us/sample - loss: 0.0637 - acc: 0.9150 - val_loss: 0.0567 - val_acc: 0.9219\n",
            "Epoch 172/700\n",
            "11983/11983 [==============================] - 2s 162us/sample - loss: 0.0637 - acc: 0.9145 - val_loss: 0.0564 - val_acc: 0.9239\n",
            "Epoch 173/700\n",
            "11983/11983 [==============================] - 2s 169us/sample - loss: 0.0627 - acc: 0.9175 - val_loss: 0.0557 - val_acc: 0.9252\n",
            "Epoch 174/700\n",
            "11983/11983 [==============================] - 2s 180us/sample - loss: 0.0630 - acc: 0.9160 - val_loss: 0.0558 - val_acc: 0.9249\n",
            "Epoch 175/700\n",
            "11983/11983 [==============================] - 2s 176us/sample - loss: 0.0620 - acc: 0.9185 - val_loss: 0.0554 - val_acc: 0.9216\n",
            "Epoch 176/700\n",
            "11983/11983 [==============================] - 2s 163us/sample - loss: 0.0631 - acc: 0.9156 - val_loss: 0.0557 - val_acc: 0.9262\n",
            "Epoch 177/700\n",
            "11983/11983 [==============================] - 2s 175us/sample - loss: 0.0620 - acc: 0.9178 - val_loss: 0.0559 - val_acc: 0.9252\n",
            "Epoch 178/700\n",
            "11983/11983 [==============================] - 2s 173us/sample - loss: 0.0627 - acc: 0.9168 - val_loss: 0.0546 - val_acc: 0.9252\n",
            "Epoch 179/700\n",
            "11983/11983 [==============================] - 2s 175us/sample - loss: 0.0628 - acc: 0.9179 - val_loss: 0.0553 - val_acc: 0.9256\n",
            "Epoch 180/700\n",
            "11983/11983 [==============================] - 2s 173us/sample - loss: 0.0634 - acc: 0.9150 - val_loss: 0.0542 - val_acc: 0.9262\n",
            "Epoch 181/700\n",
            "11983/11983 [==============================] - 2s 172us/sample - loss: 0.0617 - acc: 0.9184 - val_loss: 0.0550 - val_acc: 0.9226\n",
            "Epoch 182/700\n",
            "11983/11983 [==============================] - 2s 176us/sample - loss: 0.0593 - acc: 0.9222 - val_loss: 0.0547 - val_acc: 0.9256\n",
            "Epoch 183/700\n",
            "11983/11983 [==============================] - 2s 176us/sample - loss: 0.0619 - acc: 0.9186 - val_loss: 0.0543 - val_acc: 0.9252\n",
            "Epoch 184/700\n",
            "11983/11983 [==============================] - 2s 167us/sample - loss: 0.0637 - acc: 0.9146 - val_loss: 0.0546 - val_acc: 0.9259\n",
            "Epoch 185/700\n",
            "11983/11983 [==============================] - 2s 164us/sample - loss: 0.0622 - acc: 0.9169 - val_loss: 0.0546 - val_acc: 0.9266\n",
            "Epoch 186/700\n",
            "11983/11983 [==============================] - 2s 167us/sample - loss: 0.0628 - acc: 0.9178 - val_loss: 0.0547 - val_acc: 0.9242\n",
            "Epoch 187/700\n",
            "11983/11983 [==============================] - 2s 158us/sample - loss: 0.0610 - acc: 0.9186 - val_loss: 0.0548 - val_acc: 0.9262\n",
            "Epoch 188/700\n",
            "11983/11983 [==============================] - 2s 165us/sample - loss: 0.0634 - acc: 0.9154 - val_loss: 0.0545 - val_acc: 0.9252\n",
            "Epoch 189/700\n",
            "11983/11983 [==============================] - 2s 167us/sample - loss: 0.0622 - acc: 0.9178 - val_loss: 0.0551 - val_acc: 0.9249\n",
            "Epoch 190/700\n",
            "11983/11983 [==============================] - 2s 164us/sample - loss: 0.0612 - acc: 0.9169 - val_loss: 0.0546 - val_acc: 0.9262\n",
            "Epoch 191/700\n",
            "11983/11983 [==============================] - 2s 177us/sample - loss: 0.0617 - acc: 0.9179 - val_loss: 0.0542 - val_acc: 0.9289\n",
            "Epoch 192/700\n",
            "11983/11983 [==============================] - 2s 170us/sample - loss: 0.0613 - acc: 0.9179 - val_loss: 0.0546 - val_acc: 0.9239\n",
            "Epoch 193/700\n",
            "11983/11983 [==============================] - 2s 181us/sample - loss: 0.0607 - acc: 0.9187 - val_loss: 0.0543 - val_acc: 0.9259\n",
            "Epoch 194/700\n",
            "11983/11983 [==============================] - 2s 166us/sample - loss: 0.0598 - acc: 0.9205 - val_loss: 0.0535 - val_acc: 0.9259\n",
            "Epoch 195/700\n",
            "11983/11983 [==============================] - 2s 162us/sample - loss: 0.0617 - acc: 0.9194 - val_loss: 0.0531 - val_acc: 0.9272\n",
            "Epoch 196/700\n",
            "11983/11983 [==============================] - 2s 166us/sample - loss: 0.0583 - acc: 0.9231 - val_loss: 0.0554 - val_acc: 0.9249\n",
            "Epoch 197/700\n",
            "11983/11983 [==============================] - 2s 181us/sample - loss: 0.0616 - acc: 0.9175 - val_loss: 0.0535 - val_acc: 0.9269\n",
            "Epoch 198/700\n",
            "11983/11983 [==============================] - 2s 176us/sample - loss: 0.0618 - acc: 0.9178 - val_loss: 0.0537 - val_acc: 0.9256\n",
            "Epoch 199/700\n",
            "11983/11983 [==============================] - 2s 163us/sample - loss: 0.0606 - acc: 0.9187 - val_loss: 0.0546 - val_acc: 0.9239\n",
            "Epoch 200/700\n",
            "11983/11983 [==============================] - 2s 173us/sample - loss: 0.0607 - acc: 0.9206 - val_loss: 0.0540 - val_acc: 0.9256\n",
            "Epoch 201/700\n",
            "11983/11983 [==============================] - 2s 169us/sample - loss: 0.0599 - acc: 0.9211 - val_loss: 0.0547 - val_acc: 0.9272\n",
            "Epoch 202/700\n",
            "11983/11983 [==============================] - 2s 170us/sample - loss: 0.0601 - acc: 0.9231 - val_loss: 0.0533 - val_acc: 0.9259\n",
            "Epoch 203/700\n",
            "11983/11983 [==============================] - 2s 173us/sample - loss: 0.0600 - acc: 0.9204 - val_loss: 0.0526 - val_acc: 0.9282\n",
            "Epoch 204/700\n",
            "11983/11983 [==============================] - 2s 179us/sample - loss: 0.0611 - acc: 0.9182 - val_loss: 0.0523 - val_acc: 0.9266\n",
            "Epoch 205/700\n",
            "11983/11983 [==============================] - 2s 165us/sample - loss: 0.0596 - acc: 0.9214 - val_loss: 0.0526 - val_acc: 0.9272\n",
            "Epoch 206/700\n",
            "11983/11983 [==============================] - 2s 170us/sample - loss: 0.0595 - acc: 0.9214 - val_loss: 0.0523 - val_acc: 0.9282\n",
            "Epoch 207/700\n",
            "11983/11983 [==============================] - 2s 175us/sample - loss: 0.0614 - acc: 0.9185 - val_loss: 0.0521 - val_acc: 0.9282\n",
            "Epoch 208/700\n",
            "11983/11983 [==============================] - 2s 171us/sample - loss: 0.0598 - acc: 0.9200 - val_loss: 0.0534 - val_acc: 0.9259\n",
            "Epoch 209/700\n",
            "11983/11983 [==============================] - 2s 168us/sample - loss: 0.0612 - acc: 0.9196 - val_loss: 0.0525 - val_acc: 0.9282\n",
            "Epoch 210/700\n",
            "11983/11983 [==============================] - 2s 170us/sample - loss: 0.0598 - acc: 0.9206 - val_loss: 0.0524 - val_acc: 0.9279\n",
            "Epoch 211/700\n",
            "11983/11983 [==============================] - 2s 168us/sample - loss: 0.0605 - acc: 0.9206 - val_loss: 0.0524 - val_acc: 0.9282\n",
            "Epoch 212/700\n",
            "11983/11983 [==============================] - 2s 165us/sample - loss: 0.0589 - acc: 0.9208 - val_loss: 0.0525 - val_acc: 0.9292\n",
            "Epoch 213/700\n",
            "11983/11983 [==============================] - 2s 175us/sample - loss: 0.0601 - acc: 0.9206 - val_loss: 0.0524 - val_acc: 0.9282\n",
            "Epoch 214/700\n",
            "11983/11983 [==============================] - 2s 167us/sample - loss: 0.0588 - acc: 0.9217 - val_loss: 0.0528 - val_acc: 0.9279\n",
            "Epoch 215/700\n",
            "11983/11983 [==============================] - 2s 174us/sample - loss: 0.0583 - acc: 0.9226 - val_loss: 0.0531 - val_acc: 0.9276\n",
            "Epoch 216/700\n",
            "11983/11983 [==============================] - 2s 169us/sample - loss: 0.0580 - acc: 0.9256 - val_loss: 0.0523 - val_acc: 0.9292\n",
            "Epoch 217/700\n",
            "11983/11983 [==============================] - 2s 161us/sample - loss: 0.0598 - acc: 0.9211 - val_loss: 0.0528 - val_acc: 0.9266\n",
            "Epoch 218/700\n",
            "11983/11983 [==============================] - 2s 185us/sample - loss: 0.0591 - acc: 0.9222 - val_loss: 0.0518 - val_acc: 0.9286\n",
            "Epoch 219/700\n",
            "11983/11983 [==============================] - 2s 171us/sample - loss: 0.0584 - acc: 0.9224 - val_loss: 0.0524 - val_acc: 0.9269\n",
            "Epoch 220/700\n",
            "11983/11983 [==============================] - 2s 170us/sample - loss: 0.0574 - acc: 0.9248 - val_loss: 0.0527 - val_acc: 0.9276\n",
            "Epoch 221/700\n",
            "11983/11983 [==============================] - 2s 164us/sample - loss: 0.0601 - acc: 0.9213 - val_loss: 0.0522 - val_acc: 0.9269\n",
            "Epoch 222/700\n",
            "11983/11983 [==============================] - 2s 176us/sample - loss: 0.0569 - acc: 0.9256 - val_loss: 0.0518 - val_acc: 0.9282\n",
            "Epoch 223/700\n",
            "11983/11983 [==============================] - 2s 178us/sample - loss: 0.0585 - acc: 0.9216 - val_loss: 0.0525 - val_acc: 0.9262\n",
            "Epoch 224/700\n",
            "11983/11983 [==============================] - 2s 176us/sample - loss: 0.0579 - acc: 0.9227 - val_loss: 0.0525 - val_acc: 0.9282\n",
            "Epoch 225/700\n",
            "11983/11983 [==============================] - 2s 168us/sample - loss: 0.0583 - acc: 0.9228 - val_loss: 0.0525 - val_acc: 0.9312\n",
            "Epoch 226/700\n",
            "11983/11983 [==============================] - 2s 163us/sample - loss: 0.0582 - acc: 0.9235 - val_loss: 0.0527 - val_acc: 0.9276\n",
            "Epoch 227/700\n",
            "11983/11983 [==============================] - 2s 171us/sample - loss: 0.0593 - acc: 0.9234 - val_loss: 0.0517 - val_acc: 0.9292\n",
            "Epoch 228/700\n",
            "11983/11983 [==============================] - 2s 173us/sample - loss: 0.0578 - acc: 0.9247 - val_loss: 0.0522 - val_acc: 0.9276\n",
            "Epoch 229/700\n",
            "11983/11983 [==============================] - 2s 169us/sample - loss: 0.0590 - acc: 0.9208 - val_loss: 0.0520 - val_acc: 0.9276\n",
            "Epoch 230/700\n",
            "11983/11983 [==============================] - 2s 177us/sample - loss: 0.0571 - acc: 0.9254 - val_loss: 0.0511 - val_acc: 0.9282\n",
            "Epoch 231/700\n",
            "11983/11983 [==============================] - 2s 165us/sample - loss: 0.0574 - acc: 0.9254 - val_loss: 0.0512 - val_acc: 0.9289\n",
            "Epoch 232/700\n",
            "11983/11983 [==============================] - 2s 172us/sample - loss: 0.0568 - acc: 0.9245 - val_loss: 0.0519 - val_acc: 0.9269\n",
            "Epoch 233/700\n",
            "11983/11983 [==============================] - 2s 168us/sample - loss: 0.0585 - acc: 0.9247 - val_loss: 0.0511 - val_acc: 0.9296\n",
            "Epoch 234/700\n",
            "11983/11983 [==============================] - 2s 175us/sample - loss: 0.0589 - acc: 0.9217 - val_loss: 0.0512 - val_acc: 0.9289\n",
            "Epoch 235/700\n",
            "11983/11983 [==============================] - 2s 168us/sample - loss: 0.0575 - acc: 0.9241 - val_loss: 0.0509 - val_acc: 0.9316\n",
            "Epoch 236/700\n",
            "11983/11983 [==============================] - 2s 163us/sample - loss: 0.0573 - acc: 0.9257 - val_loss: 0.0508 - val_acc: 0.9309\n",
            "Epoch 237/700\n",
            "11983/11983 [==============================] - 2s 171us/sample - loss: 0.0569 - acc: 0.9251 - val_loss: 0.0514 - val_acc: 0.9292\n",
            "Epoch 238/700\n",
            "11983/11983 [==============================] - 2s 169us/sample - loss: 0.0588 - acc: 0.9238 - val_loss: 0.0507 - val_acc: 0.9309\n",
            "Epoch 239/700\n",
            "11983/11983 [==============================] - 2s 169us/sample - loss: 0.0571 - acc: 0.9241 - val_loss: 0.0509 - val_acc: 0.9302\n",
            "Epoch 240/700\n",
            "11983/11983 [==============================] - 2s 163us/sample - loss: 0.0561 - acc: 0.9257 - val_loss: 0.0507 - val_acc: 0.9299\n",
            "Epoch 241/700\n",
            "11983/11983 [==============================] - 2s 168us/sample - loss: 0.0565 - acc: 0.9253 - val_loss: 0.0508 - val_acc: 0.9292\n",
            "Epoch 242/700\n",
            "11983/11983 [==============================] - 2s 177us/sample - loss: 0.0577 - acc: 0.9235 - val_loss: 0.0503 - val_acc: 0.9312\n",
            "Epoch 243/700\n",
            "11983/11983 [==============================] - 2s 170us/sample - loss: 0.0561 - acc: 0.9263 - val_loss: 0.0496 - val_acc: 0.9336\n",
            "Epoch 244/700\n",
            "11983/11983 [==============================] - 2s 170us/sample - loss: 0.0569 - acc: 0.9253 - val_loss: 0.0501 - val_acc: 0.9302\n",
            "Epoch 245/700\n",
            "11983/11983 [==============================] - 2s 160us/sample - loss: 0.0557 - acc: 0.9243 - val_loss: 0.0500 - val_acc: 0.9292\n",
            "Epoch 246/700\n",
            "11983/11983 [==============================] - 2s 176us/sample - loss: 0.0569 - acc: 0.9251 - val_loss: 0.0508 - val_acc: 0.9279\n",
            "Epoch 247/700\n",
            "11983/11983 [==============================] - 2s 179us/sample - loss: 0.0561 - acc: 0.9261 - val_loss: 0.0501 - val_acc: 0.9316\n",
            "Epoch 248/700\n",
            "11983/11983 [==============================] - 2s 173us/sample - loss: 0.0567 - acc: 0.9268 - val_loss: 0.0500 - val_acc: 0.9309\n",
            "Epoch 249/700\n",
            "11983/11983 [==============================] - 2s 177us/sample - loss: 0.0550 - acc: 0.9293 - val_loss: 0.0491 - val_acc: 0.9346\n",
            "Epoch 250/700\n",
            "11983/11983 [==============================] - 2s 177us/sample - loss: 0.0553 - acc: 0.9259 - val_loss: 0.0497 - val_acc: 0.9316\n",
            "Epoch 251/700\n",
            "11983/11983 [==============================] - 2s 179us/sample - loss: 0.0566 - acc: 0.9276 - val_loss: 0.0498 - val_acc: 0.9326\n",
            "Epoch 252/700\n",
            "11983/11983 [==============================] - 2s 168us/sample - loss: 0.0551 - acc: 0.9291 - val_loss: 0.0495 - val_acc: 0.9316\n",
            "Epoch 253/700\n",
            "11983/11983 [==============================] - 2s 164us/sample - loss: 0.0548 - acc: 0.9274 - val_loss: 0.0492 - val_acc: 0.9329\n",
            "Epoch 254/700\n",
            "11983/11983 [==============================] - 2s 174us/sample - loss: 0.0559 - acc: 0.9262 - val_loss: 0.0496 - val_acc: 0.9332\n",
            "Epoch 255/700\n",
            "11983/11983 [==============================] - 2s 170us/sample - loss: 0.0562 - acc: 0.9246 - val_loss: 0.0494 - val_acc: 0.9332\n",
            "Epoch 256/700\n",
            "11983/11983 [==============================] - 2s 174us/sample - loss: 0.0550 - acc: 0.9270 - val_loss: 0.0491 - val_acc: 0.9326\n",
            "Epoch 257/700\n",
            "11983/11983 [==============================] - 2s 163us/sample - loss: 0.0547 - acc: 0.9266 - val_loss: 0.0489 - val_acc: 0.9332\n",
            "Epoch 258/700\n",
            "11983/11983 [==============================] - 2s 172us/sample - loss: 0.0559 - acc: 0.9283 - val_loss: 0.0486 - val_acc: 0.9342\n",
            "Epoch 259/700\n",
            "11983/11983 [==============================] - 2s 174us/sample - loss: 0.0565 - acc: 0.9257 - val_loss: 0.0487 - val_acc: 0.9356\n",
            "Epoch 260/700\n",
            "11983/11983 [==============================] - 2s 175us/sample - loss: 0.0553 - acc: 0.9268 - val_loss: 0.0494 - val_acc: 0.9326\n",
            "Epoch 261/700\n",
            "11983/11983 [==============================] - 2s 176us/sample - loss: 0.0552 - acc: 0.9294 - val_loss: 0.0490 - val_acc: 0.9332\n",
            "Epoch 262/700\n",
            "11983/11983 [==============================] - 2s 169us/sample - loss: 0.0569 - acc: 0.9257 - val_loss: 0.0497 - val_acc: 0.9296\n",
            "Epoch 263/700\n",
            "11983/11983 [==============================] - 2s 181us/sample - loss: 0.0551 - acc: 0.9267 - val_loss: 0.0486 - val_acc: 0.9342\n",
            "Epoch 264/700\n",
            "11983/11983 [==============================] - 2s 174us/sample - loss: 0.0560 - acc: 0.9277 - val_loss: 0.0482 - val_acc: 0.9346\n",
            "Epoch 265/700\n",
            "11983/11983 [==============================] - 2s 179us/sample - loss: 0.0559 - acc: 0.9266 - val_loss: 0.0488 - val_acc: 0.9329\n",
            "Epoch 266/700\n",
            "11983/11983 [==============================] - 2s 175us/sample - loss: 0.0549 - acc: 0.9288 - val_loss: 0.0480 - val_acc: 0.9342\n",
            "Epoch 267/700\n",
            "11983/11983 [==============================] - 2s 176us/sample - loss: 0.0553 - acc: 0.9275 - val_loss: 0.0486 - val_acc: 0.9332\n",
            "Epoch 268/700\n",
            "11983/11983 [==============================] - 2s 178us/sample - loss: 0.0549 - acc: 0.9276 - val_loss: 0.0481 - val_acc: 0.9346\n",
            "Epoch 269/700\n",
            "11983/11983 [==============================] - 2s 178us/sample - loss: 0.0557 - acc: 0.9275 - val_loss: 0.0490 - val_acc: 0.9322\n",
            "Epoch 270/700\n",
            "11983/11983 [==============================] - 2s 172us/sample - loss: 0.0540 - acc: 0.9298 - val_loss: 0.0493 - val_acc: 0.9339\n",
            "Epoch 271/700\n",
            "11983/11983 [==============================] - 2s 173us/sample - loss: 0.0552 - acc: 0.9267 - val_loss: 0.0487 - val_acc: 0.9342\n",
            "Epoch 272/700\n",
            "11983/11983 [==============================] - 2s 172us/sample - loss: 0.0540 - acc: 0.9289 - val_loss: 0.0487 - val_acc: 0.9342\n",
            "Epoch 273/700\n",
            "11983/11983 [==============================] - 2s 178us/sample - loss: 0.0556 - acc: 0.9267 - val_loss: 0.0482 - val_acc: 0.9336\n",
            "Epoch 274/700\n",
            "11983/11983 [==============================] - 2s 172us/sample - loss: 0.0546 - acc: 0.9281 - val_loss: 0.0487 - val_acc: 0.9339\n",
            "Epoch 275/700\n",
            "11983/11983 [==============================] - 2s 165us/sample - loss: 0.0541 - acc: 0.9277 - val_loss: 0.0487 - val_acc: 0.9322\n",
            "Epoch 276/700\n",
            "11983/11983 [==============================] - 2s 169us/sample - loss: 0.0538 - acc: 0.9296 - val_loss: 0.0482 - val_acc: 0.9339\n",
            "Epoch 277/700\n",
            "11983/11983 [==============================] - 2s 165us/sample - loss: 0.0535 - acc: 0.9286 - val_loss: 0.0480 - val_acc: 0.9356\n",
            "Epoch 278/700\n",
            "11983/11983 [==============================] - 2s 160us/sample - loss: 0.0541 - acc: 0.9286 - val_loss: 0.0482 - val_acc: 0.9342\n",
            "Epoch 279/700\n",
            "11983/11983 [==============================] - 2s 166us/sample - loss: 0.0546 - acc: 0.9276 - val_loss: 0.0487 - val_acc: 0.9312\n",
            "Epoch 280/700\n",
            "11983/11983 [==============================] - 2s 180us/sample - loss: 0.0528 - acc: 0.9309 - val_loss: 0.0483 - val_acc: 0.9356\n",
            "Epoch 281/700\n",
            "11983/11983 [==============================] - 2s 171us/sample - loss: 0.0539 - acc: 0.9289 - val_loss: 0.0484 - val_acc: 0.9332\n",
            "Epoch 282/700\n",
            "11983/11983 [==============================] - 2s 173us/sample - loss: 0.0547 - acc: 0.9262 - val_loss: 0.0488 - val_acc: 0.9332\n",
            "Epoch 283/700\n",
            "11983/11983 [==============================] - 2s 161us/sample - loss: 0.0560 - acc: 0.9273 - val_loss: 0.0489 - val_acc: 0.9332\n",
            "Epoch 284/700\n",
            "11983/11983 [==============================] - 2s 177us/sample - loss: 0.0524 - acc: 0.9310 - val_loss: 0.0482 - val_acc: 0.9356\n",
            "Epoch 285/700\n",
            "11983/11983 [==============================] - 2s 182us/sample - loss: 0.0543 - acc: 0.9287 - val_loss: 0.0485 - val_acc: 0.9322\n",
            "Epoch 286/700\n",
            "11983/11983 [==============================] - 2s 167us/sample - loss: 0.0547 - acc: 0.9268 - val_loss: 0.0482 - val_acc: 0.9339\n",
            "Epoch 287/700\n",
            "11983/11983 [==============================] - 2s 158us/sample - loss: 0.0532 - acc: 0.9290 - val_loss: 0.0477 - val_acc: 0.9356\n",
            "Epoch 288/700\n",
            "11983/11983 [==============================] - 2s 173us/sample - loss: 0.0528 - acc: 0.9320 - val_loss: 0.0479 - val_acc: 0.9346\n",
            "Epoch 289/700\n",
            "11983/11983 [==============================] - 2s 175us/sample - loss: 0.0534 - acc: 0.9303 - val_loss: 0.0477 - val_acc: 0.9359\n",
            "Epoch 290/700\n",
            "11983/11983 [==============================] - 2s 163us/sample - loss: 0.0531 - acc: 0.9297 - val_loss: 0.0483 - val_acc: 0.9342\n",
            "Epoch 291/700\n",
            "11983/11983 [==============================] - 2s 163us/sample - loss: 0.0539 - acc: 0.9287 - val_loss: 0.0480 - val_acc: 0.9326\n",
            "Epoch 292/700\n",
            "11983/11983 [==============================] - 2s 170us/sample - loss: 0.0521 - acc: 0.9322 - val_loss: 0.0482 - val_acc: 0.9329\n",
            "Epoch 293/700\n",
            "11983/11983 [==============================] - 2s 175us/sample - loss: 0.0526 - acc: 0.9305 - val_loss: 0.0482 - val_acc: 0.9339\n",
            "Epoch 294/700\n",
            "11983/11983 [==============================] - 2s 165us/sample - loss: 0.0546 - acc: 0.9298 - val_loss: 0.0485 - val_acc: 0.9322\n",
            "Epoch 295/700\n",
            "11983/11983 [==============================] - 2s 165us/sample - loss: 0.0543 - acc: 0.9289 - val_loss: 0.0475 - val_acc: 0.9352\n",
            "Epoch 296/700\n",
            "11983/11983 [==============================] - 2s 175us/sample - loss: 0.0542 - acc: 0.9291 - val_loss: 0.0479 - val_acc: 0.9306\n",
            "Epoch 297/700\n",
            "11983/11983 [==============================] - 2s 163us/sample - loss: 0.0542 - acc: 0.9300 - val_loss: 0.0484 - val_acc: 0.9339\n",
            "Epoch 298/700\n",
            "11983/11983 [==============================] - 2s 163us/sample - loss: 0.0539 - acc: 0.9286 - val_loss: 0.0472 - val_acc: 0.9346\n",
            "Epoch 299/700\n",
            "11983/11983 [==============================] - 2s 165us/sample - loss: 0.0541 - acc: 0.9312 - val_loss: 0.0471 - val_acc: 0.9376\n",
            "Epoch 300/700\n",
            "11983/11983 [==============================] - 2s 172us/sample - loss: 0.0528 - acc: 0.9304 - val_loss: 0.0479 - val_acc: 0.9352\n",
            "Epoch 301/700\n",
            "11983/11983 [==============================] - 2s 173us/sample - loss: 0.0529 - acc: 0.9312 - val_loss: 0.0479 - val_acc: 0.9332\n",
            "Epoch 302/700\n",
            "11983/11983 [==============================] - 2s 178us/sample - loss: 0.0517 - acc: 0.9331 - val_loss: 0.0468 - val_acc: 0.9356\n",
            "Epoch 303/700\n",
            "11983/11983 [==============================] - 2s 173us/sample - loss: 0.0531 - acc: 0.9295 - val_loss: 0.0479 - val_acc: 0.9332\n",
            "Epoch 304/700\n",
            "11983/11983 [==============================] - 2s 165us/sample - loss: 0.0532 - acc: 0.9308 - val_loss: 0.0472 - val_acc: 0.9356\n",
            "Epoch 305/700\n",
            "11983/11983 [==============================] - 2s 171us/sample - loss: 0.0532 - acc: 0.9302 - val_loss: 0.0467 - val_acc: 0.9359\n",
            "Epoch 306/700\n",
            "11983/11983 [==============================] - 2s 160us/sample - loss: 0.0529 - acc: 0.9310 - val_loss: 0.0482 - val_acc: 0.9326\n",
            "Epoch 307/700\n",
            "11983/11983 [==============================] - 2s 179us/sample - loss: 0.0533 - acc: 0.9307 - val_loss: 0.0475 - val_acc: 0.9362\n",
            "Epoch 308/700\n",
            "11983/11983 [==============================] - 2s 181us/sample - loss: 0.0528 - acc: 0.9289 - val_loss: 0.0477 - val_acc: 0.9359\n",
            "Epoch 309/700\n",
            "11983/11983 [==============================] - 2s 181us/sample - loss: 0.0538 - acc: 0.9283 - val_loss: 0.0475 - val_acc: 0.9349\n",
            "Epoch 310/700\n",
            "11983/11983 [==============================] - 2s 179us/sample - loss: 0.0527 - acc: 0.9310 - val_loss: 0.0470 - val_acc: 0.9346\n",
            "Epoch 311/700\n",
            "11983/11983 [==============================] - 2s 169us/sample - loss: 0.0516 - acc: 0.9329 - val_loss: 0.0471 - val_acc: 0.9362\n",
            "Epoch 312/700\n",
            "11983/11983 [==============================] - 2s 167us/sample - loss: 0.0527 - acc: 0.9301 - val_loss: 0.0466 - val_acc: 0.9383\n",
            "Epoch 313/700\n",
            "11983/11983 [==============================] - 2s 185us/sample - loss: 0.0522 - acc: 0.9317 - val_loss: 0.0465 - val_acc: 0.9376\n",
            "Epoch 314/700\n",
            "11983/11983 [==============================] - 2s 180us/sample - loss: 0.0527 - acc: 0.9313 - val_loss: 0.0472 - val_acc: 0.9342\n",
            "Epoch 315/700\n",
            "11983/11983 [==============================] - 2s 171us/sample - loss: 0.0517 - acc: 0.9327 - val_loss: 0.0469 - val_acc: 0.9379\n",
            "Epoch 316/700\n",
            "11983/11983 [==============================] - 2s 162us/sample - loss: 0.0543 - acc: 0.9287 - val_loss: 0.0464 - val_acc: 0.9362\n",
            "Epoch 317/700\n",
            "11983/11983 [==============================] - 2s 162us/sample - loss: 0.0509 - acc: 0.9337 - val_loss: 0.0465 - val_acc: 0.9366\n",
            "Epoch 318/700\n",
            "11983/11983 [==============================] - 2s 163us/sample - loss: 0.0519 - acc: 0.9328 - val_loss: 0.0460 - val_acc: 0.9352\n",
            "Epoch 319/700\n",
            "11983/11983 [==============================] - 2s 157us/sample - loss: 0.0518 - acc: 0.9336 - val_loss: 0.0464 - val_acc: 0.9362\n",
            "Epoch 320/700\n",
            "11983/11983 [==============================] - 2s 159us/sample - loss: 0.0531 - acc: 0.9299 - val_loss: 0.0470 - val_acc: 0.9352\n",
            "Epoch 321/700\n",
            "11983/11983 [==============================] - 2s 154us/sample - loss: 0.0519 - acc: 0.9307 - val_loss: 0.0475 - val_acc: 0.9346\n",
            "Epoch 322/700\n",
            "11983/11983 [==============================] - 2s 165us/sample - loss: 0.0508 - acc: 0.9337 - val_loss: 0.0463 - val_acc: 0.9366\n",
            "Epoch 323/700\n",
            "11983/11983 [==============================] - 2s 165us/sample - loss: 0.0506 - acc: 0.9347 - val_loss: 0.0466 - val_acc: 0.9356\n",
            "Epoch 324/700\n",
            "11983/11983 [==============================] - 2s 157us/sample - loss: 0.0515 - acc: 0.9322 - val_loss: 0.0462 - val_acc: 0.9362\n",
            "Epoch 325/700\n",
            "11983/11983 [==============================] - 2s 164us/sample - loss: 0.0510 - acc: 0.9322 - val_loss: 0.0467 - val_acc: 0.9359\n",
            "Epoch 326/700\n",
            "11983/11983 [==============================] - 2s 162us/sample - loss: 0.0513 - acc: 0.9336 - val_loss: 0.0457 - val_acc: 0.9376\n",
            "Epoch 327/700\n",
            "11983/11983 [==============================] - 2s 175us/sample - loss: 0.0508 - acc: 0.9333 - val_loss: 0.0470 - val_acc: 0.9356\n",
            "Epoch 328/700\n",
            "11983/11983 [==============================] - 2s 173us/sample - loss: 0.0503 - acc: 0.9350 - val_loss: 0.0461 - val_acc: 0.9366\n",
            "Epoch 329/700\n",
            "11983/11983 [==============================] - 2s 170us/sample - loss: 0.0506 - acc: 0.9344 - val_loss: 0.0467 - val_acc: 0.9366\n",
            "Epoch 330/700\n",
            "11983/11983 [==============================] - 2s 162us/sample - loss: 0.0511 - acc: 0.9340 - val_loss: 0.0462 - val_acc: 0.9356\n",
            "Epoch 331/700\n",
            "11983/11983 [==============================] - 2s 177us/sample - loss: 0.0524 - acc: 0.9297 - val_loss: 0.0463 - val_acc: 0.9386\n",
            "Epoch 332/700\n",
            "11983/11983 [==============================] - 2s 177us/sample - loss: 0.0527 - acc: 0.9307 - val_loss: 0.0462 - val_acc: 0.9356\n",
            "Epoch 333/700\n",
            "11983/11983 [==============================] - 2s 162us/sample - loss: 0.0519 - acc: 0.9307 - val_loss: 0.0452 - val_acc: 0.9389\n",
            "Epoch 334/700\n",
            "11983/11983 [==============================] - 2s 163us/sample - loss: 0.0502 - acc: 0.9339 - val_loss: 0.0458 - val_acc: 0.9372\n",
            "Epoch 335/700\n",
            "11983/11983 [==============================] - 2s 169us/sample - loss: 0.0513 - acc: 0.9322 - val_loss: 0.0451 - val_acc: 0.9372\n",
            "Epoch 336/700\n",
            "11983/11983 [==============================] - 2s 162us/sample - loss: 0.0500 - acc: 0.9343 - val_loss: 0.0456 - val_acc: 0.9389\n",
            "Epoch 337/700\n",
            "11983/11983 [==============================] - 2s 175us/sample - loss: 0.0513 - acc: 0.9331 - val_loss: 0.0458 - val_acc: 0.9362\n",
            "Epoch 338/700\n",
            "11983/11983 [==============================] - 2s 170us/sample - loss: 0.0509 - acc: 0.9346 - val_loss: 0.0453 - val_acc: 0.9372\n",
            "Epoch 339/700\n",
            "11983/11983 [==============================] - 2s 168us/sample - loss: 0.0505 - acc: 0.9346 - val_loss: 0.0456 - val_acc: 0.9383\n",
            "Epoch 340/700\n",
            "11983/11983 [==============================] - 2s 165us/sample - loss: 0.0502 - acc: 0.9357 - val_loss: 0.0451 - val_acc: 0.9356\n",
            "Epoch 341/700\n",
            "11983/11983 [==============================] - 2s 166us/sample - loss: 0.0503 - acc: 0.9344 - val_loss: 0.0452 - val_acc: 0.9386\n",
            "Epoch 342/700\n",
            "11983/11983 [==============================] - 2s 171us/sample - loss: 0.0526 - acc: 0.9307 - val_loss: 0.0452 - val_acc: 0.9386\n",
            "Epoch 343/700\n",
            "11983/11983 [==============================] - 2s 178us/sample - loss: 0.0506 - acc: 0.9329 - val_loss: 0.0458 - val_acc: 0.9389\n",
            "Epoch 344/700\n",
            "11983/11983 [==============================] - 2s 176us/sample - loss: 0.0524 - acc: 0.9301 - val_loss: 0.0456 - val_acc: 0.9393\n",
            "Epoch 345/700\n",
            "11983/11983 [==============================] - 2s 168us/sample - loss: 0.0497 - acc: 0.9364 - val_loss: 0.0452 - val_acc: 0.9372\n",
            "Epoch 346/700\n",
            "11983/11983 [==============================] - 2s 176us/sample - loss: 0.0493 - acc: 0.9345 - val_loss: 0.0448 - val_acc: 0.9389\n",
            "Epoch 347/700\n",
            "11983/11983 [==============================] - 2s 177us/sample - loss: 0.0493 - acc: 0.9351 - val_loss: 0.0457 - val_acc: 0.9386\n",
            "Epoch 348/700\n",
            "11983/11983 [==============================] - 2s 163us/sample - loss: 0.0517 - acc: 0.9304 - val_loss: 0.0449 - val_acc: 0.9389\n",
            "Epoch 349/700\n",
            "11983/11983 [==============================] - 2s 174us/sample - loss: 0.0514 - acc: 0.9312 - val_loss: 0.0436 - val_acc: 0.9419\n",
            "Epoch 350/700\n",
            "11983/11983 [==============================] - 2s 175us/sample - loss: 0.0500 - acc: 0.9346 - val_loss: 0.0453 - val_acc: 0.9369\n",
            "Epoch 351/700\n",
            "11983/11983 [==============================] - 2s 180us/sample - loss: 0.0490 - acc: 0.9352 - val_loss: 0.0451 - val_acc: 0.9376\n",
            "Epoch 352/700\n",
            "11983/11983 [==============================] - 2s 175us/sample - loss: 0.0500 - acc: 0.9334 - val_loss: 0.0450 - val_acc: 0.9362\n",
            "Epoch 353/700\n",
            "11983/11983 [==============================] - 2s 160us/sample - loss: 0.0483 - acc: 0.9363 - val_loss: 0.0440 - val_acc: 0.9406\n",
            "Epoch 354/700\n",
            "11983/11983 [==============================] - 2s 168us/sample - loss: 0.0486 - acc: 0.9354 - val_loss: 0.0441 - val_acc: 0.9403\n",
            "Epoch 355/700\n",
            "11983/11983 [==============================] - 2s 174us/sample - loss: 0.0498 - acc: 0.9345 - val_loss: 0.0441 - val_acc: 0.9393\n",
            "Epoch 356/700\n",
            "11983/11983 [==============================] - 2s 173us/sample - loss: 0.0505 - acc: 0.9324 - val_loss: 0.0445 - val_acc: 0.9399\n",
            "Epoch 357/700\n",
            "11983/11983 [==============================] - 2s 168us/sample - loss: 0.0527 - acc: 0.9314 - val_loss: 0.0445 - val_acc: 0.9379\n",
            "Epoch 358/700\n",
            "11983/11983 [==============================] - 2s 159us/sample - loss: 0.0502 - acc: 0.9337 - val_loss: 0.0450 - val_acc: 0.9409\n",
            "Epoch 359/700\n",
            "11983/11983 [==============================] - 2s 170us/sample - loss: 0.0508 - acc: 0.9327 - val_loss: 0.0444 - val_acc: 0.9409\n",
            "Epoch 360/700\n",
            "11983/11983 [==============================] - 2s 173us/sample - loss: 0.0487 - acc: 0.9374 - val_loss: 0.0461 - val_acc: 0.9376\n",
            "Epoch 361/700\n",
            "11983/11983 [==============================] - 2s 168us/sample - loss: 0.0490 - acc: 0.9359 - val_loss: 0.0445 - val_acc: 0.9386\n",
            "Epoch 362/700\n",
            "11983/11983 [==============================] - 2s 170us/sample - loss: 0.0504 - acc: 0.9350 - val_loss: 0.0454 - val_acc: 0.9383\n",
            "Epoch 363/700\n",
            "11983/11983 [==============================] - 2s 169us/sample - loss: 0.0499 - acc: 0.9331 - val_loss: 0.0448 - val_acc: 0.9396\n",
            "Epoch 364/700\n",
            "11983/11983 [==============================] - 2s 180us/sample - loss: 0.0488 - acc: 0.9364 - val_loss: 0.0443 - val_acc: 0.9389\n",
            "Epoch 365/700\n",
            "11983/11983 [==============================] - 2s 173us/sample - loss: 0.0494 - acc: 0.9369 - val_loss: 0.0457 - val_acc: 0.9383\n",
            "Epoch 366/700\n",
            "11983/11983 [==============================] - 2s 171us/sample - loss: 0.0494 - acc: 0.9343 - val_loss: 0.0441 - val_acc: 0.9413\n",
            "Epoch 367/700\n",
            "11983/11983 [==============================] - 2s 173us/sample - loss: 0.0486 - acc: 0.9366 - val_loss: 0.0440 - val_acc: 0.9393\n",
            "Epoch 368/700\n",
            "11983/11983 [==============================] - 2s 168us/sample - loss: 0.0504 - acc: 0.9338 - val_loss: 0.0444 - val_acc: 0.9383\n",
            "Epoch 369/700\n",
            "11983/11983 [==============================] - 2s 177us/sample - loss: 0.0487 - acc: 0.9364 - val_loss: 0.0444 - val_acc: 0.9399\n",
            "Epoch 370/700\n",
            "11983/11983 [==============================] - 2s 181us/sample - loss: 0.0488 - acc: 0.9357 - val_loss: 0.0444 - val_acc: 0.9396\n",
            "Epoch 371/700\n",
            "11983/11983 [==============================] - 2s 171us/sample - loss: 0.0486 - acc: 0.9379 - val_loss: 0.0439 - val_acc: 0.9409\n",
            "Epoch 372/700\n",
            "11983/11983 [==============================] - 2s 173us/sample - loss: 0.0482 - acc: 0.9384 - val_loss: 0.0434 - val_acc: 0.9416\n",
            "Epoch 373/700\n",
            "11983/11983 [==============================] - 2s 183us/sample - loss: 0.0484 - acc: 0.9362 - val_loss: 0.0443 - val_acc: 0.9409\n",
            "Epoch 374/700\n",
            "11983/11983 [==============================] - 2s 161us/sample - loss: 0.0489 - acc: 0.9372 - val_loss: 0.0433 - val_acc: 0.9419\n",
            "Epoch 375/700\n",
            "11983/11983 [==============================] - 2s 177us/sample - loss: 0.0500 - acc: 0.9352 - val_loss: 0.0434 - val_acc: 0.9403\n",
            "Epoch 376/700\n",
            "11983/11983 [==============================] - 2s 168us/sample - loss: 0.0510 - acc: 0.9317 - val_loss: 0.0437 - val_acc: 0.9406\n",
            "Epoch 377/700\n",
            "11983/11983 [==============================] - 2s 175us/sample - loss: 0.0492 - acc: 0.9369 - val_loss: 0.0436 - val_acc: 0.9409\n",
            "Epoch 378/700\n",
            "11983/11983 [==============================] - 2s 176us/sample - loss: 0.0477 - acc: 0.9373 - val_loss: 0.0434 - val_acc: 0.9426\n",
            "Epoch 379/700\n",
            "11983/11983 [==============================] - 2s 166us/sample - loss: 0.0490 - acc: 0.9342 - val_loss: 0.0444 - val_acc: 0.9396\n",
            "Epoch 380/700\n",
            "11983/11983 [==============================] - 2s 165us/sample - loss: 0.0487 - acc: 0.9370 - val_loss: 0.0441 - val_acc: 0.9393\n",
            "Epoch 381/700\n",
            "11983/11983 [==============================] - 2s 164us/sample - loss: 0.0483 - acc: 0.9372 - val_loss: 0.0439 - val_acc: 0.9386\n",
            "Epoch 382/700\n",
            "11983/11983 [==============================] - 2s 170us/sample - loss: 0.0492 - acc: 0.9356 - val_loss: 0.0436 - val_acc: 0.9409\n",
            "Epoch 383/700\n",
            "11983/11983 [==============================] - 2s 177us/sample - loss: 0.0481 - acc: 0.9374 - val_loss: 0.0433 - val_acc: 0.9419\n",
            "Epoch 384/700\n",
            "11983/11983 [==============================] - 2s 177us/sample - loss: 0.0480 - acc: 0.9372 - val_loss: 0.0449 - val_acc: 0.9389\n",
            "Epoch 385/700\n",
            "11983/11983 [==============================] - 2s 163us/sample - loss: 0.0497 - acc: 0.9353 - val_loss: 0.0442 - val_acc: 0.9393\n",
            "Epoch 386/700\n",
            "11983/11983 [==============================] - 2s 180us/sample - loss: 0.0486 - acc: 0.9375 - val_loss: 0.0438 - val_acc: 0.9406\n",
            "Epoch 387/700\n",
            "11983/11983 [==============================] - 2s 170us/sample - loss: 0.0484 - acc: 0.9369 - val_loss: 0.0434 - val_acc: 0.9406\n",
            "Epoch 388/700\n",
            "11983/11983 [==============================] - 2s 167us/sample - loss: 0.0486 - acc: 0.9370 - val_loss: 0.0434 - val_acc: 0.9396\n",
            "Epoch 389/700\n",
            "11983/11983 [==============================] - 2s 174us/sample - loss: 0.0474 - acc: 0.9388 - val_loss: 0.0437 - val_acc: 0.9396\n",
            "Epoch 390/700\n",
            "11983/11983 [==============================] - 2s 174us/sample - loss: 0.0493 - acc: 0.9352 - val_loss: 0.0441 - val_acc: 0.9399\n",
            "Epoch 391/700\n",
            "11983/11983 [==============================] - 2s 167us/sample - loss: 0.0483 - acc: 0.9352 - val_loss: 0.0441 - val_acc: 0.9393\n",
            "Epoch 392/700\n",
            "11983/11983 [==============================] - 2s 166us/sample - loss: 0.0494 - acc: 0.9357 - val_loss: 0.0443 - val_acc: 0.9393\n",
            "Epoch 393/700\n",
            "11983/11983 [==============================] - 2s 182us/sample - loss: 0.0493 - acc: 0.9359 - val_loss: 0.0436 - val_acc: 0.9419\n",
            "Epoch 394/700\n",
            "11983/11983 [==============================] - 2s 174us/sample - loss: 0.0469 - acc: 0.9384 - val_loss: 0.0439 - val_acc: 0.9396\n",
            "Epoch 395/700\n",
            "11983/11983 [==============================] - 2s 165us/sample - loss: 0.0467 - acc: 0.9411 - val_loss: 0.0442 - val_acc: 0.9396\n",
            "Epoch 396/700\n",
            "11983/11983 [==============================] - 2s 164us/sample - loss: 0.0462 - acc: 0.9397 - val_loss: 0.0435 - val_acc: 0.9403\n",
            "Epoch 397/700\n",
            "11983/11983 [==============================] - 2s 180us/sample - loss: 0.0487 - acc: 0.9355 - val_loss: 0.0428 - val_acc: 0.9426\n",
            "Epoch 398/700\n",
            "11983/11983 [==============================] - 2s 181us/sample - loss: 0.0484 - acc: 0.9363 - val_loss: 0.0431 - val_acc: 0.9416\n",
            "Epoch 399/700\n",
            "11983/11983 [==============================] - 2s 173us/sample - loss: 0.0475 - acc: 0.9385 - val_loss: 0.0425 - val_acc: 0.9419\n",
            "Epoch 400/700\n",
            "11983/11983 [==============================] - 2s 181us/sample - loss: 0.0469 - acc: 0.9391 - val_loss: 0.0429 - val_acc: 0.9416\n",
            "Epoch 401/700\n",
            "11983/11983 [==============================] - 2s 183us/sample - loss: 0.0463 - acc: 0.9407 - val_loss: 0.0423 - val_acc: 0.9449\n",
            "Epoch 402/700\n",
            "11983/11983 [==============================] - 2s 173us/sample - loss: 0.0473 - acc: 0.9382 - val_loss: 0.0439 - val_acc: 0.9403\n",
            "Epoch 403/700\n",
            "11983/11983 [==============================] - 2s 163us/sample - loss: 0.0496 - acc: 0.9326 - val_loss: 0.0432 - val_acc: 0.9423\n",
            "Epoch 404/700\n",
            "11983/11983 [==============================] - 2s 175us/sample - loss: 0.0476 - acc: 0.9381 - val_loss: 0.0428 - val_acc: 0.9419\n",
            "Epoch 405/700\n",
            "11983/11983 [==============================] - 2s 160us/sample - loss: 0.0486 - acc: 0.9378 - val_loss: 0.0434 - val_acc: 0.9419\n",
            "Epoch 406/700\n",
            "11983/11983 [==============================] - 2s 168us/sample - loss: 0.0459 - acc: 0.9412 - val_loss: 0.0431 - val_acc: 0.9436\n",
            "Epoch 407/700\n",
            "11983/11983 [==============================] - 2s 179us/sample - loss: 0.0474 - acc: 0.9381 - val_loss: 0.0438 - val_acc: 0.9399\n",
            "Epoch 408/700\n",
            "11983/11983 [==============================] - 2s 176us/sample - loss: 0.0470 - acc: 0.9380 - val_loss: 0.0437 - val_acc: 0.9419\n",
            "Epoch 409/700\n",
            "11983/11983 [==============================] - 2s 170us/sample - loss: 0.0476 - acc: 0.9367 - val_loss: 0.0440 - val_acc: 0.9386\n",
            "Epoch 410/700\n",
            "11983/11983 [==============================] - 2s 182us/sample - loss: 0.0477 - acc: 0.9362 - val_loss: 0.0430 - val_acc: 0.9443\n",
            "Epoch 411/700\n",
            "11983/11983 [==============================] - 2s 182us/sample - loss: 0.0482 - acc: 0.9372 - val_loss: 0.0426 - val_acc: 0.9426\n",
            "Epoch 412/700\n",
            "11983/11983 [==============================] - 2s 183us/sample - loss: 0.0460 - acc: 0.9396 - val_loss: 0.0433 - val_acc: 0.9419\n",
            "Epoch 413/700\n",
            "11983/11983 [==============================] - 2s 180us/sample - loss: 0.0493 - acc: 0.9348 - val_loss: 0.0430 - val_acc: 0.9416\n",
            "Epoch 414/700\n",
            "11983/11983 [==============================] - 2s 168us/sample - loss: 0.0471 - acc: 0.9395 - val_loss: 0.0426 - val_acc: 0.9439\n",
            "Epoch 415/700\n",
            "11983/11983 [==============================] - 2s 175us/sample - loss: 0.0477 - acc: 0.9374 - val_loss: 0.0419 - val_acc: 0.9443\n",
            "Epoch 416/700\n",
            "11983/11983 [==============================] - 2s 177us/sample - loss: 0.0459 - acc: 0.9414 - val_loss: 0.0415 - val_acc: 0.9453\n",
            "Epoch 417/700\n",
            "11983/11983 [==============================] - 2s 182us/sample - loss: 0.0466 - acc: 0.9384 - val_loss: 0.0423 - val_acc: 0.9436\n",
            "Epoch 418/700\n",
            "11983/11983 [==============================] - 2s 165us/sample - loss: 0.0471 - acc: 0.9373 - val_loss: 0.0422 - val_acc: 0.9419\n",
            "Epoch 419/700\n",
            "11983/11983 [==============================] - 2s 164us/sample - loss: 0.0464 - acc: 0.9384 - val_loss: 0.0423 - val_acc: 0.9439\n",
            "Epoch 420/700\n",
            "11983/11983 [==============================] - 2s 176us/sample - loss: 0.0465 - acc: 0.9385 - val_loss: 0.0424 - val_acc: 0.9436\n",
            "Epoch 421/700\n",
            "11983/11983 [==============================] - 2s 179us/sample - loss: 0.0462 - acc: 0.9402 - val_loss: 0.0418 - val_acc: 0.9443\n",
            "Epoch 422/700\n",
            "11983/11983 [==============================] - 2s 185us/sample - loss: 0.0476 - acc: 0.9364 - val_loss: 0.0420 - val_acc: 0.9433\n",
            "Epoch 423/700\n",
            "11983/11983 [==============================] - 2s 182us/sample - loss: 0.0478 - acc: 0.9380 - val_loss: 0.0419 - val_acc: 0.9433\n",
            "Epoch 424/700\n",
            "11983/11983 [==============================] - 2s 182us/sample - loss: 0.0447 - acc: 0.9412 - val_loss: 0.0418 - val_acc: 0.9446\n",
            "Epoch 425/700\n",
            "11983/11983 [==============================] - 2s 175us/sample - loss: 0.0477 - acc: 0.9382 - val_loss: 0.0416 - val_acc: 0.9439\n",
            "Epoch 426/700\n",
            "11983/11983 [==============================] - 2s 167us/sample - loss: 0.0471 - acc: 0.9362 - val_loss: 0.0417 - val_acc: 0.9449\n",
            "Epoch 427/700\n",
            "11983/11983 [==============================] - 2s 165us/sample - loss: 0.0470 - acc: 0.9383 - val_loss: 0.0419 - val_acc: 0.9429\n",
            "Epoch 428/700\n",
            "11983/11983 [==============================] - 2s 185us/sample - loss: 0.0471 - acc: 0.9369 - val_loss: 0.0417 - val_acc: 0.9436\n",
            "Epoch 429/700\n",
            "11983/11983 [==============================] - 2s 180us/sample - loss: 0.0481 - acc: 0.9368 - val_loss: 0.0419 - val_acc: 0.9433\n",
            "Epoch 430/700\n",
            "11983/11983 [==============================] - 2s 171us/sample - loss: 0.0464 - acc: 0.9373 - val_loss: 0.0412 - val_acc: 0.9453\n",
            "Epoch 431/700\n",
            "11983/11983 [==============================] - 2s 174us/sample - loss: 0.0461 - acc: 0.9396 - val_loss: 0.0421 - val_acc: 0.9456\n",
            "Epoch 432/700\n",
            "11983/11983 [==============================] - 2s 177us/sample - loss: 0.0470 - acc: 0.9379 - val_loss: 0.0422 - val_acc: 0.9439\n",
            "Epoch 433/700\n",
            "11983/11983 [==============================] - 2s 176us/sample - loss: 0.0467 - acc: 0.9397 - val_loss: 0.0422 - val_acc: 0.9439\n",
            "Epoch 434/700\n",
            "11983/11983 [==============================] - 2s 176us/sample - loss: 0.0454 - acc: 0.9419 - val_loss: 0.0413 - val_acc: 0.9449\n",
            "Epoch 435/700\n",
            "11983/11983 [==============================] - 2s 171us/sample - loss: 0.0462 - acc: 0.9421 - val_loss: 0.0412 - val_acc: 0.9466\n",
            "Epoch 436/700\n",
            "11983/11983 [==============================] - 2s 165us/sample - loss: 0.0453 - acc: 0.9418 - val_loss: 0.0410 - val_acc: 0.9453\n",
            "Epoch 437/700\n",
            "11983/11983 [==============================] - 2s 166us/sample - loss: 0.0468 - acc: 0.9386 - val_loss: 0.0419 - val_acc: 0.9453\n",
            "Epoch 438/700\n",
            "11983/11983 [==============================] - 2s 162us/sample - loss: 0.0473 - acc: 0.9377 - val_loss: 0.0414 - val_acc: 0.9469\n",
            "Epoch 439/700\n",
            "11983/11983 [==============================] - 2s 164us/sample - loss: 0.0445 - acc: 0.9407 - val_loss: 0.0407 - val_acc: 0.9463\n",
            "Epoch 440/700\n",
            "11983/11983 [==============================] - 2s 177us/sample - loss: 0.0454 - acc: 0.9412 - val_loss: 0.0419 - val_acc: 0.9449\n",
            "Epoch 441/700\n",
            "11983/11983 [==============================] - 2s 168us/sample - loss: 0.0461 - acc: 0.9393 - val_loss: 0.0417 - val_acc: 0.9443\n",
            "Epoch 442/700\n",
            "11983/11983 [==============================] - 2s 181us/sample - loss: 0.0448 - acc: 0.9420 - val_loss: 0.0416 - val_acc: 0.9439\n",
            "Epoch 443/700\n",
            "11983/11983 [==============================] - 2s 176us/sample - loss: 0.0467 - acc: 0.9397 - val_loss: 0.0416 - val_acc: 0.9449\n",
            "Epoch 444/700\n",
            "11983/11983 [==============================] - 2s 180us/sample - loss: 0.0436 - acc: 0.9445 - val_loss: 0.0414 - val_acc: 0.9449\n",
            "Epoch 445/700\n",
            "11983/11983 [==============================] - 2s 173us/sample - loss: 0.0451 - acc: 0.9416 - val_loss: 0.0422 - val_acc: 0.9419\n",
            "Epoch 446/700\n",
            "11983/11983 [==============================] - 2s 176us/sample - loss: 0.0454 - acc: 0.9387 - val_loss: 0.0420 - val_acc: 0.9449\n",
            "Epoch 447/700\n",
            "11983/11983 [==============================] - 2s 168us/sample - loss: 0.0467 - acc: 0.9374 - val_loss: 0.0408 - val_acc: 0.9463\n",
            "Epoch 448/700\n",
            "11983/11983 [==============================] - 2s 172us/sample - loss: 0.0468 - acc: 0.9386 - val_loss: 0.0416 - val_acc: 0.9423\n",
            "Epoch 449/700\n",
            "11983/11983 [==============================] - 2s 173us/sample - loss: 0.0471 - acc: 0.9377 - val_loss: 0.0405 - val_acc: 0.9459\n",
            "Epoch 450/700\n",
            "11983/11983 [==============================] - 2s 170us/sample - loss: 0.0464 - acc: 0.9397 - val_loss: 0.0425 - val_acc: 0.9429\n",
            "Epoch 451/700\n",
            "11983/11983 [==============================] - 2s 174us/sample - loss: 0.0466 - acc: 0.9400 - val_loss: 0.0409 - val_acc: 0.9423\n",
            "Epoch 452/700\n",
            "11983/11983 [==============================] - 2s 183us/sample - loss: 0.0458 - acc: 0.9396 - val_loss: 0.0412 - val_acc: 0.9476\n",
            "Epoch 453/700\n",
            "11983/11983 [==============================] - 2s 172us/sample - loss: 0.0455 - acc: 0.9413 - val_loss: 0.0409 - val_acc: 0.9449\n",
            "Epoch 454/700\n",
            "11983/11983 [==============================] - 2s 170us/sample - loss: 0.0460 - acc: 0.9396 - val_loss: 0.0404 - val_acc: 0.9466\n",
            "Epoch 455/700\n",
            "11983/11983 [==============================] - 2s 174us/sample - loss: 0.0458 - acc: 0.9397 - val_loss: 0.0412 - val_acc: 0.9463\n",
            "Epoch 456/700\n",
            "11983/11983 [==============================] - 2s 174us/sample - loss: 0.0459 - acc: 0.9411 - val_loss: 0.0405 - val_acc: 0.9473\n",
            "Epoch 457/700\n",
            "11983/11983 [==============================] - 2s 178us/sample - loss: 0.0473 - acc: 0.9374 - val_loss: 0.0402 - val_acc: 0.9476\n",
            "Epoch 458/700\n",
            "11983/11983 [==============================] - 2s 168us/sample - loss: 0.0446 - acc: 0.9397 - val_loss: 0.0403 - val_acc: 0.9469\n",
            "Epoch 459/700\n",
            "11983/11983 [==============================] - 2s 167us/sample - loss: 0.0453 - acc: 0.9406 - val_loss: 0.0415 - val_acc: 0.9439\n",
            "Epoch 460/700\n",
            "11983/11983 [==============================] - 2s 176us/sample - loss: 0.0478 - acc: 0.9378 - val_loss: 0.0406 - val_acc: 0.9459\n",
            "Epoch 461/700\n",
            "11983/11983 [==============================] - 2s 174us/sample - loss: 0.0454 - acc: 0.9411 - val_loss: 0.0410 - val_acc: 0.9443\n",
            "Epoch 462/700\n",
            "11983/11983 [==============================] - 2s 171us/sample - loss: 0.0451 - acc: 0.9404 - val_loss: 0.0414 - val_acc: 0.9443\n",
            "Epoch 463/700\n",
            "11983/11983 [==============================] - 2s 164us/sample - loss: 0.0471 - acc: 0.9383 - val_loss: 0.0404 - val_acc: 0.9456\n",
            "Epoch 464/700\n",
            "11983/11983 [==============================] - 2s 172us/sample - loss: 0.0448 - acc: 0.9424 - val_loss: 0.0399 - val_acc: 0.9476\n",
            "Epoch 465/700\n",
            "11983/11983 [==============================] - 2s 161us/sample - loss: 0.0449 - acc: 0.9411 - val_loss: 0.0401 - val_acc: 0.9473\n",
            "Epoch 466/700\n",
            "11983/11983 [==============================] - 2s 173us/sample - loss: 0.0442 - acc: 0.9414 - val_loss: 0.0403 - val_acc: 0.9469\n",
            "Epoch 467/700\n",
            "11983/11983 [==============================] - 2s 183us/sample - loss: 0.0450 - acc: 0.9413 - val_loss: 0.0404 - val_acc: 0.9469\n",
            "Epoch 468/700\n",
            "11983/11983 [==============================] - 2s 161us/sample - loss: 0.0447 - acc: 0.9424 - val_loss: 0.0394 - val_acc: 0.9479\n",
            "Epoch 469/700\n",
            "11983/11983 [==============================] - 2s 175us/sample - loss: 0.0459 - acc: 0.9405 - val_loss: 0.0399 - val_acc: 0.9466\n",
            "Epoch 470/700\n",
            "11983/11983 [==============================] - 2s 166us/sample - loss: 0.0456 - acc: 0.9408 - val_loss: 0.0399 - val_acc: 0.9469\n",
            "Epoch 471/700\n",
            "11983/11983 [==============================] - 2s 170us/sample - loss: 0.0459 - acc: 0.9386 - val_loss: 0.0403 - val_acc: 0.9459\n",
            "Epoch 472/700\n",
            "11983/11983 [==============================] - 2s 170us/sample - loss: 0.0474 - acc: 0.9380 - val_loss: 0.0400 - val_acc: 0.9459\n",
            "Epoch 473/700\n",
            "11983/11983 [==============================] - 2s 166us/sample - loss: 0.0443 - acc: 0.9423 - val_loss: 0.0398 - val_acc: 0.9466\n",
            "Epoch 474/700\n",
            "11983/11983 [==============================] - 2s 177us/sample - loss: 0.0453 - acc: 0.9405 - val_loss: 0.0400 - val_acc: 0.9476\n",
            "Epoch 475/700\n",
            "11983/11983 [==============================] - 2s 180us/sample - loss: 0.0446 - acc: 0.9422 - val_loss: 0.0403 - val_acc: 0.9446\n",
            "Epoch 476/700\n",
            "11983/11983 [==============================] - 2s 178us/sample - loss: 0.0456 - acc: 0.9407 - val_loss: 0.0408 - val_acc: 0.9436\n",
            "Epoch 477/700\n",
            "11983/11983 [==============================] - 2s 162us/sample - loss: 0.0451 - acc: 0.9394 - val_loss: 0.0404 - val_acc: 0.9473\n",
            "Epoch 478/700\n",
            "11983/11983 [==============================] - 2s 165us/sample - loss: 0.0446 - acc: 0.9415 - val_loss: 0.0402 - val_acc: 0.9463\n",
            "Epoch 479/700\n",
            "11983/11983 [==============================] - 2s 178us/sample - loss: 0.0453 - acc: 0.9401 - val_loss: 0.0397 - val_acc: 0.9483\n",
            "Epoch 480/700\n",
            "11983/11983 [==============================] - 2s 176us/sample - loss: 0.0446 - acc: 0.9407 - val_loss: 0.0398 - val_acc: 0.9463\n",
            "Epoch 481/700\n",
            "11983/11983 [==============================] - 2s 168us/sample - loss: 0.0451 - acc: 0.9401 - val_loss: 0.0399 - val_acc: 0.9489\n",
            "Epoch 482/700\n",
            "11983/11983 [==============================] - 2s 173us/sample - loss: 0.0460 - acc: 0.9397 - val_loss: 0.0394 - val_acc: 0.9476\n",
            "Epoch 483/700\n",
            "11983/11983 [==============================] - 2s 183us/sample - loss: 0.0447 - acc: 0.9429 - val_loss: 0.0394 - val_acc: 0.9476\n",
            "Epoch 484/700\n",
            "11983/11983 [==============================] - 2s 173us/sample - loss: 0.0456 - acc: 0.9399 - val_loss: 0.0402 - val_acc: 0.9466\n",
            "Epoch 485/700\n",
            "11983/11983 [==============================] - 2s 158us/sample - loss: 0.0433 - acc: 0.9423 - val_loss: 0.0403 - val_acc: 0.9449\n",
            "Epoch 486/700\n",
            "11983/11983 [==============================] - 2s 175us/sample - loss: 0.0436 - acc: 0.9435 - val_loss: 0.0403 - val_acc: 0.9456\n",
            "Epoch 487/700\n",
            "11983/11983 [==============================] - 2s 173us/sample - loss: 0.0443 - acc: 0.9446 - val_loss: 0.0411 - val_acc: 0.9436\n",
            "Epoch 488/700\n",
            "11983/11983 [==============================] - 2s 172us/sample - loss: 0.0449 - acc: 0.9399 - val_loss: 0.0405 - val_acc: 0.9469\n",
            "Epoch 489/700\n",
            "11983/11983 [==============================] - 2s 186us/sample - loss: 0.0455 - acc: 0.9394 - val_loss: 0.0397 - val_acc: 0.9469\n",
            "Epoch 490/700\n",
            "11983/11983 [==============================] - 2s 165us/sample - loss: 0.0446 - acc: 0.9416 - val_loss: 0.0398 - val_acc: 0.9456\n",
            "Epoch 491/700\n",
            "11983/11983 [==============================] - 2s 166us/sample - loss: 0.0443 - acc: 0.9414 - val_loss: 0.0399 - val_acc: 0.9456\n",
            "Epoch 492/700\n",
            "11983/11983 [==============================] - 2s 176us/sample - loss: 0.0453 - acc: 0.9400 - val_loss: 0.0393 - val_acc: 0.9509\n",
            "Epoch 493/700\n",
            "11983/11983 [==============================] - 2s 164us/sample - loss: 0.0453 - acc: 0.9411 - val_loss: 0.0403 - val_acc: 0.9459\n",
            "Epoch 494/700\n",
            "11983/11983 [==============================] - 2s 163us/sample - loss: 0.0452 - acc: 0.9422 - val_loss: 0.0397 - val_acc: 0.9446\n",
            "Epoch 495/700\n",
            "11983/11983 [==============================] - 2s 185us/sample - loss: 0.0453 - acc: 0.9413 - val_loss: 0.0397 - val_acc: 0.9469\n",
            "Epoch 496/700\n",
            "11983/11983 [==============================] - 2s 175us/sample - loss: 0.0444 - acc: 0.9412 - val_loss: 0.0404 - val_acc: 0.9453\n",
            "Epoch 497/700\n",
            "11983/11983 [==============================] - 2s 177us/sample - loss: 0.0450 - acc: 0.9407 - val_loss: 0.0393 - val_acc: 0.9486\n",
            "Epoch 498/700\n",
            "11983/11983 [==============================] - 2s 172us/sample - loss: 0.0441 - acc: 0.9427 - val_loss: 0.0396 - val_acc: 0.9486\n",
            "Epoch 499/700\n",
            "11983/11983 [==============================] - 2s 172us/sample - loss: 0.0465 - acc: 0.9398 - val_loss: 0.0395 - val_acc: 0.9466\n",
            "Epoch 500/700\n",
            "11983/11983 [==============================] - 2s 160us/sample - loss: 0.0436 - acc: 0.9446 - val_loss: 0.0391 - val_acc: 0.9476\n",
            "Epoch 501/700\n",
            "11983/11983 [==============================] - 2s 167us/sample - loss: 0.0443 - acc: 0.9423 - val_loss: 0.0408 - val_acc: 0.9459\n",
            "Epoch 502/700\n",
            "11983/11983 [==============================] - 2s 163us/sample - loss: 0.0445 - acc: 0.9415 - val_loss: 0.0389 - val_acc: 0.9483\n",
            "Epoch 503/700\n",
            "11983/11983 [==============================] - 2s 162us/sample - loss: 0.0440 - acc: 0.9416 - val_loss: 0.0398 - val_acc: 0.9469\n",
            "Epoch 504/700\n",
            "11983/11983 [==============================] - 2s 156us/sample - loss: 0.0436 - acc: 0.9421 - val_loss: 0.0401 - val_acc: 0.9453\n",
            "Epoch 505/700\n",
            "11983/11983 [==============================] - 2s 159us/sample - loss: 0.0437 - acc: 0.9425 - val_loss: 0.0390 - val_acc: 0.9479\n",
            "Epoch 506/700\n",
            "11983/11983 [==============================] - 2s 166us/sample - loss: 0.0437 - acc: 0.9416 - val_loss: 0.0392 - val_acc: 0.9473\n",
            "Epoch 507/700\n",
            "11983/11983 [==============================] - 2s 184us/sample - loss: 0.0436 - acc: 0.9413 - val_loss: 0.0397 - val_acc: 0.9456\n",
            "Epoch 508/700\n",
            "11983/11983 [==============================] - 2s 178us/sample - loss: 0.0423 - acc: 0.9452 - val_loss: 0.0390 - val_acc: 0.9476\n",
            "Epoch 509/700\n",
            "11983/11983 [==============================] - 2s 175us/sample - loss: 0.0440 - acc: 0.9416 - val_loss: 0.0395 - val_acc: 0.9463\n",
            "Epoch 510/700\n",
            "11983/11983 [==============================] - 2s 175us/sample - loss: 0.0440 - acc: 0.9418 - val_loss: 0.0407 - val_acc: 0.9446\n",
            "Epoch 511/700\n",
            "11983/11983 [==============================] - 2s 171us/sample - loss: 0.0448 - acc: 0.9413 - val_loss: 0.0397 - val_acc: 0.9456\n",
            "Epoch 512/700\n",
            "11983/11983 [==============================] - 2s 167us/sample - loss: 0.0435 - acc: 0.9428 - val_loss: 0.0391 - val_acc: 0.9463\n",
            "Epoch 513/700\n",
            "11983/11983 [==============================] - 2s 183us/sample - loss: 0.0430 - acc: 0.9430 - val_loss: 0.0392 - val_acc: 0.9476\n",
            "Epoch 514/700\n",
            "11983/11983 [==============================] - 2s 178us/sample - loss: 0.0443 - acc: 0.9413 - val_loss: 0.0391 - val_acc: 0.9483\n",
            "Epoch 515/700\n",
            "11983/11983 [==============================] - 2s 173us/sample - loss: 0.0434 - acc: 0.9435 - val_loss: 0.0394 - val_acc: 0.9479\n",
            "Epoch 516/700\n",
            "11983/11983 [==============================] - 2s 168us/sample - loss: 0.0455 - acc: 0.9387 - val_loss: 0.0392 - val_acc: 0.9466\n",
            "Epoch 517/700\n",
            "11983/11983 [==============================] - 2s 181us/sample - loss: 0.0451 - acc: 0.9390 - val_loss: 0.0393 - val_acc: 0.9483\n",
            "Epoch 518/700\n",
            "11983/11983 [==============================] - 2s 170us/sample - loss: 0.0418 - acc: 0.9435 - val_loss: 0.0387 - val_acc: 0.9483\n",
            "Epoch 519/700\n",
            "11983/11983 [==============================] - 2s 171us/sample - loss: 0.0436 - acc: 0.9443 - val_loss: 0.0385 - val_acc: 0.9486\n",
            "Epoch 520/700\n",
            "11983/11983 [==============================] - 2s 164us/sample - loss: 0.0437 - acc: 0.9438 - val_loss: 0.0395 - val_acc: 0.9459\n",
            "Epoch 521/700\n",
            "11983/11983 [==============================] - 2s 175us/sample - loss: 0.0436 - acc: 0.9441 - val_loss: 0.0385 - val_acc: 0.9489\n",
            "Epoch 522/700\n",
            "11983/11983 [==============================] - 2s 168us/sample - loss: 0.0440 - acc: 0.9426 - val_loss: 0.0379 - val_acc: 0.9509\n",
            "Epoch 523/700\n",
            "11983/11983 [==============================] - 2s 170us/sample - loss: 0.0418 - acc: 0.9443 - val_loss: 0.0387 - val_acc: 0.9486\n",
            "Epoch 524/700\n",
            "11983/11983 [==============================] - 2s 174us/sample - loss: 0.0446 - acc: 0.9421 - val_loss: 0.0385 - val_acc: 0.9493\n",
            "Epoch 525/700\n",
            "11983/11983 [==============================] - 2s 172us/sample - loss: 0.0428 - acc: 0.9435 - val_loss: 0.0387 - val_acc: 0.9496\n",
            "Epoch 526/700\n",
            "11983/11983 [==============================] - 2s 179us/sample - loss: 0.0416 - acc: 0.9457 - val_loss: 0.0393 - val_acc: 0.9479\n",
            "Epoch 527/700\n",
            "11983/11983 [==============================] - 2s 176us/sample - loss: 0.0428 - acc: 0.9418 - val_loss: 0.0389 - val_acc: 0.9496\n",
            "Epoch 528/700\n",
            "11983/11983 [==============================] - 2s 169us/sample - loss: 0.0440 - acc: 0.9409 - val_loss: 0.0385 - val_acc: 0.9499\n",
            "Epoch 529/700\n",
            "11983/11983 [==============================] - 2s 190us/sample - loss: 0.0442 - acc: 0.9420 - val_loss: 0.0386 - val_acc: 0.9486\n",
            "Epoch 530/700\n",
            "11983/11983 [==============================] - 2s 175us/sample - loss: 0.0417 - acc: 0.9453 - val_loss: 0.0378 - val_acc: 0.9496\n",
            "Epoch 531/700\n",
            "11983/11983 [==============================] - 2s 176us/sample - loss: 0.0435 - acc: 0.9435 - val_loss: 0.0381 - val_acc: 0.9489\n",
            "Epoch 532/700\n",
            "11983/11983 [==============================] - 2s 173us/sample - loss: 0.0425 - acc: 0.9438 - val_loss: 0.0389 - val_acc: 0.9476\n",
            "Epoch 533/700\n",
            "11983/11983 [==============================] - 2s 163us/sample - loss: 0.0441 - acc: 0.9418 - val_loss: 0.0388 - val_acc: 0.9489\n",
            "Epoch 534/700\n",
            "11983/11983 [==============================] - 2s 171us/sample - loss: 0.0437 - acc: 0.9414 - val_loss: 0.0398 - val_acc: 0.9473\n",
            "Epoch 535/700\n",
            "11983/11983 [==============================] - 2s 176us/sample - loss: 0.0452 - acc: 0.9413 - val_loss: 0.0387 - val_acc: 0.9509\n",
            "Epoch 536/700\n",
            "11983/11983 [==============================] - 2s 177us/sample - loss: 0.0443 - acc: 0.9416 - val_loss: 0.0379 - val_acc: 0.9496\n",
            "Epoch 537/700\n",
            "11983/11983 [==============================] - 2s 176us/sample - loss: 0.0412 - acc: 0.9461 - val_loss: 0.0381 - val_acc: 0.9489\n",
            "Epoch 538/700\n",
            "11983/11983 [==============================] - 2s 180us/sample - loss: 0.0432 - acc: 0.9438 - val_loss: 0.0389 - val_acc: 0.9489\n",
            "Epoch 539/700\n",
            "11983/11983 [==============================] - 2s 175us/sample - loss: 0.0425 - acc: 0.9449 - val_loss: 0.0391 - val_acc: 0.9476\n",
            "Epoch 540/700\n",
            "11983/11983 [==============================] - 2s 196us/sample - loss: 0.0439 - acc: 0.9427 - val_loss: 0.0383 - val_acc: 0.9489\n",
            "Epoch 541/700\n",
            "11983/11983 [==============================] - 2s 178us/sample - loss: 0.0422 - acc: 0.9463 - val_loss: 0.0374 - val_acc: 0.9499\n",
            "Epoch 542/700\n",
            "11983/11983 [==============================] - 2s 160us/sample - loss: 0.0429 - acc: 0.9436 - val_loss: 0.0387 - val_acc: 0.9473\n",
            "Epoch 543/700\n",
            "11983/11983 [==============================] - 2s 170us/sample - loss: 0.0425 - acc: 0.9447 - val_loss: 0.0385 - val_acc: 0.9479\n",
            "Epoch 544/700\n",
            "11983/11983 [==============================] - 2s 194us/sample - loss: 0.0435 - acc: 0.9428 - val_loss: 0.0384 - val_acc: 0.9463\n",
            "Epoch 545/700\n",
            "11983/11983 [==============================] - 2s 164us/sample - loss: 0.0417 - acc: 0.9464 - val_loss: 0.0377 - val_acc: 0.9483\n",
            "Epoch 546/700\n",
            "11983/11983 [==============================] - 2s 166us/sample - loss: 0.0420 - acc: 0.9464 - val_loss: 0.0385 - val_acc: 0.9479\n",
            "Epoch 547/700\n",
            "11983/11983 [==============================] - 2s 181us/sample - loss: 0.0415 - acc: 0.9437 - val_loss: 0.0382 - val_acc: 0.9469\n",
            "Epoch 548/700\n",
            "11983/11983 [==============================] - 2s 178us/sample - loss: 0.0428 - acc: 0.9443 - val_loss: 0.0384 - val_acc: 0.9479\n",
            "Epoch 549/700\n",
            "11983/11983 [==============================] - 2s 174us/sample - loss: 0.0438 - acc: 0.9422 - val_loss: 0.0382 - val_acc: 0.9479\n",
            "Epoch 550/700\n",
            "11983/11983 [==============================] - 2s 163us/sample - loss: 0.0429 - acc: 0.9416 - val_loss: 0.0380 - val_acc: 0.9496\n",
            "Epoch 551/700\n",
            "11983/11983 [==============================] - 2s 168us/sample - loss: 0.0414 - acc: 0.9461 - val_loss: 0.0383 - val_acc: 0.9486\n",
            "Epoch 552/700\n",
            "11983/11983 [==============================] - 2s 167us/sample - loss: 0.0419 - acc: 0.9466 - val_loss: 0.0384 - val_acc: 0.9493\n",
            "Epoch 553/700\n",
            "11983/11983 [==============================] - 2s 176us/sample - loss: 0.0425 - acc: 0.9440 - val_loss: 0.0384 - val_acc: 0.9493\n",
            "Epoch 554/700\n",
            "11983/11983 [==============================] - 2s 167us/sample - loss: 0.0420 - acc: 0.9460 - val_loss: 0.0376 - val_acc: 0.9519\n",
            "Epoch 555/700\n",
            "11983/11983 [==============================] - 2s 181us/sample - loss: 0.0418 - acc: 0.9467 - val_loss: 0.0386 - val_acc: 0.9493\n",
            "Epoch 556/700\n",
            "11983/11983 [==============================] - 2s 175us/sample - loss: 0.0427 - acc: 0.9440 - val_loss: 0.0386 - val_acc: 0.9486\n",
            "Epoch 557/700\n",
            "11983/11983 [==============================] - 2s 167us/sample - loss: 0.0414 - acc: 0.9459 - val_loss: 0.0390 - val_acc: 0.9456\n",
            "Epoch 558/700\n",
            "11983/11983 [==============================] - 2s 178us/sample - loss: 0.0421 - acc: 0.9445 - val_loss: 0.0391 - val_acc: 0.9479\n",
            "Epoch 559/700\n",
            "11983/11983 [==============================] - 2s 168us/sample - loss: 0.0428 - acc: 0.9438 - val_loss: 0.0377 - val_acc: 0.9509\n",
            "Epoch 560/700\n",
            "11983/11983 [==============================] - 2s 176us/sample - loss: 0.0410 - acc: 0.9473 - val_loss: 0.0385 - val_acc: 0.9493\n",
            "Epoch 561/700\n",
            "11983/11983 [==============================] - 2s 168us/sample - loss: 0.0409 - acc: 0.9474 - val_loss: 0.0384 - val_acc: 0.9486\n",
            "Epoch 562/700\n",
            "11983/11983 [==============================] - 2s 166us/sample - loss: 0.0417 - acc: 0.9453 - val_loss: 0.0382 - val_acc: 0.9486\n",
            "Epoch 563/700\n",
            "11983/11983 [==============================] - 2s 167us/sample - loss: 0.0427 - acc: 0.9446 - val_loss: 0.0380 - val_acc: 0.9493\n",
            "Epoch 564/700\n",
            "11983/11983 [==============================] - 2s 170us/sample - loss: 0.0420 - acc: 0.9454 - val_loss: 0.0384 - val_acc: 0.9479\n",
            "Epoch 565/700\n",
            "11983/11983 [==============================] - 2s 169us/sample - loss: 0.0426 - acc: 0.9446 - val_loss: 0.0378 - val_acc: 0.9499\n",
            "Epoch 566/700\n",
            "11983/11983 [==============================] - 2s 168us/sample - loss: 0.0430 - acc: 0.9441 - val_loss: 0.0386 - val_acc: 0.9493\n",
            "Epoch 567/700\n",
            "11983/11983 [==============================] - 2s 168us/sample - loss: 0.0430 - acc: 0.9434 - val_loss: 0.0390 - val_acc: 0.9476\n",
            "Epoch 568/700\n",
            "11983/11983 [==============================] - 2s 157us/sample - loss: 0.0415 - acc: 0.9456 - val_loss: 0.0389 - val_acc: 0.9489\n",
            "Epoch 569/700\n",
            "11983/11983 [==============================] - 2s 172us/sample - loss: 0.0411 - acc: 0.9467 - val_loss: 0.0386 - val_acc: 0.9496\n",
            "Epoch 570/700\n",
            "11983/11983 [==============================] - 2s 169us/sample - loss: 0.0430 - acc: 0.9421 - val_loss: 0.0380 - val_acc: 0.9516\n",
            "Epoch 571/700\n",
            "11983/11983 [==============================] - 2s 161us/sample - loss: 0.0423 - acc: 0.9442 - val_loss: 0.0387 - val_acc: 0.9499\n",
            "Epoch 572/700\n",
            "11983/11983 [==============================] - 2s 161us/sample - loss: 0.0417 - acc: 0.9453 - val_loss: 0.0384 - val_acc: 0.9493\n",
            "Epoch 573/700\n",
            "11983/11983 [==============================] - 2s 167us/sample - loss: 0.0414 - acc: 0.9431 - val_loss: 0.0373 - val_acc: 0.9519\n",
            "Epoch 574/700\n",
            "11983/11983 [==============================] - 2s 180us/sample - loss: 0.0411 - acc: 0.9463 - val_loss: 0.0393 - val_acc: 0.9506\n",
            "Epoch 575/700\n",
            "11983/11983 [==============================] - 2s 170us/sample - loss: 0.0428 - acc: 0.9446 - val_loss: 0.0375 - val_acc: 0.9509\n",
            "Epoch 576/700\n",
            "11983/11983 [==============================] - 2s 171us/sample - loss: 0.0433 - acc: 0.9438 - val_loss: 0.0375 - val_acc: 0.9503\n",
            "Epoch 577/700\n",
            "11983/11983 [==============================] - 2s 175us/sample - loss: 0.0406 - acc: 0.9462 - val_loss: 0.0379 - val_acc: 0.9493\n",
            "Epoch 578/700\n",
            "11983/11983 [==============================] - 2s 181us/sample - loss: 0.0426 - acc: 0.9437 - val_loss: 0.0387 - val_acc: 0.9496\n",
            "Epoch 579/700\n",
            "11983/11983 [==============================] - 2s 174us/sample - loss: 0.0424 - acc: 0.9451 - val_loss: 0.0376 - val_acc: 0.9499\n",
            "Epoch 580/700\n",
            "11983/11983 [==============================] - 2s 165us/sample - loss: 0.0416 - acc: 0.9468 - val_loss: 0.0381 - val_acc: 0.9516\n",
            "Epoch 581/700\n",
            "11983/11983 [==============================] - 2s 165us/sample - loss: 0.0424 - acc: 0.9453 - val_loss: 0.0377 - val_acc: 0.9516\n",
            "Epoch 582/700\n",
            "11983/11983 [==============================] - 2s 173us/sample - loss: 0.0411 - acc: 0.9472 - val_loss: 0.0389 - val_acc: 0.9479\n",
            "Epoch 583/700\n",
            "11983/11983 [==============================] - 2s 160us/sample - loss: 0.0419 - acc: 0.9438 - val_loss: 0.0378 - val_acc: 0.9506\n",
            "Epoch 584/700\n",
            "11983/11983 [==============================] - 2s 177us/sample - loss: 0.0425 - acc: 0.9428 - val_loss: 0.0370 - val_acc: 0.9506\n",
            "Epoch 585/700\n",
            "11983/11983 [==============================] - 2s 175us/sample - loss: 0.0422 - acc: 0.9461 - val_loss: 0.0379 - val_acc: 0.9493\n",
            "Epoch 586/700\n",
            "11983/11983 [==============================] - 2s 168us/sample - loss: 0.0414 - acc: 0.9464 - val_loss: 0.0375 - val_acc: 0.9499\n",
            "Epoch 587/700\n",
            "11983/11983 [==============================] - 2s 179us/sample - loss: 0.0423 - acc: 0.9443 - val_loss: 0.0383 - val_acc: 0.9496\n",
            "Epoch 588/700\n",
            "11983/11983 [==============================] - 2s 166us/sample - loss: 0.0427 - acc: 0.9450 - val_loss: 0.0372 - val_acc: 0.9506\n",
            "Epoch 589/700\n",
            "11983/11983 [==============================] - 2s 160us/sample - loss: 0.0426 - acc: 0.9441 - val_loss: 0.0370 - val_acc: 0.9509\n",
            "Epoch 590/700\n",
            "11983/11983 [==============================] - 2s 170us/sample - loss: 0.0420 - acc: 0.9441 - val_loss: 0.0373 - val_acc: 0.9496\n",
            "Epoch 591/700\n",
            "11983/11983 [==============================] - 2s 172us/sample - loss: 0.0402 - acc: 0.9472 - val_loss: 0.0376 - val_acc: 0.9496\n",
            "Epoch 592/700\n",
            "11983/11983 [==============================] - 2s 181us/sample - loss: 0.0415 - acc: 0.9458 - val_loss: 0.0376 - val_acc: 0.9493\n",
            "Epoch 593/700\n",
            "11983/11983 [==============================] - 2s 169us/sample - loss: 0.0417 - acc: 0.9463 - val_loss: 0.0380 - val_acc: 0.9509\n",
            "Epoch 594/700\n",
            "11983/11983 [==============================] - 2s 164us/sample - loss: 0.0416 - acc: 0.9457 - val_loss: 0.0379 - val_acc: 0.9493\n",
            "Epoch 595/700\n",
            "11983/11983 [==============================] - 2s 178us/sample - loss: 0.0418 - acc: 0.9461 - val_loss: 0.0375 - val_acc: 0.9499\n",
            "Epoch 596/700\n",
            "11983/11983 [==============================] - 2s 180us/sample - loss: 0.0415 - acc: 0.9461 - val_loss: 0.0382 - val_acc: 0.9496\n",
            "Epoch 597/700\n",
            "11983/11983 [==============================] - 2s 166us/sample - loss: 0.0411 - acc: 0.9445 - val_loss: 0.0370 - val_acc: 0.9509\n",
            "Epoch 598/700\n",
            "11983/11983 [==============================] - 2s 178us/sample - loss: 0.0424 - acc: 0.9441 - val_loss: 0.0368 - val_acc: 0.9523\n",
            "Epoch 599/700\n",
            "11983/11983 [==============================] - 2s 162us/sample - loss: 0.0422 - acc: 0.9447 - val_loss: 0.0370 - val_acc: 0.9523\n",
            "Epoch 600/700\n",
            "11983/11983 [==============================] - 2s 177us/sample - loss: 0.0425 - acc: 0.9438 - val_loss: 0.0374 - val_acc: 0.9499\n",
            "Epoch 601/700\n",
            "11983/11983 [==============================] - 2s 178us/sample - loss: 0.0422 - acc: 0.9440 - val_loss: 0.0377 - val_acc: 0.9499\n",
            "Epoch 602/700\n",
            "11983/11983 [==============================] - 2s 184us/sample - loss: 0.0425 - acc: 0.9458 - val_loss: 0.0383 - val_acc: 0.9476\n",
            "Epoch 603/700\n",
            "11983/11983 [==============================] - 2s 169us/sample - loss: 0.0415 - acc: 0.9469 - val_loss: 0.0370 - val_acc: 0.9496\n",
            "Epoch 604/700\n",
            "11983/11983 [==============================] - 2s 172us/sample - loss: 0.0418 - acc: 0.9458 - val_loss: 0.0375 - val_acc: 0.9519\n",
            "Epoch 605/700\n",
            "11983/11983 [==============================] - 2s 180us/sample - loss: 0.0428 - acc: 0.9457 - val_loss: 0.0379 - val_acc: 0.9493\n",
            "Epoch 606/700\n",
            "11983/11983 [==============================] - 2s 189us/sample - loss: 0.0402 - acc: 0.9478 - val_loss: 0.0372 - val_acc: 0.9529\n",
            "Epoch 607/700\n",
            "11983/11983 [==============================] - 2s 181us/sample - loss: 0.0381 - acc: 0.9513 - val_loss: 0.0366 - val_acc: 0.9519\n",
            "Epoch 608/700\n",
            "11983/11983 [==============================] - 2s 175us/sample - loss: 0.0408 - acc: 0.9475 - val_loss: 0.0365 - val_acc: 0.9519\n",
            "Epoch 609/700\n",
            "11983/11983 [==============================] - 2s 174us/sample - loss: 0.0414 - acc: 0.9465 - val_loss: 0.0369 - val_acc: 0.9516\n",
            "Epoch 610/700\n",
            "11983/11983 [==============================] - 2s 161us/sample - loss: 0.0401 - acc: 0.9478 - val_loss: 0.0364 - val_acc: 0.9516\n",
            "Epoch 611/700\n",
            "11983/11983 [==============================] - 2s 176us/sample - loss: 0.0418 - acc: 0.9459 - val_loss: 0.0373 - val_acc: 0.9483\n",
            "Epoch 612/700\n",
            "11983/11983 [==============================] - 2s 166us/sample - loss: 0.0417 - acc: 0.9449 - val_loss: 0.0377 - val_acc: 0.9486\n",
            "Epoch 613/700\n",
            "11983/11983 [==============================] - 2s 183us/sample - loss: 0.0412 - acc: 0.9478 - val_loss: 0.0374 - val_acc: 0.9519\n",
            "Epoch 614/700\n",
            "11983/11983 [==============================] - 2s 173us/sample - loss: 0.0407 - acc: 0.9475 - val_loss: 0.0369 - val_acc: 0.9499\n",
            "Epoch 615/700\n",
            "11983/11983 [==============================] - 2s 179us/sample - loss: 0.0411 - acc: 0.9475 - val_loss: 0.0373 - val_acc: 0.9529\n",
            "Epoch 616/700\n",
            "11983/11983 [==============================] - 2s 180us/sample - loss: 0.0433 - acc: 0.9430 - val_loss: 0.0367 - val_acc: 0.9519\n",
            "Epoch 617/700\n",
            "11983/11983 [==============================] - 2s 177us/sample - loss: 0.0405 - acc: 0.9488 - val_loss: 0.0365 - val_acc: 0.9536\n",
            "Epoch 618/700\n",
            "11983/11983 [==============================] - 2s 168us/sample - loss: 0.0423 - acc: 0.9443 - val_loss: 0.0369 - val_acc: 0.9516\n",
            "Epoch 619/700\n",
            "11983/11983 [==============================] - 2s 161us/sample - loss: 0.0396 - acc: 0.9493 - val_loss: 0.0373 - val_acc: 0.9509\n",
            "Epoch 620/700\n",
            "11983/11983 [==============================] - 2s 157us/sample - loss: 0.0416 - acc: 0.9460 - val_loss: 0.0367 - val_acc: 0.9506\n",
            "Epoch 621/700\n",
            "11983/11983 [==============================] - 2s 168us/sample - loss: 0.0404 - acc: 0.9473 - val_loss: 0.0365 - val_acc: 0.9516\n",
            "Epoch 622/700\n",
            "11983/11983 [==============================] - 2s 175us/sample - loss: 0.0408 - acc: 0.9475 - val_loss: 0.0368 - val_acc: 0.9506\n",
            "Epoch 623/700\n",
            "11983/11983 [==============================] - 2s 170us/sample - loss: 0.0409 - acc: 0.9455 - val_loss: 0.0380 - val_acc: 0.9479\n",
            "Epoch 624/700\n",
            "11983/11983 [==============================] - 2s 181us/sample - loss: 0.0392 - acc: 0.9502 - val_loss: 0.0371 - val_acc: 0.9513\n",
            "Epoch 625/700\n",
            "11983/11983 [==============================] - 2s 182us/sample - loss: 0.0404 - acc: 0.9488 - val_loss: 0.0373 - val_acc: 0.9503\n",
            "Epoch 626/700\n",
            "11983/11983 [==============================] - 2s 176us/sample - loss: 0.0397 - acc: 0.9463 - val_loss: 0.0365 - val_acc: 0.9533\n",
            "Epoch 627/700\n",
            "11983/11983 [==============================] - 2s 181us/sample - loss: 0.0416 - acc: 0.9455 - val_loss: 0.0377 - val_acc: 0.9519\n",
            "Epoch 628/700\n",
            "11983/11983 [==============================] - 2s 182us/sample - loss: 0.0412 - acc: 0.9466 - val_loss: 0.0365 - val_acc: 0.9533\n",
            "Epoch 629/700\n",
            "11983/11983 [==============================] - 2s 188us/sample - loss: 0.0418 - acc: 0.9470 - val_loss: 0.0364 - val_acc: 0.9516\n",
            "Epoch 630/700\n",
            "11983/11983 [==============================] - 2s 173us/sample - loss: 0.0419 - acc: 0.9448 - val_loss: 0.0371 - val_acc: 0.9496\n",
            "Epoch 631/700\n",
            "11983/11983 [==============================] - 2s 175us/sample - loss: 0.0416 - acc: 0.9446 - val_loss: 0.0360 - val_acc: 0.9516\n",
            "Epoch 632/700\n",
            "11983/11983 [==============================] - 2s 169us/sample - loss: 0.0409 - acc: 0.9459 - val_loss: 0.0360 - val_acc: 0.9543\n",
            "Epoch 633/700\n",
            "11983/11983 [==============================] - 2s 173us/sample - loss: 0.0409 - acc: 0.9461 - val_loss: 0.0362 - val_acc: 0.9516\n",
            "Epoch 634/700\n",
            "11983/11983 [==============================] - 2s 179us/sample - loss: 0.0400 - acc: 0.9477 - val_loss: 0.0364 - val_acc: 0.9513\n",
            "Epoch 635/700\n",
            "11983/11983 [==============================] - 2s 176us/sample - loss: 0.0405 - acc: 0.9465 - val_loss: 0.0372 - val_acc: 0.9496\n",
            "Epoch 636/700\n",
            "11983/11983 [==============================] - 2s 172us/sample - loss: 0.0397 - acc: 0.9463 - val_loss: 0.0371 - val_acc: 0.9523\n",
            "Epoch 637/700\n",
            "11983/11983 [==============================] - 2s 164us/sample - loss: 0.0401 - acc: 0.9473 - val_loss: 0.0360 - val_acc: 0.9529\n",
            "Epoch 638/700\n",
            "11983/11983 [==============================] - 2s 181us/sample - loss: 0.0398 - acc: 0.9490 - val_loss: 0.0368 - val_acc: 0.9526\n",
            "Epoch 639/700\n",
            "11983/11983 [==============================] - 2s 168us/sample - loss: 0.0405 - acc: 0.9478 - val_loss: 0.0372 - val_acc: 0.9513\n",
            "Epoch 640/700\n",
            "11983/11983 [==============================] - 2s 184us/sample - loss: 0.0407 - acc: 0.9458 - val_loss: 0.0363 - val_acc: 0.9533\n",
            "Epoch 641/700\n",
            "11983/11983 [==============================] - 2s 170us/sample - loss: 0.0408 - acc: 0.9457 - val_loss: 0.0365 - val_acc: 0.9523\n",
            "Epoch 642/700\n",
            "11983/11983 [==============================] - 2s 184us/sample - loss: 0.0404 - acc: 0.9469 - val_loss: 0.0361 - val_acc: 0.9556\n",
            "Epoch 643/700\n",
            "11983/11983 [==============================] - 2s 169us/sample - loss: 0.0407 - acc: 0.9478 - val_loss: 0.0372 - val_acc: 0.9503\n",
            "Epoch 644/700\n",
            "11983/11983 [==============================] - 2s 178us/sample - loss: 0.0401 - acc: 0.9471 - val_loss: 0.0369 - val_acc: 0.9493\n",
            "Epoch 645/700\n",
            "11983/11983 [==============================] - 2s 189us/sample - loss: 0.0401 - acc: 0.9468 - val_loss: 0.0372 - val_acc: 0.9503\n",
            "Epoch 646/700\n",
            "11983/11983 [==============================] - 2s 175us/sample - loss: 0.0413 - acc: 0.9460 - val_loss: 0.0365 - val_acc: 0.9519\n",
            "Epoch 647/700\n",
            "11983/11983 [==============================] - 2s 173us/sample - loss: 0.0405 - acc: 0.9472 - val_loss: 0.0367 - val_acc: 0.9489\n",
            "Epoch 648/700\n",
            "11983/11983 [==============================] - 2s 168us/sample - loss: 0.0411 - acc: 0.9473 - val_loss: 0.0366 - val_acc: 0.9509\n",
            "Epoch 649/700\n",
            "11983/11983 [==============================] - 2s 166us/sample - loss: 0.0410 - acc: 0.9472 - val_loss: 0.0363 - val_acc: 0.9513\n",
            "Epoch 650/700\n",
            "11983/11983 [==============================] - 2s 160us/sample - loss: 0.0398 - acc: 0.9478 - val_loss: 0.0356 - val_acc: 0.9533\n",
            "Epoch 651/700\n",
            "11983/11983 [==============================] - 2s 175us/sample - loss: 0.0428 - acc: 0.9424 - val_loss: 0.0366 - val_acc: 0.9533\n",
            "Epoch 652/700\n",
            "11983/11983 [==============================] - 2s 170us/sample - loss: 0.0408 - acc: 0.9480 - val_loss: 0.0361 - val_acc: 0.9533\n",
            "Epoch 653/700\n",
            "11983/11983 [==============================] - 2s 171us/sample - loss: 0.0402 - acc: 0.9459 - val_loss: 0.0361 - val_acc: 0.9539\n",
            "Epoch 654/700\n",
            "11983/11983 [==============================] - 2s 180us/sample - loss: 0.0401 - acc: 0.9475 - val_loss: 0.0358 - val_acc: 0.9526\n",
            "Epoch 655/700\n",
            "11983/11983 [==============================] - 2s 172us/sample - loss: 0.0393 - acc: 0.9489 - val_loss: 0.0359 - val_acc: 0.9509\n",
            "Epoch 656/700\n",
            "11983/11983 [==============================] - 2s 167us/sample - loss: 0.0400 - acc: 0.9478 - val_loss: 0.0352 - val_acc: 0.9536\n",
            "Epoch 657/700\n",
            "11983/11983 [==============================] - 2s 188us/sample - loss: 0.0409 - acc: 0.9464 - val_loss: 0.0363 - val_acc: 0.9526\n",
            "Epoch 658/700\n",
            "11983/11983 [==============================] - 2s 164us/sample - loss: 0.0403 - acc: 0.9496 - val_loss: 0.0363 - val_acc: 0.9523\n",
            "Epoch 659/700\n",
            "11983/11983 [==============================] - 2s 188us/sample - loss: 0.0406 - acc: 0.9468 - val_loss: 0.0358 - val_acc: 0.9529\n",
            "Epoch 660/700\n",
            "11983/11983 [==============================] - 2s 171us/sample - loss: 0.0393 - acc: 0.9488 - val_loss: 0.0350 - val_acc: 0.9549\n",
            "Epoch 661/700\n",
            "11983/11983 [==============================] - 2s 173us/sample - loss: 0.0407 - acc: 0.9467 - val_loss: 0.0360 - val_acc: 0.9549\n",
            "Epoch 662/700\n",
            "11983/11983 [==============================] - 2s 184us/sample - loss: 0.0410 - acc: 0.9470 - val_loss: 0.0364 - val_acc: 0.9526\n",
            "Epoch 663/700\n",
            "11983/11983 [==============================] - 2s 157us/sample - loss: 0.0395 - acc: 0.9500 - val_loss: 0.0371 - val_acc: 0.9489\n",
            "Epoch 664/700\n",
            "11983/11983 [==============================] - 2s 164us/sample - loss: 0.0390 - acc: 0.9482 - val_loss: 0.0369 - val_acc: 0.9509\n",
            "Epoch 665/700\n",
            "11983/11983 [==============================] - 2s 177us/sample - loss: 0.0407 - acc: 0.9473 - val_loss: 0.0364 - val_acc: 0.9523\n",
            "Epoch 666/700\n",
            "11983/11983 [==============================] - 2s 157us/sample - loss: 0.0385 - acc: 0.9503 - val_loss: 0.0360 - val_acc: 0.9536\n",
            "Epoch 667/700\n",
            "11983/11983 [==============================] - 2s 179us/sample - loss: 0.0404 - acc: 0.9463 - val_loss: 0.0361 - val_acc: 0.9536\n",
            "Epoch 668/700\n",
            "11983/11983 [==============================] - 2s 160us/sample - loss: 0.0387 - acc: 0.9503 - val_loss: 0.0367 - val_acc: 0.9523\n",
            "Epoch 669/700\n",
            "11983/11983 [==============================] - 2s 162us/sample - loss: 0.0385 - acc: 0.9505 - val_loss: 0.0366 - val_acc: 0.9529\n",
            "Epoch 670/700\n",
            "11983/11983 [==============================] - 2s 178us/sample - loss: 0.0387 - acc: 0.9485 - val_loss: 0.0365 - val_acc: 0.9503\n",
            "Epoch 671/700\n",
            "11983/11983 [==============================] - 2s 168us/sample - loss: 0.0406 - acc: 0.9459 - val_loss: 0.0362 - val_acc: 0.9526\n",
            "Epoch 672/700\n",
            "11983/11983 [==============================] - 2s 168us/sample - loss: 0.0403 - acc: 0.9487 - val_loss: 0.0375 - val_acc: 0.9499\n",
            "Epoch 673/700\n",
            "11983/11983 [==============================] - 2s 175us/sample - loss: 0.0381 - acc: 0.9505 - val_loss: 0.0375 - val_acc: 0.9476\n",
            "Epoch 674/700\n",
            "11983/11983 [==============================] - 2s 176us/sample - loss: 0.0391 - acc: 0.9501 - val_loss: 0.0362 - val_acc: 0.9506\n",
            "Epoch 675/700\n",
            "11983/11983 [==============================] - 2s 170us/sample - loss: 0.0377 - acc: 0.9513 - val_loss: 0.0353 - val_acc: 0.9533\n",
            "Epoch 676/700\n",
            "11983/11983 [==============================] - 2s 166us/sample - loss: 0.0393 - acc: 0.9493 - val_loss: 0.0363 - val_acc: 0.9516\n",
            "Epoch 677/700\n",
            "11983/11983 [==============================] - 2s 165us/sample - loss: 0.0390 - acc: 0.9508 - val_loss: 0.0367 - val_acc: 0.9519\n",
            "Epoch 678/700\n",
            "11983/11983 [==============================] - 2s 181us/sample - loss: 0.0387 - acc: 0.9495 - val_loss: 0.0355 - val_acc: 0.9523\n",
            "Epoch 679/700\n",
            "11983/11983 [==============================] - 2s 175us/sample - loss: 0.0396 - acc: 0.9494 - val_loss: 0.0371 - val_acc: 0.9506\n",
            "Epoch 680/700\n",
            "11983/11983 [==============================] - 2s 182us/sample - loss: 0.0386 - acc: 0.9498 - val_loss: 0.0360 - val_acc: 0.9539\n",
            "Epoch 681/700\n",
            "11983/11983 [==============================] - 2s 165us/sample - loss: 0.0390 - acc: 0.9497 - val_loss: 0.0364 - val_acc: 0.9519\n",
            "Epoch 682/700\n",
            "11983/11983 [==============================] - 2s 168us/sample - loss: 0.0393 - acc: 0.9498 - val_loss: 0.0363 - val_acc: 0.9529\n",
            "Epoch 683/700\n",
            "11983/11983 [==============================] - 2s 177us/sample - loss: 0.0381 - acc: 0.9505 - val_loss: 0.0362 - val_acc: 0.9519\n",
            "Epoch 684/700\n",
            "11983/11983 [==============================] - 2s 173us/sample - loss: 0.0388 - acc: 0.9485 - val_loss: 0.0356 - val_acc: 0.9553\n",
            "Epoch 685/700\n",
            "11983/11983 [==============================] - 2s 174us/sample - loss: 0.0399 - acc: 0.9470 - val_loss: 0.0353 - val_acc: 0.9556\n",
            "Epoch 686/700\n",
            "11983/11983 [==============================] - 2s 179us/sample - loss: 0.0398 - acc: 0.9492 - val_loss: 0.0357 - val_acc: 0.9543\n",
            "Epoch 687/700\n",
            "11983/11983 [==============================] - 2s 171us/sample - loss: 0.0384 - acc: 0.9518 - val_loss: 0.0362 - val_acc: 0.9536\n",
            "Epoch 688/700\n",
            "11983/11983 [==============================] - 2s 171us/sample - loss: 0.0406 - acc: 0.9450 - val_loss: 0.0356 - val_acc: 0.9529\n",
            "Epoch 689/700\n",
            "11983/11983 [==============================] - 2s 165us/sample - loss: 0.0408 - acc: 0.9458 - val_loss: 0.0362 - val_acc: 0.9533\n",
            "Epoch 690/700\n",
            "11983/11983 [==============================] - 2s 184us/sample - loss: 0.0385 - acc: 0.9498 - val_loss: 0.0355 - val_acc: 0.9539\n",
            "Epoch 691/700\n",
            "11983/11983 [==============================] - 2s 170us/sample - loss: 0.0396 - acc: 0.9486 - val_loss: 0.0351 - val_acc: 0.9559\n",
            "Epoch 692/700\n",
            "11983/11983 [==============================] - 2s 165us/sample - loss: 0.0394 - acc: 0.9488 - val_loss: 0.0354 - val_acc: 0.9533\n",
            "Epoch 693/700\n",
            "11983/11983 [==============================] - 2s 169us/sample - loss: 0.0396 - acc: 0.9476 - val_loss: 0.0355 - val_acc: 0.9539\n",
            "Epoch 694/700\n",
            "11983/11983 [==============================] - 2s 161us/sample - loss: 0.0410 - acc: 0.9459 - val_loss: 0.0366 - val_acc: 0.9516\n",
            "Epoch 695/700\n",
            "11983/11983 [==============================] - 2s 172us/sample - loss: 0.0392 - acc: 0.9493 - val_loss: 0.0362 - val_acc: 0.9539\n",
            "Epoch 696/700\n",
            "11983/11983 [==============================] - 2s 176us/sample - loss: 0.0406 - acc: 0.9480 - val_loss: 0.0364 - val_acc: 0.9516\n",
            "Epoch 697/700\n",
            "11983/11983 [==============================] - 2s 180us/sample - loss: 0.0397 - acc: 0.9498 - val_loss: 0.0357 - val_acc: 0.9529\n",
            "Epoch 698/700\n",
            "11983/11983 [==============================] - 2s 184us/sample - loss: 0.0384 - acc: 0.9510 - val_loss: 0.0362 - val_acc: 0.9536\n",
            "Epoch 699/700\n",
            "11983/11983 [==============================] - 2s 175us/sample - loss: 0.0384 - acc: 0.9507 - val_loss: 0.0355 - val_acc: 0.9533\n",
            "Epoch 700/700\n",
            "11983/11983 [==============================] - 2s 185us/sample - loss: 0.0396 - acc: 0.9488 - val_loss: 0.0356 - val_acc: 0.9529\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBeKDuPHzmsf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "train_loss_list.append(loss[-1])\n",
        "val_loss_list.append(val_loss[-1])\n",
        "\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "epoch = range(1,len(loss)+1)\n",
        "\n",
        "train_accuracy_list.append(acc[-1])\n",
        "val_accuracy_list.append(val_acc[-1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GD2OrFha0c-N",
        "colab_type": "code",
        "outputId": "5c540a20-ddfd-4cba-b794-7c017f36ea53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "#print(\"Number of run \" + str(run))\n",
        "print(\"Train loss \" + loss[-1].astype(str))\n",
        "print(\"Validation loss \" + val_loss[-1].astype(str))\n",
        "print(\"Train accuracy \" + acc[-1].astype(str))\n",
        "print(\"Validation accuracy \" + val_acc[-1].astype(str))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train loss 0.03960783818916517\n",
            "Validation loss 0.03564444231553294\n",
            "Train accuracy 0.94876075\n",
            "Validation accuracy 0.95293725\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NstWgRess_rX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train'], loc='upper left')\n",
        "\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spY91H0Ss_oh",
        "colab_type": "code",
        "outputId": "4a33c8bf-0ef7-4cf1-df59-09d83731eb65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "a=2\n",
        "a"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jp_tEEVs_g6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GsIdHzwm0dBU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_val = [x for x in range(1, 51)]\n",
        "plt.figure()\n",
        "plt.plot(x_val, acc,'bo', label= 'Training accuracy')\n",
        "plt.plot(x_val, val_acc,'b', label= 'Validation accuracy')\n",
        "plt.title('Training and Validation accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(x_val, loss,'bo', label= 'Training loss')\n",
        "plt.plot(x_val, val_loss,'b', label= 'Validation loss')\n",
        "plt.title('Training and Validation loss')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHxT_Rm-0i_S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure()\n",
        "plt.plot(x_values,train_accuracy_list,'bo',label= 'Training accuracy per run')\n",
        "plt.plot(x_values,val_accuracy_list,'b',label= 'Validation accuracy per run')\n",
        "plt.title('Training and Validation accuracy per run')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(x_values,train_loss_list,'bo',label= 'Training loss per run')\n",
        "plt.plot(x_values,val_loss_list,'b',label= 'Validation loss per run')\n",
        "plt.title('Training and Validation loss per run')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "average_train_loss = sum(train_loss_list, 0.0)/len(train_loss_list)\n",
        "average_train_accuracy = sum(train_accuracy_list, 0.0)/len(train_accuracy_list)\n",
        "print(\"Average train loss \" + average_train_loss.astype(str))\n",
        "print(\"Average train accuracy \" + average_train_accuracy.astype(str))\n",
        "\n",
        "average_val_loss = sum(val_loss_list, 0.0)/len(val_loss_list)\n",
        "average_val_accuracy = sum(val_accuracy_list, 0.0)/len(val_accuracy_list)\n",
        "print(\"Average val loss \" + average_val_loss.astype(str))\n",
        "print(\"Average val accuracy \" + average_val_accuracy.astype(str))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4D_ZZl9e0jCk",
        "colab_type": "code",
        "outputId": "2128f823-1e21-4e46-e4a6-123cc07e1100",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "a=2\n",
        "a"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkORNYSOXimC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}