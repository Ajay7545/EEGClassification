{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model2lstm.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aof-LJk1kVGl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1uCyK0FpS5h",
        "colab_type": "code",
        "outputId": "a53ad796-88fc-41ed-b13e-ac5ade579872",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "source": [
        "\n",
        "from random import shuffle\n",
        "\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import io\n",
        "import numpy as np\n",
        "import os\n",
        "import collections\n",
        "\n",
        "from tensor2tensor import models\n",
        "from tensor2tensor import problems\n",
        "from tensor2tensor.layers import common_layers\n",
        "from tensor2tensor.utils import trainer_lib\n",
        "from tensor2tensor.utils import t2t_model\n",
        "from tensor2tensor.utils import registry\n",
        "from tensor2tensor.utils import metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.python import keras\n",
        "from tensorflow.python.keras.models import Sequential, Model\n",
        "from tensorflow.python.keras.layers import Input, Dense, core,TimeDistributed,AveragePooling1D\n",
        "\n",
        "from tensorflow.python.keras.layers import LSTM, Dense, Dropout, Activation\n",
        "from sklearn.preprocessing import minmax_scale\n",
        "from sklearn import preprocessing\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from pandas import read_csv\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from numpy import delete\n",
        "from numpy import savetxt\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0624 06:59:17.931348 140177937680256 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/tensor2tensor/utils/expert_utils.py:68: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "W0624 06:59:22.611491 140177937680256 lazy_loader.py:50] \n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "W0624 06:59:29.115647 140177937680256 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/tensor2tensor/utils/adafactor.py:27: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0624 06:59:29.118603 140177937680256 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/tensor2tensor/utils/multistep_optimizer.py:32: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
            "\n",
            "W0624 06:59:29.674315 140177937680256 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/mesh_tensorflow/ops.py:4237: The name tf.train.CheckpointSaverListener is deprecated. Please use tf.estimator.CheckpointSaverListener instead.\n",
            "\n",
            "W0624 06:59:29.678962 140177937680256 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/mesh_tensorflow/ops.py:4260: The name tf.train.SessionRunHook is deprecated. Please use tf.estimator.SessionRunHook instead.\n",
            "\n",
            "W0624 06:59:30.019173 140177937680256 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/tensor2tensor/utils/trainer_lib.py:105: The name tf.OptimizerOptions is deprecated. Please use tf.compat.v1.OptimizerOptions instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2VWoKT-pZr7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TNThn6FpvLw",
        "colab_type": "code",
        "outputId": "1f8ed0b2-87b2-4c1b-df97-12a64024253c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df1.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14979, 15)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QtNSBpcAqdV1",
        "colab_type": "code",
        "outputId": "0ff3b542-79b9-4ebe-b3b8-27de5601ed90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        }
      },
      "source": [
        "df=pd.read_csv('drive/My Drive/COLAB Files/EEG Eye State.csv')\n",
        "df.columns = ['A','B','C','D','E','F','G','H','I','J','K','L','M','N','O']\n",
        "df.head(2)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>A</th>\n",
              "      <th>B</th>\n",
              "      <th>C</th>\n",
              "      <th>D</th>\n",
              "      <th>E</th>\n",
              "      <th>F</th>\n",
              "      <th>G</th>\n",
              "      <th>H</th>\n",
              "      <th>I</th>\n",
              "      <th>J</th>\n",
              "      <th>K</th>\n",
              "      <th>L</th>\n",
              "      <th>M</th>\n",
              "      <th>N</th>\n",
              "      <th>O</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4324.62</td>\n",
              "      <td>4004.62</td>\n",
              "      <td>4293.85</td>\n",
              "      <td>4148.72</td>\n",
              "      <td>4342.05</td>\n",
              "      <td>4586.67</td>\n",
              "      <td>4097.44</td>\n",
              "      <td>4638.97</td>\n",
              "      <td>4210.77</td>\n",
              "      <td>4226.67</td>\n",
              "      <td>4207.69</td>\n",
              "      <td>4279.49</td>\n",
              "      <td>4632.82</td>\n",
              "      <td>4384.10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4327.69</td>\n",
              "      <td>4006.67</td>\n",
              "      <td>4295.38</td>\n",
              "      <td>4156.41</td>\n",
              "      <td>4336.92</td>\n",
              "      <td>4583.59</td>\n",
              "      <td>4096.92</td>\n",
              "      <td>4630.26</td>\n",
              "      <td>4207.69</td>\n",
              "      <td>4222.05</td>\n",
              "      <td>4206.67</td>\n",
              "      <td>4282.05</td>\n",
              "      <td>4628.72</td>\n",
              "      <td>4389.23</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         A        B        C        D  ...        L        M        N  O\n",
              "0  4324.62  4004.62  4293.85  4148.72  ...  4279.49  4632.82  4384.10  0\n",
              "1  4327.69  4006.67  4295.38  4156.41  ...  4282.05  4628.72  4389.23  0\n",
              "\n",
              "[2 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blUKoJQprS5v",
        "colab_type": "code",
        "outputId": "f3a5bae9-4621-4806-ca8b-c8c0de0a90e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14979, 15)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUZ3skFusfsw",
        "colab_type": "code",
        "outputId": "bd2f6248-53e5-465e-f3e8-c1dca32d8cd2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "y=df['O']\n",
        "print(len(y))\n",
        "print(y.shape)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "14979\n",
            "(14979,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kAdzPlbosrR7",
        "colab_type": "code",
        "outputId": "cce92776-2191-406a-cd68-b2d8ab9de35b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "df.drop(['O'], axis = 1, inplace = True)\n",
        "df.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>A</th>\n",
              "      <th>B</th>\n",
              "      <th>C</th>\n",
              "      <th>D</th>\n",
              "      <th>E</th>\n",
              "      <th>F</th>\n",
              "      <th>G</th>\n",
              "      <th>H</th>\n",
              "      <th>I</th>\n",
              "      <th>J</th>\n",
              "      <th>K</th>\n",
              "      <th>L</th>\n",
              "      <th>M</th>\n",
              "      <th>N</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4324.62</td>\n",
              "      <td>4004.62</td>\n",
              "      <td>4293.85</td>\n",
              "      <td>4148.72</td>\n",
              "      <td>4342.05</td>\n",
              "      <td>4586.67</td>\n",
              "      <td>4097.44</td>\n",
              "      <td>4638.97</td>\n",
              "      <td>4210.77</td>\n",
              "      <td>4226.67</td>\n",
              "      <td>4207.69</td>\n",
              "      <td>4279.49</td>\n",
              "      <td>4632.82</td>\n",
              "      <td>4384.10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4327.69</td>\n",
              "      <td>4006.67</td>\n",
              "      <td>4295.38</td>\n",
              "      <td>4156.41</td>\n",
              "      <td>4336.92</td>\n",
              "      <td>4583.59</td>\n",
              "      <td>4096.92</td>\n",
              "      <td>4630.26</td>\n",
              "      <td>4207.69</td>\n",
              "      <td>4222.05</td>\n",
              "      <td>4206.67</td>\n",
              "      <td>4282.05</td>\n",
              "      <td>4628.72</td>\n",
              "      <td>4389.23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4328.72</td>\n",
              "      <td>4011.79</td>\n",
              "      <td>4296.41</td>\n",
              "      <td>4155.90</td>\n",
              "      <td>4343.59</td>\n",
              "      <td>4582.56</td>\n",
              "      <td>4097.44</td>\n",
              "      <td>4630.77</td>\n",
              "      <td>4217.44</td>\n",
              "      <td>4235.38</td>\n",
              "      <td>4210.77</td>\n",
              "      <td>4287.69</td>\n",
              "      <td>4632.31</td>\n",
              "      <td>4396.41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4326.15</td>\n",
              "      <td>4011.79</td>\n",
              "      <td>4292.31</td>\n",
              "      <td>4151.28</td>\n",
              "      <td>4347.69</td>\n",
              "      <td>4586.67</td>\n",
              "      <td>4095.90</td>\n",
              "      <td>4627.69</td>\n",
              "      <td>4210.77</td>\n",
              "      <td>4244.10</td>\n",
              "      <td>4212.82</td>\n",
              "      <td>4288.21</td>\n",
              "      <td>4632.82</td>\n",
              "      <td>4398.46</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4321.03</td>\n",
              "      <td>4004.62</td>\n",
              "      <td>4284.10</td>\n",
              "      <td>4153.33</td>\n",
              "      <td>4345.64</td>\n",
              "      <td>4587.18</td>\n",
              "      <td>4093.33</td>\n",
              "      <td>4616.92</td>\n",
              "      <td>4202.56</td>\n",
              "      <td>4232.82</td>\n",
              "      <td>4209.74</td>\n",
              "      <td>4281.03</td>\n",
              "      <td>4628.21</td>\n",
              "      <td>4389.74</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         A        B        C        D  ...        K        L        M        N\n",
              "0  4324.62  4004.62  4293.85  4148.72  ...  4207.69  4279.49  4632.82  4384.10\n",
              "1  4327.69  4006.67  4295.38  4156.41  ...  4206.67  4282.05  4628.72  4389.23\n",
              "2  4328.72  4011.79  4296.41  4155.90  ...  4210.77  4287.69  4632.31  4396.41\n",
              "3  4326.15  4011.79  4292.31  4151.28  ...  4212.82  4288.21  4632.82  4398.46\n",
              "4  4321.03  4004.62  4284.10  4153.33  ...  4209.74  4281.03  4628.21  4389.74\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_h4KfOC0tBur",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#inputs = datalist[:, :-1]\n",
        "#output = datalist[:, -1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s44qKilqtxGm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_runs = 10\n",
        "num_runs = num_runs + 1\n",
        "\n",
        "train_loss_list = []\n",
        "train_accuracy_list = []\n",
        "\n",
        "val_loss_list = []\n",
        "val_accuracy_list = []\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQ8bEUXYvPaB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGSWkRumtxKj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmyJlLOMtxYN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKeWhot4txbN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Train_inputs, Test_inputs, train_output, test_output = train_test_split(df,y, test_size=0.20, shuffle=True, random_state=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UghiA9YvtxFV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "std_scale = preprocessing.StandardScaler().fit(Train_inputs)\n",
        "train_inputs = std_scale.transform(Train_inputs)\n",
        "test_inputs = std_scale.transform(Test_inputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a94hdCyYv6VN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "trintf=np.asarray(train_inputs)\n",
        "trouttf=np.asarray(train_output)\n",
        "tsintf=np.asarray(test_inputs)\n",
        "tsouttf=np.asarray(test_output)\n",
        "\n",
        "#train_inputs_tf = tf.convert_to_tensor(train_inputs, np.float32)\n",
        "#train_output_tf = tf.convert_to_tensor(train_output, np.float32)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pd5wzqQtyx37",
        "colab_type": "code",
        "outputId": "a9befe00-cb79-4abc-8a01-bf7dbb262c3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(trintf.shape)\n",
        "print(11983*14)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(11983, 14)\n",
            "167762\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLHPy3bLyx0h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6AVrFdn0yxy0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0lk3qO8Rv6Y-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "trintf=trintf.reshape(11983,1,14)\n",
        "trouttf=trouttf.reshape(11983,1,1)\n",
        "tsintf=tsintf.reshape(2996,1,14)\n",
        "tsouttf=tsouttf.reshape(2996,1,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4yEv0tuAv6by",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 1\n",
        "training_split = 0.25\n",
        "num_fields = 14"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMWJ_L3SzSqJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(100,return_sequences=True,implementation=2))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(LSTM(100,return_sequences=True,implementation=2))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='mean_squared_error', optimizer='rmsprop', metrics=['accuracy'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYc2C0uBzStI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ObrEK8-Kv6TA",
        "colab_type": "code",
        "outputId": "18612cad-3092-4aa8-fe35-c9b7e3b273c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17054
        }
      },
      "source": [
        "history = model.fit(trintf, trouttf, epochs=500, batch_size= 128,verbose=1,validation_data=(tsintf, tsouttf))\n"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 11983 samples, validate on 2996 samples\n",
            "Epoch 1/500\n",
            "11983/11983 [==============================] - 1s 71us/sample - loss: 0.0447 - acc: 0.9419 - val_loss: 0.0408 - val_acc: 0.9476\n",
            "Epoch 2/500\n",
            "11983/11983 [==============================] - 1s 74us/sample - loss: 0.0450 - acc: 0.9399 - val_loss: 0.0407 - val_acc: 0.9473\n",
            "Epoch 3/500\n",
            "11983/11983 [==============================] - 1s 75us/sample - loss: 0.0436 - acc: 0.9426 - val_loss: 0.0400 - val_acc: 0.9486\n",
            "Epoch 4/500\n",
            "11983/11983 [==============================] - 1s 72us/sample - loss: 0.0447 - acc: 0.9427 - val_loss: 0.0407 - val_acc: 0.9469\n",
            "Epoch 5/500\n",
            "11983/11983 [==============================] - 1s 75us/sample - loss: 0.0446 - acc: 0.9415 - val_loss: 0.0409 - val_acc: 0.9469\n",
            "Epoch 6/500\n",
            "11983/11983 [==============================] - 1s 75us/sample - loss: 0.0450 - acc: 0.9401 - val_loss: 0.0406 - val_acc: 0.9476\n",
            "Epoch 7/500\n",
            "11983/11983 [==============================] - 1s 76us/sample - loss: 0.0452 - acc: 0.9396 - val_loss: 0.0408 - val_acc: 0.9473\n",
            "Epoch 8/500\n",
            "11983/11983 [==============================] - 1s 73us/sample - loss: 0.0449 - acc: 0.9425 - val_loss: 0.0409 - val_acc: 0.9476\n",
            "Epoch 9/500\n",
            "11983/11983 [==============================] - 1s 71us/sample - loss: 0.0436 - acc: 0.9416 - val_loss: 0.0411 - val_acc: 0.9466\n",
            "Epoch 10/500\n",
            "11983/11983 [==============================] - 1s 74us/sample - loss: 0.0435 - acc: 0.9418 - val_loss: 0.0415 - val_acc: 0.9453\n",
            "Epoch 11/500\n",
            "11983/11983 [==============================] - 1s 74us/sample - loss: 0.0450 - acc: 0.9412 - val_loss: 0.0413 - val_acc: 0.9456\n",
            "Epoch 12/500\n",
            "11983/11983 [==============================] - 1s 72us/sample - loss: 0.0437 - acc: 0.9440 - val_loss: 0.0415 - val_acc: 0.9476\n",
            "Epoch 13/500\n",
            "11983/11983 [==============================] - 1s 74us/sample - loss: 0.0441 - acc: 0.9410 - val_loss: 0.0407 - val_acc: 0.9479\n",
            "Epoch 14/500\n",
            "11983/11983 [==============================] - 1s 74us/sample - loss: 0.0422 - acc: 0.9447 - val_loss: 0.0409 - val_acc: 0.9453\n",
            "Epoch 15/500\n",
            "11983/11983 [==============================] - 1s 71us/sample - loss: 0.0431 - acc: 0.9453 - val_loss: 0.0406 - val_acc: 0.9476\n",
            "Epoch 16/500\n",
            "11983/11983 [==============================] - 1s 71us/sample - loss: 0.0442 - acc: 0.9419 - val_loss: 0.0406 - val_acc: 0.9479\n",
            "Epoch 17/500\n",
            "11983/11983 [==============================] - 1s 73us/sample - loss: 0.0442 - acc: 0.9422 - val_loss: 0.0403 - val_acc: 0.9466\n",
            "Epoch 18/500\n",
            "11983/11983 [==============================] - 1s 72us/sample - loss: 0.0428 - acc: 0.9441 - val_loss: 0.0405 - val_acc: 0.9456\n",
            "Epoch 19/500\n",
            "11983/11983 [==============================] - 1s 71us/sample - loss: 0.0448 - acc: 0.9417 - val_loss: 0.0408 - val_acc: 0.9466\n",
            "Epoch 20/500\n",
            "11983/11983 [==============================] - 1s 69us/sample - loss: 0.0449 - acc: 0.9409 - val_loss: 0.0395 - val_acc: 0.9489\n",
            "Epoch 21/500\n",
            "11983/11983 [==============================] - 1s 71us/sample - loss: 0.0449 - acc: 0.9405 - val_loss: 0.0404 - val_acc: 0.9483\n",
            "Epoch 22/500\n",
            "11983/11983 [==============================] - 1s 70us/sample - loss: 0.0440 - acc: 0.9440 - val_loss: 0.0404 - val_acc: 0.9463\n",
            "Epoch 23/500\n",
            "11983/11983 [==============================] - 1s 70us/sample - loss: 0.0437 - acc: 0.9424 - val_loss: 0.0400 - val_acc: 0.9473\n",
            "Epoch 24/500\n",
            "11983/11983 [==============================] - 1s 74us/sample - loss: 0.0445 - acc: 0.9425 - val_loss: 0.0411 - val_acc: 0.9466\n",
            "Epoch 25/500\n",
            "11983/11983 [==============================] - 1s 72us/sample - loss: 0.0450 - acc: 0.9394 - val_loss: 0.0398 - val_acc: 0.9466\n",
            "Epoch 26/500\n",
            "11983/11983 [==============================] - 1s 72us/sample - loss: 0.0429 - acc: 0.9446 - val_loss: 0.0396 - val_acc: 0.9489\n",
            "Epoch 27/500\n",
            "11983/11983 [==============================] - 1s 70us/sample - loss: 0.0433 - acc: 0.9438 - val_loss: 0.0393 - val_acc: 0.9493\n",
            "Epoch 28/500\n",
            "11983/11983 [==============================] - 1s 71us/sample - loss: 0.0429 - acc: 0.9430 - val_loss: 0.0400 - val_acc: 0.9479\n",
            "Epoch 29/500\n",
            "11983/11983 [==============================] - 1s 72us/sample - loss: 0.0428 - acc: 0.9439 - val_loss: 0.0401 - val_acc: 0.9473\n",
            "Epoch 30/500\n",
            "11983/11983 [==============================] - 1s 73us/sample - loss: 0.0426 - acc: 0.9436 - val_loss: 0.0408 - val_acc: 0.9473\n",
            "Epoch 31/500\n",
            "11983/11983 [==============================] - 1s 72us/sample - loss: 0.0419 - acc: 0.9455 - val_loss: 0.0400 - val_acc: 0.9473\n",
            "Epoch 32/500\n",
            "11983/11983 [==============================] - 1s 73us/sample - loss: 0.0446 - acc: 0.9427 - val_loss: 0.0405 - val_acc: 0.9473\n",
            "Epoch 33/500\n",
            "11983/11983 [==============================] - 1s 72us/sample - loss: 0.0429 - acc: 0.9444 - val_loss: 0.0406 - val_acc: 0.9476\n",
            "Epoch 34/500\n",
            "11983/11983 [==============================] - 1s 72us/sample - loss: 0.0432 - acc: 0.9442 - val_loss: 0.0400 - val_acc: 0.9483\n",
            "Epoch 35/500\n",
            "11983/11983 [==============================] - 1s 74us/sample - loss: 0.0427 - acc: 0.9442 - val_loss: 0.0402 - val_acc: 0.9489\n",
            "Epoch 36/500\n",
            "11983/11983 [==============================] - 1s 71us/sample - loss: 0.0441 - acc: 0.9429 - val_loss: 0.0402 - val_acc: 0.9476\n",
            "Epoch 37/500\n",
            "11983/11983 [==============================] - 1s 75us/sample - loss: 0.0436 - acc: 0.9427 - val_loss: 0.0402 - val_acc: 0.9466\n",
            "Epoch 38/500\n",
            "11983/11983 [==============================] - 1s 72us/sample - loss: 0.0433 - acc: 0.9438 - val_loss: 0.0403 - val_acc: 0.9483\n",
            "Epoch 39/500\n",
            "11983/11983 [==============================] - 1s 72us/sample - loss: 0.0432 - acc: 0.9427 - val_loss: 0.0407 - val_acc: 0.9463\n",
            "Epoch 40/500\n",
            "11983/11983 [==============================] - 1s 72us/sample - loss: 0.0439 - acc: 0.9417 - val_loss: 0.0404 - val_acc: 0.9476\n",
            "Epoch 41/500\n",
            "11983/11983 [==============================] - 1s 75us/sample - loss: 0.0435 - acc: 0.9438 - val_loss: 0.0398 - val_acc: 0.9483\n",
            "Epoch 42/500\n",
            "11983/11983 [==============================] - 1s 76us/sample - loss: 0.0439 - acc: 0.9423 - val_loss: 0.0401 - val_acc: 0.9459\n",
            "Epoch 43/500\n",
            "11983/11983 [==============================] - 1s 72us/sample - loss: 0.0438 - acc: 0.9437 - val_loss: 0.0397 - val_acc: 0.9469\n",
            "Epoch 44/500\n",
            "11983/11983 [==============================] - 1s 73us/sample - loss: 0.0433 - acc: 0.9433 - val_loss: 0.0395 - val_acc: 0.9479\n",
            "Epoch 45/500\n",
            "11983/11983 [==============================] - 1s 75us/sample - loss: 0.0428 - acc: 0.9433 - val_loss: 0.0393 - val_acc: 0.9476\n",
            "Epoch 46/500\n",
            "11983/11983 [==============================] - 1s 73us/sample - loss: 0.0439 - acc: 0.9427 - val_loss: 0.0400 - val_acc: 0.9459\n",
            "Epoch 47/500\n",
            "11983/11983 [==============================] - 1s 72us/sample - loss: 0.0425 - acc: 0.9426 - val_loss: 0.0395 - val_acc: 0.9483\n",
            "Epoch 48/500\n",
            "11983/11983 [==============================] - 1s 74us/sample - loss: 0.0413 - acc: 0.9473 - val_loss: 0.0394 - val_acc: 0.9479\n",
            "Epoch 49/500\n",
            "11983/11983 [==============================] - 1s 74us/sample - loss: 0.0440 - acc: 0.9402 - val_loss: 0.0399 - val_acc: 0.9466\n",
            "Epoch 50/500\n",
            "11983/11983 [==============================] - 1s 72us/sample - loss: 0.0429 - acc: 0.9442 - val_loss: 0.0404 - val_acc: 0.9459\n",
            "Epoch 51/500\n",
            "11983/11983 [==============================] - 1s 73us/sample - loss: 0.0432 - acc: 0.9424 - val_loss: 0.0399 - val_acc: 0.9483\n",
            "Epoch 52/500\n",
            "11983/11983 [==============================] - 1s 72us/sample - loss: 0.0440 - acc: 0.9414 - val_loss: 0.0399 - val_acc: 0.9483\n",
            "Epoch 53/500\n",
            "11983/11983 [==============================] - 1s 74us/sample - loss: 0.0435 - acc: 0.9428 - val_loss: 0.0408 - val_acc: 0.9453\n",
            "Epoch 54/500\n",
            "11983/11983 [==============================] - 1s 81us/sample - loss: 0.0425 - acc: 0.9426 - val_loss: 0.0393 - val_acc: 0.9483\n",
            "Epoch 55/500\n",
            "11983/11983 [==============================] - 1s 76us/sample - loss: 0.0439 - acc: 0.9425 - val_loss: 0.0397 - val_acc: 0.9479\n",
            "Epoch 56/500\n",
            "11983/11983 [==============================] - 1s 76us/sample - loss: 0.0431 - acc: 0.9445 - val_loss: 0.0390 - val_acc: 0.9476\n",
            "Epoch 57/500\n",
            "11983/11983 [==============================] - 1s 74us/sample - loss: 0.0447 - acc: 0.9428 - val_loss: 0.0398 - val_acc: 0.9479\n",
            "Epoch 58/500\n",
            "11983/11983 [==============================] - 1s 71us/sample - loss: 0.0428 - acc: 0.9460 - val_loss: 0.0388 - val_acc: 0.9493\n",
            "Epoch 59/500\n",
            "11983/11983 [==============================] - 1s 72us/sample - loss: 0.0433 - acc: 0.9439 - val_loss: 0.0388 - val_acc: 0.9473\n",
            "Epoch 60/500\n",
            "11983/11983 [==============================] - 1s 74us/sample - loss: 0.0425 - acc: 0.9448 - val_loss: 0.0383 - val_acc: 0.9489\n",
            "Epoch 61/500\n",
            "11983/11983 [==============================] - 1s 75us/sample - loss: 0.0433 - acc: 0.9427 - val_loss: 0.0397 - val_acc: 0.9473\n",
            "Epoch 62/500\n",
            "11983/11983 [==============================] - 1s 75us/sample - loss: 0.0445 - acc: 0.9394 - val_loss: 0.0395 - val_acc: 0.9483\n",
            "Epoch 63/500\n",
            "11983/11983 [==============================] - 1s 75us/sample - loss: 0.0420 - acc: 0.9448 - val_loss: 0.0394 - val_acc: 0.9489\n",
            "Epoch 64/500\n",
            "11983/11983 [==============================] - 1s 73us/sample - loss: 0.0427 - acc: 0.9450 - val_loss: 0.0396 - val_acc: 0.9459\n",
            "Epoch 65/500\n",
            "11983/11983 [==============================] - 1s 76us/sample - loss: 0.0428 - acc: 0.9439 - val_loss: 0.0387 - val_acc: 0.9489\n",
            "Epoch 66/500\n",
            "11983/11983 [==============================] - 1s 75us/sample - loss: 0.0409 - acc: 0.9453 - val_loss: 0.0395 - val_acc: 0.9483\n",
            "Epoch 67/500\n",
            "11983/11983 [==============================] - 1s 76us/sample - loss: 0.0404 - acc: 0.9483 - val_loss: 0.0394 - val_acc: 0.9479\n",
            "Epoch 68/500\n",
            "11983/11983 [==============================] - 1s 72us/sample - loss: 0.0431 - acc: 0.9434 - val_loss: 0.0394 - val_acc: 0.9486\n",
            "Epoch 69/500\n",
            "11983/11983 [==============================] - 1s 74us/sample - loss: 0.0422 - acc: 0.9461 - val_loss: 0.0404 - val_acc: 0.9476\n",
            "Epoch 70/500\n",
            "11983/11983 [==============================] - 1s 73us/sample - loss: 0.0413 - acc: 0.9463 - val_loss: 0.0398 - val_acc: 0.9496\n",
            "Epoch 71/500\n",
            "11983/11983 [==============================] - 1s 77us/sample - loss: 0.0436 - acc: 0.9426 - val_loss: 0.0381 - val_acc: 0.9513\n",
            "Epoch 72/500\n",
            "11983/11983 [==============================] - 1s 73us/sample - loss: 0.0420 - acc: 0.9462 - val_loss: 0.0386 - val_acc: 0.9513\n",
            "Epoch 73/500\n",
            "11983/11983 [==============================] - 1s 73us/sample - loss: 0.0434 - acc: 0.9438 - val_loss: 0.0389 - val_acc: 0.9499\n",
            "Epoch 74/500\n",
            "11983/11983 [==============================] - 1s 73us/sample - loss: 0.0406 - acc: 0.9466 - val_loss: 0.0388 - val_acc: 0.9493\n",
            "Epoch 75/500\n",
            "11983/11983 [==============================] - 1s 73us/sample - loss: 0.0419 - acc: 0.9468 - val_loss: 0.0384 - val_acc: 0.9493\n",
            "Epoch 76/500\n",
            "11983/11983 [==============================] - 1s 72us/sample - loss: 0.0415 - acc: 0.9454 - val_loss: 0.0396 - val_acc: 0.9496\n",
            "Epoch 77/500\n",
            "11983/11983 [==============================] - 1s 76us/sample - loss: 0.0422 - acc: 0.9448 - val_loss: 0.0380 - val_acc: 0.9499\n",
            "Epoch 78/500\n",
            "11983/11983 [==============================] - 1s 75us/sample - loss: 0.0403 - acc: 0.9490 - val_loss: 0.0382 - val_acc: 0.9493\n",
            "Epoch 79/500\n",
            "11983/11983 [==============================] - 1s 75us/sample - loss: 0.0422 - acc: 0.9439 - val_loss: 0.0384 - val_acc: 0.9496\n",
            "Epoch 80/500\n",
            "11983/11983 [==============================] - 1s 73us/sample - loss: 0.0423 - acc: 0.9455 - val_loss: 0.0386 - val_acc: 0.9476\n",
            "Epoch 81/500\n",
            "11983/11983 [==============================] - 1s 75us/sample - loss: 0.0427 - acc: 0.9450 - val_loss: 0.0384 - val_acc: 0.9493\n",
            "Epoch 82/500\n",
            "11983/11983 [==============================] - 1s 73us/sample - loss: 0.0440 - acc: 0.9426 - val_loss: 0.0389 - val_acc: 0.9486\n",
            "Epoch 83/500\n",
            "11983/11983 [==============================] - 1s 72us/sample - loss: 0.0410 - acc: 0.9466 - val_loss: 0.0390 - val_acc: 0.9469\n",
            "Epoch 84/500\n",
            "11983/11983 [==============================] - 1s 74us/sample - loss: 0.0426 - acc: 0.9439 - val_loss: 0.0390 - val_acc: 0.9496\n",
            "Epoch 85/500\n",
            "11983/11983 [==============================] - 1s 73us/sample - loss: 0.0416 - acc: 0.9458 - val_loss: 0.0390 - val_acc: 0.9473\n",
            "Epoch 86/500\n",
            "11983/11983 [==============================] - 1s 73us/sample - loss: 0.0435 - acc: 0.9423 - val_loss: 0.0385 - val_acc: 0.9479\n",
            "Epoch 87/500\n",
            "11983/11983 [==============================] - 1s 74us/sample - loss: 0.0424 - acc: 0.9451 - val_loss: 0.0386 - val_acc: 0.9503\n",
            "Epoch 88/500\n",
            "11983/11983 [==============================] - 1s 74us/sample - loss: 0.0414 - acc: 0.9463 - val_loss: 0.0378 - val_acc: 0.9483\n",
            "Epoch 89/500\n",
            "11983/11983 [==============================] - 1s 73us/sample - loss: 0.0402 - acc: 0.9475 - val_loss: 0.0382 - val_acc: 0.9486\n",
            "Epoch 90/500\n",
            "11983/11983 [==============================] - 1s 76us/sample - loss: 0.0421 - acc: 0.9436 - val_loss: 0.0382 - val_acc: 0.9506\n",
            "Epoch 91/500\n",
            "11983/11983 [==============================] - 1s 74us/sample - loss: 0.0403 - acc: 0.9488 - val_loss: 0.0385 - val_acc: 0.9493\n",
            "Epoch 92/500\n",
            "11983/11983 [==============================] - 1s 74us/sample - loss: 0.0419 - acc: 0.9461 - val_loss: 0.0381 - val_acc: 0.9493\n",
            "Epoch 93/500\n",
            "11983/11983 [==============================] - 1s 72us/sample - loss: 0.0413 - acc: 0.9463 - val_loss: 0.0377 - val_acc: 0.9506\n",
            "Epoch 94/500\n",
            "11983/11983 [==============================] - 1s 72us/sample - loss: 0.0409 - acc: 0.9468 - val_loss: 0.0378 - val_acc: 0.9509\n",
            "Epoch 95/500\n",
            "11983/11983 [==============================] - 1s 72us/sample - loss: 0.0403 - acc: 0.9478 - val_loss: 0.0376 - val_acc: 0.9496\n",
            "Epoch 96/500\n",
            "11983/11983 [==============================] - 1s 71us/sample - loss: 0.0405 - acc: 0.9462 - val_loss: 0.0376 - val_acc: 0.9516\n",
            "Epoch 97/500\n",
            "11983/11983 [==============================] - 1s 72us/sample - loss: 0.0412 - acc: 0.9469 - val_loss: 0.0379 - val_acc: 0.9493\n",
            "Epoch 98/500\n",
            "11983/11983 [==============================] - 1s 74us/sample - loss: 0.0425 - acc: 0.9454 - val_loss: 0.0379 - val_acc: 0.9506\n",
            "Epoch 99/500\n",
            "11983/11983 [==============================] - 1s 75us/sample - loss: 0.0414 - acc: 0.9458 - val_loss: 0.0385 - val_acc: 0.9469\n",
            "Epoch 100/500\n",
            "11983/11983 [==============================] - 1s 72us/sample - loss: 0.0408 - acc: 0.9463 - val_loss: 0.0384 - val_acc: 0.9486\n",
            "Epoch 101/500\n",
            "11983/11983 [==============================] - 1s 74us/sample - loss: 0.0422 - acc: 0.9458 - val_loss: 0.0389 - val_acc: 0.9486\n",
            "Epoch 102/500\n",
            "11983/11983 [==============================] - 1s 77us/sample - loss: 0.0424 - acc: 0.9439 - val_loss: 0.0387 - val_acc: 0.9489\n",
            "Epoch 103/500\n",
            "11983/11983 [==============================] - 1s 75us/sample - loss: 0.0409 - acc: 0.9469 - val_loss: 0.0382 - val_acc: 0.9486\n",
            "Epoch 104/500\n",
            "11983/11983 [==============================] - 1s 73us/sample - loss: 0.0408 - acc: 0.9472 - val_loss: 0.0382 - val_acc: 0.9503\n",
            "Epoch 105/500\n",
            "11983/11983 [==============================] - 1s 74us/sample - loss: 0.0408 - acc: 0.9477 - val_loss: 0.0383 - val_acc: 0.9483\n",
            "Epoch 106/500\n",
            "11983/11983 [==============================] - 1s 73us/sample - loss: 0.0422 - acc: 0.9432 - val_loss: 0.0384 - val_acc: 0.9496\n",
            "Epoch 107/500\n",
            "11983/11983 [==============================] - 1s 74us/sample - loss: 0.0416 - acc: 0.9475 - val_loss: 0.0372 - val_acc: 0.9506\n",
            "Epoch 108/500\n",
            "11983/11983 [==============================] - 1s 77us/sample - loss: 0.0414 - acc: 0.9456 - val_loss: 0.0396 - val_acc: 0.9476\n",
            "Epoch 109/500\n",
            "11983/11983 [==============================] - 1s 74us/sample - loss: 0.0395 - acc: 0.9485 - val_loss: 0.0384 - val_acc: 0.9476\n",
            "Epoch 110/500\n",
            "11983/11983 [==============================] - 1s 71us/sample - loss: 0.0410 - acc: 0.9462 - val_loss: 0.0385 - val_acc: 0.9466\n",
            "Epoch 111/500\n",
            "11983/11983 [==============================] - 1s 75us/sample - loss: 0.0418 - acc: 0.9454 - val_loss: 0.0395 - val_acc: 0.9466\n",
            "Epoch 112/500\n",
            "11983/11983 [==============================] - 1s 74us/sample - loss: 0.0411 - acc: 0.9442 - val_loss: 0.0380 - val_acc: 0.9499\n",
            "Epoch 113/500\n",
            "11983/11983 [==============================] - 1s 73us/sample - loss: 0.0411 - acc: 0.9463 - val_loss: 0.0378 - val_acc: 0.9503\n",
            "Epoch 114/500\n",
            "11983/11983 [==============================] - 1s 77us/sample - loss: 0.0412 - acc: 0.9473 - val_loss: 0.0378 - val_acc: 0.9483\n",
            "Epoch 115/500\n",
            "11983/11983 [==============================] - 1s 75us/sample - loss: 0.0401 - acc: 0.9474 - val_loss: 0.0383 - val_acc: 0.9499\n",
            "Epoch 116/500\n",
            "11983/11983 [==============================] - 1s 73us/sample - loss: 0.0421 - acc: 0.9433 - val_loss: 0.0386 - val_acc: 0.9496\n",
            "Epoch 117/500\n",
            "11983/11983 [==============================] - 1s 75us/sample - loss: 0.0412 - acc: 0.9449 - val_loss: 0.0384 - val_acc: 0.9479\n",
            "Epoch 118/500\n",
            "11983/11983 [==============================] - 1s 73us/sample - loss: 0.0421 - acc: 0.9464 - val_loss: 0.0383 - val_acc: 0.9483\n",
            "Epoch 119/500\n",
            "11983/11983 [==============================] - 1s 74us/sample - loss: 0.0389 - acc: 0.9498 - val_loss: 0.0384 - val_acc: 0.9496\n",
            "Epoch 120/500\n",
            "11983/11983 [==============================] - 1s 73us/sample - loss: 0.0419 - acc: 0.9453 - val_loss: 0.0384 - val_acc: 0.9483\n",
            "Epoch 121/500\n",
            "11983/11983 [==============================] - 1s 73us/sample - loss: 0.0419 - acc: 0.9452 - val_loss: 0.0379 - val_acc: 0.9479\n",
            "Epoch 122/500\n",
            "11983/11983 [==============================] - 1s 74us/sample - loss: 0.0409 - acc: 0.9472 - val_loss: 0.0386 - val_acc: 0.9469\n",
            "Epoch 123/500\n",
            "11983/11983 [==============================] - 1s 74us/sample - loss: 0.0396 - acc: 0.9486 - val_loss: 0.0377 - val_acc: 0.9486\n",
            "Epoch 124/500\n",
            "11983/11983 [==============================] - 1s 75us/sample - loss: 0.0408 - acc: 0.9450 - val_loss: 0.0383 - val_acc: 0.9489\n",
            "Epoch 125/500\n",
            "11983/11983 [==============================] - 1s 76us/sample - loss: 0.0408 - acc: 0.9468 - val_loss: 0.0373 - val_acc: 0.9479\n",
            "Epoch 126/500\n",
            "11983/11983 [==============================] - 1s 76us/sample - loss: 0.0400 - acc: 0.9475 - val_loss: 0.0380 - val_acc: 0.9476\n",
            "Epoch 127/500\n",
            "11983/11983 [==============================] - 1s 71us/sample - loss: 0.0406 - acc: 0.9475 - val_loss: 0.0371 - val_acc: 0.9506\n",
            "Epoch 128/500\n",
            "11983/11983 [==============================] - 1s 70us/sample - loss: 0.0401 - acc: 0.9483 - val_loss: 0.0381 - val_acc: 0.9496\n",
            "Epoch 129/500\n",
            "11983/11983 [==============================] - 1s 72us/sample - loss: 0.0409 - acc: 0.9458 - val_loss: 0.0371 - val_acc: 0.9506\n",
            "Epoch 130/500\n",
            "11983/11983 [==============================] - 1s 71us/sample - loss: 0.0396 - acc: 0.9476 - val_loss: 0.0376 - val_acc: 0.9506\n",
            "Epoch 131/500\n",
            "11983/11983 [==============================] - 1s 73us/sample - loss: 0.0407 - acc: 0.9462 - val_loss: 0.0372 - val_acc: 0.9509\n",
            "Epoch 132/500\n",
            "11983/11983 [==============================] - 1s 72us/sample - loss: 0.0405 - acc: 0.9458 - val_loss: 0.0378 - val_acc: 0.9516\n",
            "Epoch 133/500\n",
            "11983/11983 [==============================] - 1s 75us/sample - loss: 0.0396 - acc: 0.9501 - val_loss: 0.0375 - val_acc: 0.9503\n",
            "Epoch 134/500\n",
            "11983/11983 [==============================] - 1s 74us/sample - loss: 0.0400 - acc: 0.9482 - val_loss: 0.0376 - val_acc: 0.9499\n",
            "Epoch 135/500\n",
            "11983/11983 [==============================] - 1s 74us/sample - loss: 0.0414 - acc: 0.9459 - val_loss: 0.0374 - val_acc: 0.9506\n",
            "Epoch 136/500\n",
            "11983/11983 [==============================] - 1s 72us/sample - loss: 0.0390 - acc: 0.9506 - val_loss: 0.0384 - val_acc: 0.9496\n",
            "Epoch 137/500\n",
            "11983/11983 [==============================] - 1s 73us/sample - loss: 0.0404 - acc: 0.9471 - val_loss: 0.0375 - val_acc: 0.9516\n",
            "Epoch 138/500\n",
            "11983/11983 [==============================] - 1s 76us/sample - loss: 0.0408 - acc: 0.9467 - val_loss: 0.0382 - val_acc: 0.9476\n",
            "Epoch 139/500\n",
            "11983/11983 [==============================] - 1s 72us/sample - loss: 0.0408 - acc: 0.9473 - val_loss: 0.0375 - val_acc: 0.9496\n",
            "Epoch 140/500\n",
            "11983/11983 [==============================] - 1s 75us/sample - loss: 0.0415 - acc: 0.9463 - val_loss: 0.0375 - val_acc: 0.9493\n",
            "Epoch 141/500\n",
            "11983/11983 [==============================] - 1s 74us/sample - loss: 0.0393 - acc: 0.9485 - val_loss: 0.0379 - val_acc: 0.9496\n",
            "Epoch 142/500\n",
            "11983/11983 [==============================] - 1s 72us/sample - loss: 0.0404 - acc: 0.9472 - val_loss: 0.0373 - val_acc: 0.9489\n",
            "Epoch 143/500\n",
            "11983/11983 [==============================] - 1s 72us/sample - loss: 0.0419 - acc: 0.9463 - val_loss: 0.0373 - val_acc: 0.9486\n",
            "Epoch 144/500\n",
            "11983/11983 [==============================] - 1s 73us/sample - loss: 0.0408 - acc: 0.9465 - val_loss: 0.0366 - val_acc: 0.9509\n",
            "Epoch 145/500\n",
            "11983/11983 [==============================] - 1s 72us/sample - loss: 0.0387 - acc: 0.9502 - val_loss: 0.0366 - val_acc: 0.9503\n",
            "Epoch 146/500\n",
            "11983/11983 [==============================] - 1s 74us/sample - loss: 0.0395 - acc: 0.9478 - val_loss: 0.0373 - val_acc: 0.9489\n",
            "Epoch 147/500\n",
            "11983/11983 [==============================] - 1s 73us/sample - loss: 0.0392 - acc: 0.9490 - val_loss: 0.0374 - val_acc: 0.9496\n",
            "Epoch 148/500\n",
            "11983/11983 [==============================] - 1s 73us/sample - loss: 0.0396 - acc: 0.9483 - val_loss: 0.0372 - val_acc: 0.9513\n",
            "Epoch 149/500\n",
            "11983/11983 [==============================] - 1s 76us/sample - loss: 0.0403 - acc: 0.9476 - val_loss: 0.0372 - val_acc: 0.9499\n",
            "Epoch 150/500\n",
            "11983/11983 [==============================] - 1s 73us/sample - loss: 0.0395 - acc: 0.9479 - val_loss: 0.0376 - val_acc: 0.9486\n",
            "Epoch 151/500\n",
            "11983/11983 [==============================] - 1s 75us/sample - loss: 0.0389 - acc: 0.9501 - val_loss: 0.0363 - val_acc: 0.9489\n",
            "Epoch 152/500\n",
            "11983/11983 [==============================] - 1s 72us/sample - loss: 0.0393 - acc: 0.9484 - val_loss: 0.0370 - val_acc: 0.9496\n",
            "Epoch 153/500\n",
            "11983/11983 [==============================] - 1s 72us/sample - loss: 0.0392 - acc: 0.9502 - val_loss: 0.0370 - val_acc: 0.9503\n",
            "Epoch 154/500\n",
            "11983/11983 [==============================] - 1s 72us/sample - loss: 0.0393 - acc: 0.9488 - val_loss: 0.0382 - val_acc: 0.9493\n",
            "Epoch 155/500\n",
            "11983/11983 [==============================] - 1s 74us/sample - loss: 0.0395 - acc: 0.9493 - val_loss: 0.0373 - val_acc: 0.9496\n",
            "Epoch 156/500\n",
            "11983/11983 [==============================] - 1s 74us/sample - loss: 0.0398 - acc: 0.9488 - val_loss: 0.0374 - val_acc: 0.9503\n",
            "Epoch 157/500\n",
            "11983/11983 [==============================] - 1s 75us/sample - loss: 0.0386 - acc: 0.9484 - val_loss: 0.0371 - val_acc: 0.9499\n",
            "Epoch 158/500\n",
            "11983/11983 [==============================] - 1s 75us/sample - loss: 0.0406 - acc: 0.9463 - val_loss: 0.0375 - val_acc: 0.9493\n",
            "Epoch 159/500\n",
            "11983/11983 [==============================] - 1s 78us/sample - loss: 0.0391 - acc: 0.9484 - val_loss: 0.0379 - val_acc: 0.9493\n",
            "Epoch 160/500\n",
            "11983/11983 [==============================] - 1s 78us/sample - loss: 0.0404 - acc: 0.9469 - val_loss: 0.0378 - val_acc: 0.9499\n",
            "Epoch 161/500\n",
            "11983/11983 [==============================] - 1s 78us/sample - loss: 0.0387 - acc: 0.9503 - val_loss: 0.0377 - val_acc: 0.9516\n",
            "Epoch 162/500\n",
            "11983/11983 [==============================] - 1s 76us/sample - loss: 0.0403 - acc: 0.9463 - val_loss: 0.0373 - val_acc: 0.9499\n",
            "Epoch 163/500\n",
            "11983/11983 [==============================] - 1s 75us/sample - loss: 0.0426 - acc: 0.9437 - val_loss: 0.0374 - val_acc: 0.9493\n",
            "Epoch 164/500\n",
            "11983/11983 [==============================] - 1s 76us/sample - loss: 0.0415 - acc: 0.9466 - val_loss: 0.0376 - val_acc: 0.9483\n",
            "Epoch 165/500\n",
            "11983/11983 [==============================] - 1s 76us/sample - loss: 0.0408 - acc: 0.9458 - val_loss: 0.0369 - val_acc: 0.9516\n",
            "Epoch 166/500\n",
            "11983/11983 [==============================] - 1s 75us/sample - loss: 0.0397 - acc: 0.9483 - val_loss: 0.0375 - val_acc: 0.9489\n",
            "Epoch 167/500\n",
            "11983/11983 [==============================] - 1s 76us/sample - loss: 0.0389 - acc: 0.9501 - val_loss: 0.0370 - val_acc: 0.9513\n",
            "Epoch 168/500\n",
            "11983/11983 [==============================] - 1s 73us/sample - loss: 0.0397 - acc: 0.9492 - val_loss: 0.0366 - val_acc: 0.9513\n",
            "Epoch 169/500\n",
            "11983/11983 [==============================] - 1s 74us/sample - loss: 0.0398 - acc: 0.9469 - val_loss: 0.0367 - val_acc: 0.9499\n",
            "Epoch 170/500\n",
            "11983/11983 [==============================] - 1s 74us/sample - loss: 0.0391 - acc: 0.9491 - val_loss: 0.0370 - val_acc: 0.9496\n",
            "Epoch 171/500\n",
            "11983/11983 [==============================] - 1s 74us/sample - loss: 0.0397 - acc: 0.9489 - val_loss: 0.0377 - val_acc: 0.9483\n",
            "Epoch 172/500\n",
            "11983/11983 [==============================] - 1s 73us/sample - loss: 0.0404 - acc: 0.9471 - val_loss: 0.0377 - val_acc: 0.9499\n",
            "Epoch 173/500\n",
            "11983/11983 [==============================] - 1s 75us/sample - loss: 0.0395 - acc: 0.9489 - val_loss: 0.0373 - val_acc: 0.9496\n",
            "Epoch 174/500\n",
            "11983/11983 [==============================] - 1s 71us/sample - loss: 0.0388 - acc: 0.9495 - val_loss: 0.0367 - val_acc: 0.9513\n",
            "Epoch 175/500\n",
            "11983/11983 [==============================] - 1s 71us/sample - loss: 0.0378 - acc: 0.9510 - val_loss: 0.0368 - val_acc: 0.9509\n",
            "Epoch 176/500\n",
            "11983/11983 [==============================] - 1s 73us/sample - loss: 0.0396 - acc: 0.9471 - val_loss: 0.0372 - val_acc: 0.9506\n",
            "Epoch 177/500\n",
            "11983/11983 [==============================] - 1s 73us/sample - loss: 0.0383 - acc: 0.9487 - val_loss: 0.0372 - val_acc: 0.9496\n",
            "Epoch 178/500\n",
            "11983/11983 [==============================] - 1s 73us/sample - loss: 0.0405 - acc: 0.9460 - val_loss: 0.0374 - val_acc: 0.9483\n",
            "Epoch 179/500\n",
            "11983/11983 [==============================] - 1s 73us/sample - loss: 0.0386 - acc: 0.9484 - val_loss: 0.0376 - val_acc: 0.9496\n",
            "Epoch 180/500\n",
            "11983/11983 [==============================] - 1s 74us/sample - loss: 0.0382 - acc: 0.9508 - val_loss: 0.0379 - val_acc: 0.9513\n",
            "Epoch 181/500\n",
            "11983/11983 [==============================] - 1s 72us/sample - loss: 0.0406 - acc: 0.9475 - val_loss: 0.0374 - val_acc: 0.9499\n",
            "Epoch 182/500\n",
            "11983/11983 [==============================] - 1s 72us/sample - loss: 0.0392 - acc: 0.9480 - val_loss: 0.0374 - val_acc: 0.9503\n",
            "Epoch 183/500\n",
            "11983/11983 [==============================] - 1s 75us/sample - loss: 0.0384 - acc: 0.9505 - val_loss: 0.0363 - val_acc: 0.9529\n",
            "Epoch 184/500\n",
            "11983/11983 [==============================] - 1s 74us/sample - loss: 0.0376 - acc: 0.9514 - val_loss: 0.0372 - val_acc: 0.9476\n",
            "Epoch 185/500\n",
            "11983/11983 [==============================] - 1s 76us/sample - loss: 0.0395 - acc: 0.9476 - val_loss: 0.0367 - val_acc: 0.9523\n",
            "Epoch 186/500\n",
            "11983/11983 [==============================] - 1s 73us/sample - loss: 0.0403 - acc: 0.9471 - val_loss: 0.0366 - val_acc: 0.9509\n",
            "Epoch 187/500\n",
            "11983/11983 [==============================] - 1s 76us/sample - loss: 0.0388 - acc: 0.9502 - val_loss: 0.0363 - val_acc: 0.9513\n",
            "Epoch 188/500\n",
            "11983/11983 [==============================] - 1s 75us/sample - loss: 0.0393 - acc: 0.9503 - val_loss: 0.0370 - val_acc: 0.9499\n",
            "Epoch 189/500\n",
            "11983/11983 [==============================] - 1s 77us/sample - loss: 0.0399 - acc: 0.9470 - val_loss: 0.0368 - val_acc: 0.9496\n",
            "Epoch 190/500\n",
            "11983/11983 [==============================] - 1s 74us/sample - loss: 0.0395 - acc: 0.9494 - val_loss: 0.0372 - val_acc: 0.9516\n",
            "Epoch 191/500\n",
            "11983/11983 [==============================] - 1s 73us/sample - loss: 0.0399 - acc: 0.9472 - val_loss: 0.0367 - val_acc: 0.9506\n",
            "Epoch 192/500\n",
            "11983/11983 [==============================] - 1s 73us/sample - loss: 0.0391 - acc: 0.9508 - val_loss: 0.0363 - val_acc: 0.9513\n",
            "Epoch 193/500\n",
            "11983/11983 [==============================] - 1s 73us/sample - loss: 0.0395 - acc: 0.9473 - val_loss: 0.0359 - val_acc: 0.9523\n",
            "Epoch 194/500\n",
            "11983/11983 [==============================] - 1s 74us/sample - loss: 0.0376 - acc: 0.9510 - val_loss: 0.0369 - val_acc: 0.9509\n",
            "Epoch 195/500\n",
            "11983/11983 [==============================] - 1s 75us/sample - loss: 0.0383 - acc: 0.9513 - val_loss: 0.0367 - val_acc: 0.9513\n",
            "Epoch 196/500\n",
            "11983/11983 [==============================] - 1s 74us/sample - loss: 0.0407 - acc: 0.9482 - val_loss: 0.0372 - val_acc: 0.9496\n",
            "Epoch 197/500\n",
            "11983/11983 [==============================] - 1s 76us/sample - loss: 0.0390 - acc: 0.9488 - val_loss: 0.0365 - val_acc: 0.9486\n",
            "Epoch 198/500\n",
            "11983/11983 [==============================] - 1s 75us/sample - loss: 0.0387 - acc: 0.9488 - val_loss: 0.0365 - val_acc: 0.9503\n",
            "Epoch 199/500\n",
            "11983/11983 [==============================] - 1s 74us/sample - loss: 0.0384 - acc: 0.9498 - val_loss: 0.0369 - val_acc: 0.9489\n",
            "Epoch 200/500\n",
            "11983/11983 [==============================] - 1s 75us/sample - loss: 0.0393 - acc: 0.9492 - val_loss: 0.0368 - val_acc: 0.9506\n",
            "Epoch 201/500\n",
            "11983/11983 [==============================] - 1s 76us/sample - loss: 0.0388 - acc: 0.9488 - val_loss: 0.0375 - val_acc: 0.9503\n",
            "Epoch 202/500\n",
            "11983/11983 [==============================] - 1s 75us/sample - loss: 0.0395 - acc: 0.9480 - val_loss: 0.0377 - val_acc: 0.9516\n",
            "Epoch 203/500\n",
            "11983/11983 [==============================] - 1s 73us/sample - loss: 0.0400 - acc: 0.9476 - val_loss: 0.0372 - val_acc: 0.9479\n",
            "Epoch 204/500\n",
            "11983/11983 [==============================] - 1s 74us/sample - loss: 0.0393 - acc: 0.9478 - val_loss: 0.0360 - val_acc: 0.9513\n",
            "Epoch 205/500\n",
            "11983/11983 [==============================] - 1s 76us/sample - loss: 0.0376 - acc: 0.9516 - val_loss: 0.0366 - val_acc: 0.9513\n",
            "Epoch 206/500\n",
            "11983/11983 [==============================] - 1s 75us/sample - loss: 0.0378 - acc: 0.9507 - val_loss: 0.0362 - val_acc: 0.9509\n",
            "Epoch 207/500\n",
            "11983/11983 [==============================] - 1s 74us/sample - loss: 0.0397 - acc: 0.9491 - val_loss: 0.0361 - val_acc: 0.9516\n",
            "Epoch 208/500\n",
            "11983/11983 [==============================] - 1s 78us/sample - loss: 0.0385 - acc: 0.9507 - val_loss: 0.0357 - val_acc: 0.9519\n",
            "Epoch 209/500\n",
            "11983/11983 [==============================] - 1s 80us/sample - loss: 0.0387 - acc: 0.9507 - val_loss: 0.0359 - val_acc: 0.9533\n",
            "Epoch 210/500\n",
            "11983/11983 [==============================] - 1s 76us/sample - loss: 0.0380 - acc: 0.9503 - val_loss: 0.0357 - val_acc: 0.9536\n",
            "Epoch 211/500\n",
            "11983/11983 [==============================] - 1s 76us/sample - loss: 0.0386 - acc: 0.9488 - val_loss: 0.0365 - val_acc: 0.9513\n",
            "Epoch 212/500\n",
            "11983/11983 [==============================] - 1s 76us/sample - loss: 0.0386 - acc: 0.9497 - val_loss: 0.0359 - val_acc: 0.9503\n",
            "Epoch 213/500\n",
            "11983/11983 [==============================] - 1s 77us/sample - loss: 0.0387 - acc: 0.9483 - val_loss: 0.0366 - val_acc: 0.9529\n",
            "Epoch 214/500\n",
            "11983/11983 [==============================] - 1s 78us/sample - loss: 0.0372 - acc: 0.9529 - val_loss: 0.0364 - val_acc: 0.9503\n",
            "Epoch 215/500\n",
            "11983/11983 [==============================] - 1s 79us/sample - loss: 0.0372 - acc: 0.9509 - val_loss: 0.0363 - val_acc: 0.9503\n",
            "Epoch 216/500\n",
            "11983/11983 [==============================] - 1s 78us/sample - loss: 0.0384 - acc: 0.9508 - val_loss: 0.0362 - val_acc: 0.9513\n",
            "Epoch 217/500\n",
            "11983/11983 [==============================] - 1s 76us/sample - loss: 0.0381 - acc: 0.9498 - val_loss: 0.0354 - val_acc: 0.9526\n",
            "Epoch 218/500\n",
            "11983/11983 [==============================] - 1s 75us/sample - loss: 0.0401 - acc: 0.9479 - val_loss: 0.0357 - val_acc: 0.9526\n",
            "Epoch 219/500\n",
            "11983/11983 [==============================] - 1s 74us/sample - loss: 0.0371 - acc: 0.9514 - val_loss: 0.0370 - val_acc: 0.9513\n",
            "Epoch 220/500\n",
            "11983/11983 [==============================] - 1s 78us/sample - loss: 0.0379 - acc: 0.9503 - val_loss: 0.0363 - val_acc: 0.9523\n",
            "Epoch 221/500\n",
            "11983/11983 [==============================] - 1s 74us/sample - loss: 0.0386 - acc: 0.9514 - val_loss: 0.0368 - val_acc: 0.9503\n",
            "Epoch 222/500\n",
            "11983/11983 [==============================] - 1s 75us/sample - loss: 0.0372 - acc: 0.9513 - val_loss: 0.0370 - val_acc: 0.9503\n",
            "Epoch 223/500\n",
            "11983/11983 [==============================] - 1s 74us/sample - loss: 0.0381 - acc: 0.9510 - val_loss: 0.0360 - val_acc: 0.9489\n",
            "Epoch 224/500\n",
            "11983/11983 [==============================] - 1s 75us/sample - loss: 0.0370 - acc: 0.9515 - val_loss: 0.0361 - val_acc: 0.9513\n",
            "Epoch 225/500\n",
            "11983/11983 [==============================] - 1s 74us/sample - loss: 0.0368 - acc: 0.9523 - val_loss: 0.0357 - val_acc: 0.9523\n",
            "Epoch 226/500\n",
            "11983/11983 [==============================] - 1s 72us/sample - loss: 0.0364 - acc: 0.9535 - val_loss: 0.0360 - val_acc: 0.9513\n",
            "Epoch 227/500\n",
            "11983/11983 [==============================] - 1s 75us/sample - loss: 0.0388 - acc: 0.9496 - val_loss: 0.0364 - val_acc: 0.9526\n",
            "Epoch 228/500\n",
            "11983/11983 [==============================] - 1s 77us/sample - loss: 0.0383 - acc: 0.9496 - val_loss: 0.0358 - val_acc: 0.9499\n",
            "Epoch 229/500\n",
            "11983/11983 [==============================] - 1s 75us/sample - loss: 0.0388 - acc: 0.9496 - val_loss: 0.0358 - val_acc: 0.9513\n",
            "Epoch 230/500\n",
            "11983/11983 [==============================] - 1s 74us/sample - loss: 0.0376 - acc: 0.9518 - val_loss: 0.0358 - val_acc: 0.9509\n",
            "Epoch 231/500\n",
            "11983/11983 [==============================] - 1s 79us/sample - loss: 0.0385 - acc: 0.9522 - val_loss: 0.0360 - val_acc: 0.9509\n",
            "Epoch 232/500\n",
            "11983/11983 [==============================] - 1s 77us/sample - loss: 0.0370 - acc: 0.9518 - val_loss: 0.0352 - val_acc: 0.9513\n",
            "Epoch 233/500\n",
            "11983/11983 [==============================] - 1s 76us/sample - loss: 0.0377 - acc: 0.9529 - val_loss: 0.0358 - val_acc: 0.9516\n",
            "Epoch 234/500\n",
            "11983/11983 [==============================] - 1s 75us/sample - loss: 0.0392 - acc: 0.9486 - val_loss: 0.0359 - val_acc: 0.9519\n",
            "Epoch 235/500\n",
            "11983/11983 [==============================] - 1s 77us/sample - loss: 0.0374 - acc: 0.9515 - val_loss: 0.0352 - val_acc: 0.9516\n",
            "Epoch 236/500\n",
            "11983/11983 [==============================] - 1s 76us/sample - loss: 0.0373 - acc: 0.9505 - val_loss: 0.0364 - val_acc: 0.9506\n",
            "Epoch 237/500\n",
            "11983/11983 [==============================] - 1s 76us/sample - loss: 0.0372 - acc: 0.9512 - val_loss: 0.0355 - val_acc: 0.9539\n",
            "Epoch 238/500\n",
            "11983/11983 [==============================] - 1s 77us/sample - loss: 0.0389 - acc: 0.9489 - val_loss: 0.0355 - val_acc: 0.9519\n",
            "Epoch 239/500\n",
            "11983/11983 [==============================] - 1s 77us/sample - loss: 0.0375 - acc: 0.9507 - val_loss: 0.0368 - val_acc: 0.9506\n",
            "Epoch 240/500\n",
            "11983/11983 [==============================] - 1s 76us/sample - loss: 0.0379 - acc: 0.9509 - val_loss: 0.0364 - val_acc: 0.9513\n",
            "Epoch 241/500\n",
            "11983/11983 [==============================] - 1s 76us/sample - loss: 0.0399 - acc: 0.9467 - val_loss: 0.0354 - val_acc: 0.9509\n",
            "Epoch 242/500\n",
            "11983/11983 [==============================] - 1s 77us/sample - loss: 0.0377 - acc: 0.9505 - val_loss: 0.0354 - val_acc: 0.9513\n",
            "Epoch 243/500\n",
            "11983/11983 [==============================] - 1s 75us/sample - loss: 0.0385 - acc: 0.9500 - val_loss: 0.0348 - val_acc: 0.9519\n",
            "Epoch 244/500\n",
            "11983/11983 [==============================] - 1s 75us/sample - loss: 0.0383 - acc: 0.9508 - val_loss: 0.0354 - val_acc: 0.9506\n",
            "Epoch 245/500\n",
            "11983/11983 [==============================] - 1s 75us/sample - loss: 0.0370 - acc: 0.9509 - val_loss: 0.0350 - val_acc: 0.9536\n",
            "Epoch 246/500\n",
            "11983/11983 [==============================] - 1s 74us/sample - loss: 0.0370 - acc: 0.9518 - val_loss: 0.0356 - val_acc: 0.9509\n",
            "Epoch 247/500\n",
            "11983/11983 [==============================] - 1s 75us/sample - loss: 0.0371 - acc: 0.9527 - val_loss: 0.0351 - val_acc: 0.9533\n",
            "Epoch 248/500\n",
            "11983/11983 [==============================] - 1s 73us/sample - loss: 0.0375 - acc: 0.9503 - val_loss: 0.0360 - val_acc: 0.9516\n",
            "Epoch 249/500\n",
            "11983/11983 [==============================] - 1s 77us/sample - loss: 0.0371 - acc: 0.9526 - val_loss: 0.0353 - val_acc: 0.9526\n",
            "Epoch 250/500\n",
            "11983/11983 [==============================] - 1s 75us/sample - loss: 0.0384 - acc: 0.9495 - val_loss: 0.0358 - val_acc: 0.9523\n",
            "Epoch 251/500\n",
            "11983/11983 [==============================] - 1s 74us/sample - loss: 0.0386 - acc: 0.9492 - val_loss: 0.0352 - val_acc: 0.9499\n",
            "Epoch 252/500\n",
            "11983/11983 [==============================] - 1s 75us/sample - loss: 0.0381 - acc: 0.9496 - val_loss: 0.0354 - val_acc: 0.9516\n",
            "Epoch 253/500\n",
            "11983/11983 [==============================] - 1s 74us/sample - loss: 0.0361 - acc: 0.9533 - val_loss: 0.0363 - val_acc: 0.9503\n",
            "Epoch 254/500\n",
            "11983/11983 [==============================] - 1s 75us/sample - loss: 0.0373 - acc: 0.9519 - val_loss: 0.0362 - val_acc: 0.9509\n",
            "Epoch 255/500\n",
            "11983/11983 [==============================] - 1s 76us/sample - loss: 0.0382 - acc: 0.9502 - val_loss: 0.0352 - val_acc: 0.9519\n",
            "Epoch 256/500\n",
            "11983/11983 [==============================] - 1s 76us/sample - loss: 0.0382 - acc: 0.9507 - val_loss: 0.0353 - val_acc: 0.9519\n",
            "Epoch 257/500\n",
            "11983/11983 [==============================] - 1s 74us/sample - loss: 0.0367 - acc: 0.9523 - val_loss: 0.0362 - val_acc: 0.9513\n",
            "Epoch 258/500\n",
            "11983/11983 [==============================] - 1s 78us/sample - loss: 0.0383 - acc: 0.9493 - val_loss: 0.0358 - val_acc: 0.9503\n",
            "Epoch 259/500\n",
            "11983/11983 [==============================] - 1s 74us/sample - loss: 0.0378 - acc: 0.9498 - val_loss: 0.0359 - val_acc: 0.9503\n",
            "Epoch 260/500\n",
            "11983/11983 [==============================] - 1s 74us/sample - loss: 0.0383 - acc: 0.9518 - val_loss: 0.0361 - val_acc: 0.9513\n",
            "Epoch 261/500\n",
            "11983/11983 [==============================] - 1s 74us/sample - loss: 0.0381 - acc: 0.9495 - val_loss: 0.0360 - val_acc: 0.9513\n",
            "Epoch 262/500\n",
            "11983/11983 [==============================] - 1s 75us/sample - loss: 0.0376 - acc: 0.9521 - val_loss: 0.0369 - val_acc: 0.9476\n",
            "Epoch 263/500\n",
            "11983/11983 [==============================] - 1s 76us/sample - loss: 0.0377 - acc: 0.9497 - val_loss: 0.0364 - val_acc: 0.9513\n",
            "Epoch 264/500\n",
            "11983/11983 [==============================] - 1s 75us/sample - loss: 0.0383 - acc: 0.9506 - val_loss: 0.0353 - val_acc: 0.9523\n",
            "Epoch 265/500\n",
            "11983/11983 [==============================] - 1s 74us/sample - loss: 0.0376 - acc: 0.9509 - val_loss: 0.0352 - val_acc: 0.9526\n",
            "Epoch 266/500\n",
            "11983/11983 [==============================] - 1s 74us/sample - loss: 0.0390 - acc: 0.9486 - val_loss: 0.0355 - val_acc: 0.9513\n",
            "Epoch 267/500\n",
            "11983/11983 [==============================] - 1s 77us/sample - loss: 0.0381 - acc: 0.9505 - val_loss: 0.0357 - val_acc: 0.9513\n",
            "Epoch 268/500\n",
            "11983/11983 [==============================] - 1s 76us/sample - loss: 0.0362 - acc: 0.9518 - val_loss: 0.0363 - val_acc: 0.9523\n",
            "Epoch 269/500\n",
            "11983/11983 [==============================] - 1s 77us/sample - loss: 0.0364 - acc: 0.9529 - val_loss: 0.0351 - val_acc: 0.9536\n",
            "Epoch 270/500\n",
            "11983/11983 [==============================] - 1s 76us/sample - loss: 0.0369 - acc: 0.9527 - val_loss: 0.0351 - val_acc: 0.9533\n",
            "Epoch 271/500\n",
            "11983/11983 [==============================] - 1s 76us/sample - loss: 0.0378 - acc: 0.9509 - val_loss: 0.0363 - val_acc: 0.9506\n",
            "Epoch 272/500\n",
            "11983/11983 [==============================] - 1s 76us/sample - loss: 0.0383 - acc: 0.9498 - val_loss: 0.0353 - val_acc: 0.9533\n",
            "Epoch 273/500\n",
            "11983/11983 [==============================] - 1s 77us/sample - loss: 0.0379 - acc: 0.9502 - val_loss: 0.0349 - val_acc: 0.9536\n",
            "Epoch 274/500\n",
            "11983/11983 [==============================] - 1s 75us/sample - loss: 0.0385 - acc: 0.9489 - val_loss: 0.0353 - val_acc: 0.9526\n",
            "Epoch 275/500\n",
            "11983/11983 [==============================] - 1s 77us/sample - loss: 0.0380 - acc: 0.9508 - val_loss: 0.0353 - val_acc: 0.9513\n",
            "Epoch 276/500\n",
            "11983/11983 [==============================] - 1s 76us/sample - loss: 0.0385 - acc: 0.9508 - val_loss: 0.0359 - val_acc: 0.9489\n",
            "Epoch 277/500\n",
            "11983/11983 [==============================] - 1s 72us/sample - loss: 0.0362 - acc: 0.9518 - val_loss: 0.0357 - val_acc: 0.9496\n",
            "Epoch 278/500\n",
            "11983/11983 [==============================] - 1s 74us/sample - loss: 0.0379 - acc: 0.9517 - val_loss: 0.0359 - val_acc: 0.9519\n",
            "Epoch 279/500\n",
            "11983/11983 [==============================] - 1s 75us/sample - loss: 0.0383 - acc: 0.9491 - val_loss: 0.0355 - val_acc: 0.9516\n",
            "Epoch 280/500\n",
            "11983/11983 [==============================] - 1s 75us/sample - loss: 0.0373 - acc: 0.9524 - val_loss: 0.0356 - val_acc: 0.9489\n",
            "Epoch 281/500\n",
            "11983/11983 [==============================] - 1s 73us/sample - loss: 0.0380 - acc: 0.9514 - val_loss: 0.0353 - val_acc: 0.9513\n",
            "Epoch 282/500\n",
            "11983/11983 [==============================] - 1s 75us/sample - loss: 0.0392 - acc: 0.9487 - val_loss: 0.0349 - val_acc: 0.9536\n",
            "Epoch 283/500\n",
            "11983/11983 [==============================] - 1s 76us/sample - loss: 0.0357 - acc: 0.9539 - val_loss: 0.0352 - val_acc: 0.9536\n",
            "Epoch 284/500\n",
            "11983/11983 [==============================] - 1s 77us/sample - loss: 0.0362 - acc: 0.9534 - val_loss: 0.0346 - val_acc: 0.9533\n",
            "Epoch 285/500\n",
            "11983/11983 [==============================] - 1s 75us/sample - loss: 0.0388 - acc: 0.9480 - val_loss: 0.0346 - val_acc: 0.9529\n",
            "Epoch 286/500\n",
            "11983/11983 [==============================] - 1s 77us/sample - loss: 0.0363 - acc: 0.9525 - val_loss: 0.0347 - val_acc: 0.9529\n",
            "Epoch 287/500\n",
            "11983/11983 [==============================] - 1s 75us/sample - loss: 0.0376 - acc: 0.9517 - val_loss: 0.0350 - val_acc: 0.9519\n",
            "Epoch 288/500\n",
            "11983/11983 [==============================] - 1s 81us/sample - loss: 0.0356 - acc: 0.9523 - val_loss: 0.0344 - val_acc: 0.9549\n",
            "Epoch 289/500\n",
            "11983/11983 [==============================] - 1s 74us/sample - loss: 0.0383 - acc: 0.9491 - val_loss: 0.0347 - val_acc: 0.9533\n",
            "Epoch 290/500\n",
            "11983/11983 [==============================] - 1s 75us/sample - loss: 0.0360 - acc: 0.9531 - val_loss: 0.0352 - val_acc: 0.9526\n",
            "Epoch 291/500\n",
            "11983/11983 [==============================] - 1s 77us/sample - loss: 0.0362 - acc: 0.9531 - val_loss: 0.0354 - val_acc: 0.9523\n",
            "Epoch 292/500\n",
            "11983/11983 [==============================] - 1s 77us/sample - loss: 0.0377 - acc: 0.9489 - val_loss: 0.0353 - val_acc: 0.9523\n",
            "Epoch 293/500\n",
            "11983/11983 [==============================] - 1s 76us/sample - loss: 0.0367 - acc: 0.9518 - val_loss: 0.0350 - val_acc: 0.9529\n",
            "Epoch 294/500\n",
            "11983/11983 [==============================] - 1s 76us/sample - loss: 0.0363 - acc: 0.9536 - val_loss: 0.0356 - val_acc: 0.9519\n",
            "Epoch 295/500\n",
            "11983/11983 [==============================] - 1s 75us/sample - loss: 0.0370 - acc: 0.9506 - val_loss: 0.0357 - val_acc: 0.9513\n",
            "Epoch 296/500\n",
            "11983/11983 [==============================] - 1s 76us/sample - loss: 0.0366 - acc: 0.9515 - val_loss: 0.0354 - val_acc: 0.9506\n",
            "Epoch 297/500\n",
            "11983/11983 [==============================] - 1s 74us/sample - loss: 0.0338 - acc: 0.9554 - val_loss: 0.0350 - val_acc: 0.9529\n",
            "Epoch 298/500\n",
            "11983/11983 [==============================] - 1s 75us/sample - loss: 0.0363 - acc: 0.9513 - val_loss: 0.0349 - val_acc: 0.9533\n",
            "Epoch 299/500\n",
            "11983/11983 [==============================] - 1s 76us/sample - loss: 0.0356 - acc: 0.9522 - val_loss: 0.0342 - val_acc: 0.9536\n",
            "Epoch 300/500\n",
            "11983/11983 [==============================] - 1s 74us/sample - loss: 0.0378 - acc: 0.9508 - val_loss: 0.0350 - val_acc: 0.9536\n",
            "Epoch 301/500\n",
            "11983/11983 [==============================] - 1s 77us/sample - loss: 0.0363 - acc: 0.9523 - val_loss: 0.0346 - val_acc: 0.9529\n",
            "Epoch 302/500\n",
            "11983/11983 [==============================] - 1s 73us/sample - loss: 0.0351 - acc: 0.9554 - val_loss: 0.0347 - val_acc: 0.9539\n",
            "Epoch 303/500\n",
            "11983/11983 [==============================] - 1s 74us/sample - loss: 0.0370 - acc: 0.9517 - val_loss: 0.0346 - val_acc: 0.9526\n",
            "Epoch 304/500\n",
            "11983/11983 [==============================] - 1s 76us/sample - loss: 0.0360 - acc: 0.9535 - val_loss: 0.0351 - val_acc: 0.9533\n",
            "Epoch 305/500\n",
            "11983/11983 [==============================] - 1s 75us/sample - loss: 0.0367 - acc: 0.9503 - val_loss: 0.0349 - val_acc: 0.9539\n",
            "Epoch 306/500\n",
            "11983/11983 [==============================] - 1s 74us/sample - loss: 0.0368 - acc: 0.9500 - val_loss: 0.0344 - val_acc: 0.9533\n",
            "Epoch 307/500\n",
            "11983/11983 [==============================] - 1s 76us/sample - loss: 0.0378 - acc: 0.9517 - val_loss: 0.0352 - val_acc: 0.9526\n",
            "Epoch 308/500\n",
            "11983/11983 [==============================] - 1s 75us/sample - loss: 0.0366 - acc: 0.9544 - val_loss: 0.0357 - val_acc: 0.9523\n",
            "Epoch 309/500\n",
            "11983/11983 [==============================] - 1s 77us/sample - loss: 0.0364 - acc: 0.9521 - val_loss: 0.0354 - val_acc: 0.9519\n",
            "Epoch 310/500\n",
            "11983/11983 [==============================] - 1s 72us/sample - loss: 0.0366 - acc: 0.9523 - val_loss: 0.0353 - val_acc: 0.9529\n",
            "Epoch 311/500\n",
            "11983/11983 [==============================] - 1s 77us/sample - loss: 0.0379 - acc: 0.9514 - val_loss: 0.0355 - val_acc: 0.9529\n",
            "Epoch 312/500\n",
            "11983/11983 [==============================] - 1s 74us/sample - loss: 0.0361 - acc: 0.9516 - val_loss: 0.0349 - val_acc: 0.9523\n",
            "Epoch 313/500\n",
            "11983/11983 [==============================] - 1s 75us/sample - loss: 0.0381 - acc: 0.9508 - val_loss: 0.0346 - val_acc: 0.9526\n",
            "Epoch 314/500\n",
            "11983/11983 [==============================] - 1s 77us/sample - loss: 0.0349 - acc: 0.9543 - val_loss: 0.0346 - val_acc: 0.9519\n",
            "Epoch 315/500\n",
            "11983/11983 [==============================] - 1s 74us/sample - loss: 0.0372 - acc: 0.9503 - val_loss: 0.0344 - val_acc: 0.9519\n",
            "Epoch 316/500\n",
            "11983/11983 [==============================] - 1s 74us/sample - loss: 0.0353 - acc: 0.9551 - val_loss: 0.0341 - val_acc: 0.9533\n",
            "Epoch 317/500\n",
            "11983/11983 [==============================] - 1s 73us/sample - loss: 0.0364 - acc: 0.9528 - val_loss: 0.0343 - val_acc: 0.9546\n",
            "Epoch 318/500\n",
            "11983/11983 [==============================] - 1s 73us/sample - loss: 0.0377 - acc: 0.9510 - val_loss: 0.0340 - val_acc: 0.9536\n",
            "Epoch 319/500\n",
            "11983/11983 [==============================] - 1s 75us/sample - loss: 0.0355 - acc: 0.9540 - val_loss: 0.0341 - val_acc: 0.9533\n",
            "Epoch 320/500\n",
            "11983/11983 [==============================] - 1s 74us/sample - loss: 0.0364 - acc: 0.9518 - val_loss: 0.0346 - val_acc: 0.9513\n",
            "Epoch 321/500\n",
            "11983/11983 [==============================] - 1s 76us/sample - loss: 0.0367 - acc: 0.9531 - val_loss: 0.0346 - val_acc: 0.9533\n",
            "Epoch 322/500\n",
            "11983/11983 [==============================] - 1s 75us/sample - loss: 0.0375 - acc: 0.9503 - val_loss: 0.0347 - val_acc: 0.9546\n",
            "Epoch 323/500\n",
            "11983/11983 [==============================] - 1s 75us/sample - loss: 0.0369 - acc: 0.9530 - val_loss: 0.0345 - val_acc: 0.9533\n",
            "Epoch 324/500\n",
            "11983/11983 [==============================] - 1s 74us/sample - loss: 0.0374 - acc: 0.9503 - val_loss: 0.0348 - val_acc: 0.9526\n",
            "Epoch 325/500\n",
            "11983/11983 [==============================] - 1s 75us/sample - loss: 0.0376 - acc: 0.9503 - val_loss: 0.0342 - val_acc: 0.9543\n",
            "Epoch 326/500\n",
            "11983/11983 [==============================] - 1s 74us/sample - loss: 0.0366 - acc: 0.9525 - val_loss: 0.0347 - val_acc: 0.9526\n",
            "Epoch 327/500\n",
            "11983/11983 [==============================] - 1s 78us/sample - loss: 0.0355 - acc: 0.9520 - val_loss: 0.0347 - val_acc: 0.9523\n",
            "Epoch 328/500\n",
            "11983/11983 [==============================] - 1s 77us/sample - loss: 0.0360 - acc: 0.9532 - val_loss: 0.0345 - val_acc: 0.9523\n",
            "Epoch 329/500\n",
            "11983/11983 [==============================] - 1s 74us/sample - loss: 0.0360 - acc: 0.9519 - val_loss: 0.0344 - val_acc: 0.9526\n",
            "Epoch 330/500\n",
            "11983/11983 [==============================] - 1s 104us/sample - loss: 0.0365 - acc: 0.9514 - val_loss: 0.0340 - val_acc: 0.9549\n",
            "Epoch 331/500\n",
            "11983/11983 [==============================] - 2s 138us/sample - loss: 0.0372 - acc: 0.9510 - val_loss: 0.0337 - val_acc: 0.9523\n",
            "Epoch 332/500\n",
            "11983/11983 [==============================] - 1s 99us/sample - loss: 0.0364 - acc: 0.9529 - val_loss: 0.0343 - val_acc: 0.9539\n",
            "Epoch 333/500\n",
            "11983/11983 [==============================] - 1s 79us/sample - loss: 0.0366 - acc: 0.9526 - val_loss: 0.0336 - val_acc: 0.9556\n",
            "Epoch 334/500\n",
            "11983/11983 [==============================] - 1s 80us/sample - loss: 0.0362 - acc: 0.9532 - val_loss: 0.0339 - val_acc: 0.9526\n",
            "Epoch 335/500\n",
            "11983/11983 [==============================] - 1s 74us/sample - loss: 0.0367 - acc: 0.9522 - val_loss: 0.0338 - val_acc: 0.9529\n",
            "Epoch 336/500\n",
            "11983/11983 [==============================] - 1s 76us/sample - loss: 0.0372 - acc: 0.9510 - val_loss: 0.0353 - val_acc: 0.9526\n",
            "Epoch 337/500\n",
            "11983/11983 [==============================] - 1s 73us/sample - loss: 0.0375 - acc: 0.9506 - val_loss: 0.0339 - val_acc: 0.9546\n",
            "Epoch 338/500\n",
            "11983/11983 [==============================] - 1s 74us/sample - loss: 0.0362 - acc: 0.9535 - val_loss: 0.0339 - val_acc: 0.9543\n",
            "Epoch 339/500\n",
            "11983/11983 [==============================] - 1s 74us/sample - loss: 0.0371 - acc: 0.9514 - val_loss: 0.0348 - val_acc: 0.9523\n",
            "Epoch 340/500\n",
            "11983/11983 [==============================] - 1s 76us/sample - loss: 0.0355 - acc: 0.9545 - val_loss: 0.0343 - val_acc: 0.9543\n",
            "Epoch 341/500\n",
            "11983/11983 [==============================] - 1s 74us/sample - loss: 0.0351 - acc: 0.9559 - val_loss: 0.0341 - val_acc: 0.9549\n",
            "Epoch 342/500\n",
            "11983/11983 [==============================] - 1s 74us/sample - loss: 0.0357 - acc: 0.9535 - val_loss: 0.0343 - val_acc: 0.9546\n",
            "Epoch 343/500\n",
            "11983/11983 [==============================] - 1s 74us/sample - loss: 0.0351 - acc: 0.9529 - val_loss: 0.0345 - val_acc: 0.9533\n",
            "Epoch 344/500\n",
            "11983/11983 [==============================] - 1s 75us/sample - loss: 0.0349 - acc: 0.9540 - val_loss: 0.0352 - val_acc: 0.9526\n",
            "Epoch 345/500\n",
            "11983/11983 [==============================] - 1s 74us/sample - loss: 0.0353 - acc: 0.9535 - val_loss: 0.0341 - val_acc: 0.9536\n",
            "Epoch 346/500\n",
            "11983/11983 [==============================] - 1s 101us/sample - loss: 0.0370 - acc: 0.9527 - val_loss: 0.0347 - val_acc: 0.9536\n",
            "Epoch 347/500\n",
            "11983/11983 [==============================] - 1s 123us/sample - loss: 0.0362 - acc: 0.9527 - val_loss: 0.0347 - val_acc: 0.9523\n",
            "Epoch 348/500\n",
            "11983/11983 [==============================] - 2s 134us/sample - loss: 0.0376 - acc: 0.9502 - val_loss: 0.0350 - val_acc: 0.9526\n",
            "Epoch 349/500\n",
            "11983/11983 [==============================] - 1s 119us/sample - loss: 0.0370 - acc: 0.9522 - val_loss: 0.0347 - val_acc: 0.9539\n",
            "Epoch 350/500\n",
            "11983/11983 [==============================] - 1s 122us/sample - loss: 0.0359 - acc: 0.9544 - val_loss: 0.0337 - val_acc: 0.9549\n",
            "Epoch 351/500\n",
            "11983/11983 [==============================] - 1s 122us/sample - loss: 0.0364 - acc: 0.9523 - val_loss: 0.0345 - val_acc: 0.9519\n",
            "Epoch 352/500\n",
            "11983/11983 [==============================] - 2s 136us/sample - loss: 0.0345 - acc: 0.9557 - val_loss: 0.0332 - val_acc: 0.9566\n",
            "Epoch 353/500\n",
            "11983/11983 [==============================] - 1s 86us/sample - loss: 0.0355 - acc: 0.9554 - val_loss: 0.0343 - val_acc: 0.9509\n",
            "Epoch 354/500\n",
            "11983/11983 [==============================] - 1s 77us/sample - loss: 0.0360 - acc: 0.9523 - val_loss: 0.0336 - val_acc: 0.9546\n",
            "Epoch 355/500\n",
            "11983/11983 [==============================] - 1s 75us/sample - loss: 0.0376 - acc: 0.9498 - val_loss: 0.0335 - val_acc: 0.9543\n",
            "Epoch 356/500\n",
            "11983/11983 [==============================] - 1s 77us/sample - loss: 0.0365 - acc: 0.9516 - val_loss: 0.0338 - val_acc: 0.9536\n",
            "Epoch 357/500\n",
            "11983/11983 [==============================] - 1s 74us/sample - loss: 0.0354 - acc: 0.9541 - val_loss: 0.0338 - val_acc: 0.9536\n",
            "Epoch 358/500\n",
            "11983/11983 [==============================] - 1s 73us/sample - loss: 0.0367 - acc: 0.9534 - val_loss: 0.0342 - val_acc: 0.9526\n",
            "Epoch 359/500\n",
            "11983/11983 [==============================] - 1s 74us/sample - loss: 0.0365 - acc: 0.9508 - val_loss: 0.0333 - val_acc: 0.9556\n",
            "Epoch 360/500\n",
            "11983/11983 [==============================] - 1s 74us/sample - loss: 0.0363 - acc: 0.9534 - val_loss: 0.0337 - val_acc: 0.9539\n",
            "Epoch 361/500\n",
            "11983/11983 [==============================] - 1s 75us/sample - loss: 0.0338 - acc: 0.9558 - val_loss: 0.0334 - val_acc: 0.9539\n",
            "Epoch 362/500\n",
            "11983/11983 [==============================] - 1s 76us/sample - loss: 0.0358 - acc: 0.9533 - val_loss: 0.0339 - val_acc: 0.9529\n",
            "Epoch 363/500\n",
            "11983/11983 [==============================] - 1s 75us/sample - loss: 0.0362 - acc: 0.9513 - val_loss: 0.0338 - val_acc: 0.9526\n",
            "Epoch 364/500\n",
            "11983/11983 [==============================] - 1s 75us/sample - loss: 0.0356 - acc: 0.9537 - val_loss: 0.0348 - val_acc: 0.9533\n",
            "Epoch 365/500\n",
            "11983/11983 [==============================] - 1s 75us/sample - loss: 0.0347 - acc: 0.9544 - val_loss: 0.0339 - val_acc: 0.9556\n",
            "Epoch 366/500\n",
            "11983/11983 [==============================] - 1s 76us/sample - loss: 0.0366 - acc: 0.9526 - val_loss: 0.0348 - val_acc: 0.9516\n",
            "Epoch 367/500\n",
            "11983/11983 [==============================] - 1s 106us/sample - loss: 0.0366 - acc: 0.9528 - val_loss: 0.0339 - val_acc: 0.9549\n",
            "Epoch 368/500\n",
            "11983/11983 [==============================] - 2s 132us/sample - loss: 0.0349 - acc: 0.9561 - val_loss: 0.0347 - val_acc: 0.9523\n",
            "Epoch 369/500\n",
            "11983/11983 [==============================] - 1s 123us/sample - loss: 0.0371 - acc: 0.9505 - val_loss: 0.0342 - val_acc: 0.9556\n",
            "Epoch 370/500\n",
            "11983/11983 [==============================] - 1s 74us/sample - loss: 0.0358 - acc: 0.9554 - val_loss: 0.0345 - val_acc: 0.9543\n",
            "Epoch 371/500\n",
            "11983/11983 [==============================] - 1s 75us/sample - loss: 0.0346 - acc: 0.9554 - val_loss: 0.0338 - val_acc: 0.9549\n",
            "Epoch 372/500\n",
            "11983/11983 [==============================] - 1s 76us/sample - loss: 0.0374 - acc: 0.9488 - val_loss: 0.0342 - val_acc: 0.9526\n",
            "Epoch 373/500\n",
            "11983/11983 [==============================] - 1s 77us/sample - loss: 0.0354 - acc: 0.9535 - val_loss: 0.0344 - val_acc: 0.9529\n",
            "Epoch 374/500\n",
            "11983/11983 [==============================] - 1s 76us/sample - loss: 0.0362 - acc: 0.9514 - val_loss: 0.0336 - val_acc: 0.9536\n",
            "Epoch 375/500\n",
            "11983/11983 [==============================] - 1s 76us/sample - loss: 0.0365 - acc: 0.9528 - val_loss: 0.0335 - val_acc: 0.9556\n",
            "Epoch 376/500\n",
            "11983/11983 [==============================] - 1s 73us/sample - loss: 0.0355 - acc: 0.9537 - val_loss: 0.0336 - val_acc: 0.9553\n",
            "Epoch 377/500\n",
            "11983/11983 [==============================] - 1s 73us/sample - loss: 0.0351 - acc: 0.9544 - val_loss: 0.0339 - val_acc: 0.9559\n",
            "Epoch 378/500\n",
            "11983/11983 [==============================] - 1s 75us/sample - loss: 0.0336 - acc: 0.9560 - val_loss: 0.0339 - val_acc: 0.9533\n",
            "Epoch 379/500\n",
            "11983/11983 [==============================] - 1s 76us/sample - loss: 0.0350 - acc: 0.9555 - val_loss: 0.0340 - val_acc: 0.9536\n",
            "Epoch 380/500\n",
            "11983/11983 [==============================] - 1s 75us/sample - loss: 0.0354 - acc: 0.9554 - val_loss: 0.0337 - val_acc: 0.9549\n",
            "Epoch 381/500\n",
            "11983/11983 [==============================] - 1s 76us/sample - loss: 0.0342 - acc: 0.9574 - val_loss: 0.0343 - val_acc: 0.9543\n",
            "Epoch 382/500\n",
            "11983/11983 [==============================] - 1s 78us/sample - loss: 0.0367 - acc: 0.9522 - val_loss: 0.0334 - val_acc: 0.9569\n",
            "Epoch 383/500\n",
            "11983/11983 [==============================] - 1s 79us/sample - loss: 0.0362 - acc: 0.9523 - val_loss: 0.0339 - val_acc: 0.9543\n",
            "Epoch 384/500\n",
            "11983/11983 [==============================] - 1s 75us/sample - loss: 0.0349 - acc: 0.9563 - val_loss: 0.0342 - val_acc: 0.9559\n",
            "Epoch 385/500\n",
            "11983/11983 [==============================] - 1s 75us/sample - loss: 0.0356 - acc: 0.9550 - val_loss: 0.0343 - val_acc: 0.9519\n",
            "Epoch 386/500\n",
            "11983/11983 [==============================] - 1s 73us/sample - loss: 0.0353 - acc: 0.9543 - val_loss: 0.0343 - val_acc: 0.9529\n",
            "Epoch 387/500\n",
            "11983/11983 [==============================] - 1s 77us/sample - loss: 0.0354 - acc: 0.9538 - val_loss: 0.0342 - val_acc: 0.9566\n",
            "Epoch 388/500\n",
            "11983/11983 [==============================] - 1s 74us/sample - loss: 0.0332 - acc: 0.9581 - val_loss: 0.0333 - val_acc: 0.9553\n",
            "Epoch 389/500\n",
            "11983/11983 [==============================] - 1s 76us/sample - loss: 0.0362 - acc: 0.9516 - val_loss: 0.0338 - val_acc: 0.9549\n",
            "Epoch 390/500\n",
            "11983/11983 [==============================] - 1s 76us/sample - loss: 0.0349 - acc: 0.9543 - val_loss: 0.0337 - val_acc: 0.9563\n",
            "Epoch 391/500\n",
            "11983/11983 [==============================] - 1s 84us/sample - loss: 0.0341 - acc: 0.9559 - val_loss: 0.0334 - val_acc: 0.9553\n",
            "Epoch 392/500\n",
            "11983/11983 [==============================] - 1s 93us/sample - loss: 0.0345 - acc: 0.9544 - val_loss: 0.0328 - val_acc: 0.9559\n",
            "Epoch 393/500\n",
            "11983/11983 [==============================] - 1s 80us/sample - loss: 0.0357 - acc: 0.9536 - val_loss: 0.0336 - val_acc: 0.9563\n",
            "Epoch 394/500\n",
            "11983/11983 [==============================] - 1s 78us/sample - loss: 0.0345 - acc: 0.9549 - val_loss: 0.0337 - val_acc: 0.9543\n",
            "Epoch 395/500\n",
            "11983/11983 [==============================] - 1s 77us/sample - loss: 0.0343 - acc: 0.9567 - val_loss: 0.0340 - val_acc: 0.9536\n",
            "Epoch 396/500\n",
            "11983/11983 [==============================] - 1s 73us/sample - loss: 0.0360 - acc: 0.9542 - val_loss: 0.0330 - val_acc: 0.9536\n",
            "Epoch 397/500\n",
            "11983/11983 [==============================] - 1s 75us/sample - loss: 0.0354 - acc: 0.9539 - val_loss: 0.0328 - val_acc: 0.9546\n",
            "Epoch 398/500\n",
            "11983/11983 [==============================] - 1s 76us/sample - loss: 0.0355 - acc: 0.9546 - val_loss: 0.0328 - val_acc: 0.9566\n",
            "Epoch 399/500\n",
            "11983/11983 [==============================] - 1s 75us/sample - loss: 0.0343 - acc: 0.9563 - val_loss: 0.0330 - val_acc: 0.9566\n",
            "Epoch 400/500\n",
            "11983/11983 [==============================] - 1s 74us/sample - loss: 0.0355 - acc: 0.9540 - val_loss: 0.0336 - val_acc: 0.9543\n",
            "Epoch 401/500\n",
            "11983/11983 [==============================] - 1s 75us/sample - loss: 0.0354 - acc: 0.9546 - val_loss: 0.0336 - val_acc: 0.9556\n",
            "Epoch 402/500\n",
            "11983/11983 [==============================] - 1s 73us/sample - loss: 0.0342 - acc: 0.9539 - val_loss: 0.0343 - val_acc: 0.9523\n",
            "Epoch 403/500\n",
            "11983/11983 [==============================] - 1s 73us/sample - loss: 0.0355 - acc: 0.9544 - val_loss: 0.0336 - val_acc: 0.9526\n",
            "Epoch 404/500\n",
            "11983/11983 [==============================] - 1s 77us/sample - loss: 0.0356 - acc: 0.9530 - val_loss: 0.0338 - val_acc: 0.9553\n",
            "Epoch 405/500\n",
            "11983/11983 [==============================] - 1s 76us/sample - loss: 0.0346 - acc: 0.9556 - val_loss: 0.0328 - val_acc: 0.9569\n",
            "Epoch 406/500\n",
            "11983/11983 [==============================] - 1s 74us/sample - loss: 0.0351 - acc: 0.9541 - val_loss: 0.0331 - val_acc: 0.9563\n",
            "Epoch 407/500\n",
            "11983/11983 [==============================] - 1s 75us/sample - loss: 0.0347 - acc: 0.9566 - val_loss: 0.0334 - val_acc: 0.9539\n",
            "Epoch 408/500\n",
            "11983/11983 [==============================] - 1s 76us/sample - loss: 0.0360 - acc: 0.9543 - val_loss: 0.0339 - val_acc: 0.9559\n",
            "Epoch 409/500\n",
            "11983/11983 [==============================] - 1s 78us/sample - loss: 0.0351 - acc: 0.9538 - val_loss: 0.0340 - val_acc: 0.9546\n",
            "Epoch 410/500\n",
            "11983/11983 [==============================] - 1s 77us/sample - loss: 0.0352 - acc: 0.9530 - val_loss: 0.0333 - val_acc: 0.9543\n",
            "Epoch 411/500\n",
            "11983/11983 [==============================] - 1s 74us/sample - loss: 0.0348 - acc: 0.9550 - val_loss: 0.0335 - val_acc: 0.9546\n",
            "Epoch 412/500\n",
            "11983/11983 [==============================] - 1s 74us/sample - loss: 0.0346 - acc: 0.9559 - val_loss: 0.0339 - val_acc: 0.9539\n",
            "Epoch 413/500\n",
            "11983/11983 [==============================] - 1s 75us/sample - loss: 0.0349 - acc: 0.9559 - val_loss: 0.0343 - val_acc: 0.9543\n",
            "Epoch 414/500\n",
            "11983/11983 [==============================] - 1s 75us/sample - loss: 0.0358 - acc: 0.9535 - val_loss: 0.0337 - val_acc: 0.9533\n",
            "Epoch 415/500\n",
            "11983/11983 [==============================] - 1s 72us/sample - loss: 0.0355 - acc: 0.9545 - val_loss: 0.0329 - val_acc: 0.9549\n",
            "Epoch 416/500\n",
            "11983/11983 [==============================] - 1s 73us/sample - loss: 0.0346 - acc: 0.9549 - val_loss: 0.0325 - val_acc: 0.9536\n",
            "Epoch 417/500\n",
            "11983/11983 [==============================] - 1s 74us/sample - loss: 0.0353 - acc: 0.9550 - val_loss: 0.0325 - val_acc: 0.9546\n",
            "Epoch 418/500\n",
            "11983/11983 [==============================] - 1s 73us/sample - loss: 0.0352 - acc: 0.9547 - val_loss: 0.0333 - val_acc: 0.9543\n",
            "Epoch 419/500\n",
            "11983/11983 [==============================] - 1s 74us/sample - loss: 0.0351 - acc: 0.9539 - val_loss: 0.0339 - val_acc: 0.9546\n",
            "Epoch 420/500\n",
            "11983/11983 [==============================] - 1s 73us/sample - loss: 0.0339 - acc: 0.9553 - val_loss: 0.0324 - val_acc: 0.9556\n",
            "Epoch 421/500\n",
            "11983/11983 [==============================] - 1s 75us/sample - loss: 0.0343 - acc: 0.9554 - val_loss: 0.0331 - val_acc: 0.9553\n",
            "Epoch 422/500\n",
            "11983/11983 [==============================] - 1s 74us/sample - loss: 0.0356 - acc: 0.9534 - val_loss: 0.0333 - val_acc: 0.9546\n",
            "Epoch 423/500\n",
            "11983/11983 [==============================] - 1s 76us/sample - loss: 0.0348 - acc: 0.9549 - val_loss: 0.0329 - val_acc: 0.9566\n",
            "Epoch 424/500\n",
            "11983/11983 [==============================] - 1s 76us/sample - loss: 0.0351 - acc: 0.9537 - val_loss: 0.0330 - val_acc: 0.9559\n",
            "Epoch 425/500\n",
            "11983/11983 [==============================] - 1s 73us/sample - loss: 0.0350 - acc: 0.9548 - val_loss: 0.0327 - val_acc: 0.9573\n",
            "Epoch 426/500\n",
            "11983/11983 [==============================] - 1s 75us/sample - loss: 0.0372 - acc: 0.9530 - val_loss: 0.0324 - val_acc: 0.9566\n",
            "Epoch 427/500\n",
            "11983/11983 [==============================] - 1s 76us/sample - loss: 0.0339 - acc: 0.9564 - val_loss: 0.0321 - val_acc: 0.9563\n",
            "Epoch 428/500\n",
            "11983/11983 [==============================] - 1s 73us/sample - loss: 0.0338 - acc: 0.9554 - val_loss: 0.0331 - val_acc: 0.9546\n",
            "Epoch 429/500\n",
            "11983/11983 [==============================] - 1s 75us/sample - loss: 0.0359 - acc: 0.9542 - val_loss: 0.0334 - val_acc: 0.9549\n",
            "Epoch 430/500\n",
            "11983/11983 [==============================] - 1s 74us/sample - loss: 0.0332 - acc: 0.9580 - val_loss: 0.0331 - val_acc: 0.9553\n",
            "Epoch 431/500\n",
            "11983/11983 [==============================] - 1s 73us/sample - loss: 0.0347 - acc: 0.9540 - val_loss: 0.0329 - val_acc: 0.9576\n",
            "Epoch 432/500\n",
            "11983/11983 [==============================] - 1s 74us/sample - loss: 0.0361 - acc: 0.9529 - val_loss: 0.0329 - val_acc: 0.9566\n",
            "Epoch 433/500\n",
            "11983/11983 [==============================] - 1s 76us/sample - loss: 0.0347 - acc: 0.9554 - val_loss: 0.0338 - val_acc: 0.9553\n",
            "Epoch 434/500\n",
            "11983/11983 [==============================] - 1s 76us/sample - loss: 0.0355 - acc: 0.9544 - val_loss: 0.0336 - val_acc: 0.9549\n",
            "Epoch 435/500\n",
            "11983/11983 [==============================] - 1s 73us/sample - loss: 0.0348 - acc: 0.9556 - val_loss: 0.0332 - val_acc: 0.9549\n",
            "Epoch 436/500\n",
            "11983/11983 [==============================] - 1s 75us/sample - loss: 0.0346 - acc: 0.9545 - val_loss: 0.0328 - val_acc: 0.9549\n",
            "Epoch 437/500\n",
            "11983/11983 [==============================] - 1s 74us/sample - loss: 0.0357 - acc: 0.9533 - val_loss: 0.0339 - val_acc: 0.9556\n",
            "Epoch 438/500\n",
            "11983/11983 [==============================] - 1s 77us/sample - loss: 0.0337 - acc: 0.9573 - val_loss: 0.0340 - val_acc: 0.9553\n",
            "Epoch 439/500\n",
            "11983/11983 [==============================] - 1s 74us/sample - loss: 0.0338 - acc: 0.9561 - val_loss: 0.0330 - val_acc: 0.9559\n",
            "Epoch 440/500\n",
            "11983/11983 [==============================] - 1s 79us/sample - loss: 0.0350 - acc: 0.9552 - val_loss: 0.0325 - val_acc: 0.9553\n",
            "Epoch 441/500\n",
            "11983/11983 [==============================] - 1s 75us/sample - loss: 0.0349 - acc: 0.9562 - val_loss: 0.0329 - val_acc: 0.9546\n",
            "Epoch 442/500\n",
            "11983/11983 [==============================] - 1s 74us/sample - loss: 0.0338 - acc: 0.9549 - val_loss: 0.0335 - val_acc: 0.9546\n",
            "Epoch 443/500\n",
            "11983/11983 [==============================] - 1s 75us/sample - loss: 0.0337 - acc: 0.9560 - val_loss: 0.0338 - val_acc: 0.9563\n",
            "Epoch 444/500\n",
            "11983/11983 [==============================] - 1s 72us/sample - loss: 0.0355 - acc: 0.9544 - val_loss: 0.0336 - val_acc: 0.9546\n",
            "Epoch 445/500\n",
            "11983/11983 [==============================] - 1s 74us/sample - loss: 0.0357 - acc: 0.9542 - val_loss: 0.0335 - val_acc: 0.9546\n",
            "Epoch 446/500\n",
            "11983/11983 [==============================] - 1s 73us/sample - loss: 0.0357 - acc: 0.9538 - val_loss: 0.0341 - val_acc: 0.9529\n",
            "Epoch 447/500\n",
            "11983/11983 [==============================] - 1s 74us/sample - loss: 0.0332 - acc: 0.9579 - val_loss: 0.0327 - val_acc: 0.9563\n",
            "Epoch 448/500\n",
            "11983/11983 [==============================] - 1s 73us/sample - loss: 0.0348 - acc: 0.9546 - val_loss: 0.0323 - val_acc: 0.9553\n",
            "Epoch 449/500\n",
            "11983/11983 [==============================] - 1s 74us/sample - loss: 0.0335 - acc: 0.9566 - val_loss: 0.0330 - val_acc: 0.9576\n",
            "Epoch 450/500\n",
            "11983/11983 [==============================] - 1s 72us/sample - loss: 0.0343 - acc: 0.9565 - val_loss: 0.0329 - val_acc: 0.9549\n",
            "Epoch 451/500\n",
            "11983/11983 [==============================] - 1s 73us/sample - loss: 0.0346 - acc: 0.9562 - val_loss: 0.0319 - val_acc: 0.9569\n",
            "Epoch 452/500\n",
            "11983/11983 [==============================] - 1s 76us/sample - loss: 0.0332 - acc: 0.9579 - val_loss: 0.0326 - val_acc: 0.9563\n",
            "Epoch 453/500\n",
            "11983/11983 [==============================] - 1s 77us/sample - loss: 0.0353 - acc: 0.9553 - val_loss: 0.0326 - val_acc: 0.9566\n",
            "Epoch 454/500\n",
            "11983/11983 [==============================] - 1s 73us/sample - loss: 0.0336 - acc: 0.9566 - val_loss: 0.0331 - val_acc: 0.9553\n",
            "Epoch 455/500\n",
            "11983/11983 [==============================] - 1s 74us/sample - loss: 0.0339 - acc: 0.9563 - val_loss: 0.0322 - val_acc: 0.9579\n",
            "Epoch 456/500\n",
            "11983/11983 [==============================] - 1s 75us/sample - loss: 0.0363 - acc: 0.9523 - val_loss: 0.0329 - val_acc: 0.9559\n",
            "Epoch 457/500\n",
            "11983/11983 [==============================] - 1s 97us/sample - loss: 0.0354 - acc: 0.9525 - val_loss: 0.0327 - val_acc: 0.9539\n",
            "Epoch 458/500\n",
            "11983/11983 [==============================] - 1s 74us/sample - loss: 0.0337 - acc: 0.9569 - val_loss: 0.0320 - val_acc: 0.9573\n",
            "Epoch 459/500\n",
            "11983/11983 [==============================] - 1s 75us/sample - loss: 0.0351 - acc: 0.9550 - val_loss: 0.0330 - val_acc: 0.9573\n",
            "Epoch 460/500\n",
            "11983/11983 [==============================] - 1s 80us/sample - loss: 0.0347 - acc: 0.9544 - val_loss: 0.0321 - val_acc: 0.9546\n",
            "Epoch 461/500\n",
            "11983/11983 [==============================] - 1s 77us/sample - loss: 0.0354 - acc: 0.9546 - val_loss: 0.0330 - val_acc: 0.9579\n",
            "Epoch 462/500\n",
            "11983/11983 [==============================] - 1s 77us/sample - loss: 0.0332 - acc: 0.9564 - val_loss: 0.0324 - val_acc: 0.9543\n",
            "Epoch 463/500\n",
            "11983/11983 [==============================] - 1s 75us/sample - loss: 0.0353 - acc: 0.9542 - val_loss: 0.0328 - val_acc: 0.9556\n",
            "Epoch 464/500\n",
            "11983/11983 [==============================] - 1s 75us/sample - loss: 0.0345 - acc: 0.9559 - val_loss: 0.0332 - val_acc: 0.9559\n",
            "Epoch 465/500\n",
            "11983/11983 [==============================] - 1s 76us/sample - loss: 0.0343 - acc: 0.9566 - val_loss: 0.0332 - val_acc: 0.9559\n",
            "Epoch 466/500\n",
            "11983/11983 [==============================] - 1s 75us/sample - loss: 0.0340 - acc: 0.9567 - val_loss: 0.0333 - val_acc: 0.9539\n",
            "Epoch 467/500\n",
            "11983/11983 [==============================] - 1s 75us/sample - loss: 0.0324 - acc: 0.9577 - val_loss: 0.0321 - val_acc: 0.9559\n",
            "Epoch 468/500\n",
            "11983/11983 [==============================] - 1s 80us/sample - loss: 0.0341 - acc: 0.9569 - val_loss: 0.0329 - val_acc: 0.9543\n",
            "Epoch 469/500\n",
            "11983/11983 [==============================] - 1s 75us/sample - loss: 0.0345 - acc: 0.9560 - val_loss: 0.0324 - val_acc: 0.9559\n",
            "Epoch 470/500\n",
            "11983/11983 [==============================] - 1s 75us/sample - loss: 0.0331 - acc: 0.9576 - val_loss: 0.0327 - val_acc: 0.9576\n",
            "Epoch 471/500\n",
            "11983/11983 [==============================] - 1s 72us/sample - loss: 0.0346 - acc: 0.9559 - val_loss: 0.0337 - val_acc: 0.9539\n",
            "Epoch 472/500\n",
            "11983/11983 [==============================] - 1s 75us/sample - loss: 0.0321 - acc: 0.9588 - val_loss: 0.0332 - val_acc: 0.9566\n",
            "Epoch 473/500\n",
            "11983/11983 [==============================] - 1s 74us/sample - loss: 0.0349 - acc: 0.9543 - val_loss: 0.0327 - val_acc: 0.9566\n",
            "Epoch 474/500\n",
            "11983/11983 [==============================] - 1s 75us/sample - loss: 0.0341 - acc: 0.9564 - val_loss: 0.0329 - val_acc: 0.9556\n",
            "Epoch 475/500\n",
            "11983/11983 [==============================] - 1s 76us/sample - loss: 0.0344 - acc: 0.9559 - val_loss: 0.0326 - val_acc: 0.9556\n",
            "Epoch 476/500\n",
            "11983/11983 [==============================] - 1s 76us/sample - loss: 0.0328 - acc: 0.9572 - val_loss: 0.0320 - val_acc: 0.9559\n",
            "Epoch 477/500\n",
            "11983/11983 [==============================] - 1s 77us/sample - loss: 0.0333 - acc: 0.9568 - val_loss: 0.0330 - val_acc: 0.9569\n",
            "Epoch 478/500\n",
            "11983/11983 [==============================] - 1s 74us/sample - loss: 0.0355 - acc: 0.9544 - val_loss: 0.0336 - val_acc: 0.9523\n",
            "Epoch 479/500\n",
            "11983/11983 [==============================] - 1s 78us/sample - loss: 0.0337 - acc: 0.9552 - val_loss: 0.0340 - val_acc: 0.9546\n",
            "Epoch 480/500\n",
            "11983/11983 [==============================] - 1s 76us/sample - loss: 0.0328 - acc: 0.9589 - val_loss: 0.0323 - val_acc: 0.9566\n",
            "Epoch 481/500\n",
            "11983/11983 [==============================] - 1s 74us/sample - loss: 0.0343 - acc: 0.9552 - val_loss: 0.0325 - val_acc: 0.9569\n",
            "Epoch 482/500\n",
            "11983/11983 [==============================] - 1s 74us/sample - loss: 0.0362 - acc: 0.9543 - val_loss: 0.0329 - val_acc: 0.9543\n",
            "Epoch 483/500\n",
            "11983/11983 [==============================] - 1s 76us/sample - loss: 0.0344 - acc: 0.9556 - val_loss: 0.0329 - val_acc: 0.9549\n",
            "Epoch 484/500\n",
            "11983/11983 [==============================] - 1s 77us/sample - loss: 0.0340 - acc: 0.9559 - val_loss: 0.0321 - val_acc: 0.9559\n",
            "Epoch 485/500\n",
            "11983/11983 [==============================] - 1s 75us/sample - loss: 0.0338 - acc: 0.9548 - val_loss: 0.0328 - val_acc: 0.9556\n",
            "Epoch 486/500\n",
            "11983/11983 [==============================] - 1s 75us/sample - loss: 0.0334 - acc: 0.9558 - val_loss: 0.0326 - val_acc: 0.9563\n",
            "Epoch 487/500\n",
            "11983/11983 [==============================] - 1s 76us/sample - loss: 0.0342 - acc: 0.9546 - val_loss: 0.0336 - val_acc: 0.9556\n",
            "Epoch 488/500\n",
            "11983/11983 [==============================] - 1s 76us/sample - loss: 0.0337 - acc: 0.9563 - val_loss: 0.0332 - val_acc: 0.9559\n",
            "Epoch 489/500\n",
            "11983/11983 [==============================] - 1s 78us/sample - loss: 0.0353 - acc: 0.9536 - val_loss: 0.0328 - val_acc: 0.9566\n",
            "Epoch 490/500\n",
            "11983/11983 [==============================] - 1s 79us/sample - loss: 0.0342 - acc: 0.9550 - val_loss: 0.0323 - val_acc: 0.9576\n",
            "Epoch 491/500\n",
            "11983/11983 [==============================] - 1s 81us/sample - loss: 0.0344 - acc: 0.9558 - val_loss: 0.0333 - val_acc: 0.9533\n",
            "Epoch 492/500\n",
            "11983/11983 [==============================] - 1s 79us/sample - loss: 0.0343 - acc: 0.9554 - val_loss: 0.0325 - val_acc: 0.9586\n",
            "Epoch 493/500\n",
            "11983/11983 [==============================] - 1s 80us/sample - loss: 0.0335 - acc: 0.9540 - val_loss: 0.0329 - val_acc: 0.9573\n",
            "Epoch 494/500\n",
            "11983/11983 [==============================] - 1s 79us/sample - loss: 0.0322 - acc: 0.9585 - val_loss: 0.0330 - val_acc: 0.9556\n",
            "Epoch 495/500\n",
            "11983/11983 [==============================] - 1s 79us/sample - loss: 0.0351 - acc: 0.9548 - val_loss: 0.0331 - val_acc: 0.9569\n",
            "Epoch 496/500\n",
            "11983/11983 [==============================] - 1s 79us/sample - loss: 0.0338 - acc: 0.9563 - val_loss: 0.0328 - val_acc: 0.9586\n",
            "Epoch 497/500\n",
            "11983/11983 [==============================] - 1s 79us/sample - loss: 0.0337 - acc: 0.9565 - val_loss: 0.0331 - val_acc: 0.9556\n",
            "Epoch 498/500\n",
            "11983/11983 [==============================] - 1s 79us/sample - loss: 0.0336 - acc: 0.9561 - val_loss: 0.0325 - val_acc: 0.9566\n",
            "Epoch 499/500\n",
            "11983/11983 [==============================] - 1s 80us/sample - loss: 0.0339 - acc: 0.9550 - val_loss: 0.0323 - val_acc: 0.9576\n",
            "Epoch 500/500\n",
            "11983/11983 [==============================] - 1s 77us/sample - loss: 0.0333 - acc: 0.9562 - val_loss: 0.0325 - val_acc: 0.9586\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBeKDuPHzmsf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "train_loss_list.append(loss[-1])\n",
        "val_loss_list.append(val_loss[-1])\n",
        "\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "epoch = range(1,len(loss)+1)\n",
        "\n",
        "train_accuracy_list.append(acc[-1])\n",
        "val_accuracy_list.append(val_acc[-1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GD2OrFha0c-N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "c3516bc3-c934-42f3-e46a-893028cb044e"
      },
      "source": [
        "#print(\"Number of run \" + str(run))\n",
        "print(\"Train loss \" + loss[-1].astype(str))\n",
        "print(\"Validation loss \" + val_loss[-1].astype(str))\n",
        "print(\"Train accuracy \" + acc[-1].astype(str))\n",
        "print(\"Validation accuracy \" + val_acc[-1].astype(str))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train loss 0.03330417853686593\n",
            "Validation loss 0.03249877279945146\n",
            "Train accuracy 0.9561879\n",
            "Validation accuracy 0.9586115\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NstWgRess_rX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train'], loc='upper left')\n",
        "\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spY91H0Ss_oh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4a33c8bf-0ef7-4cf1-df59-09d83731eb65"
      },
      "source": [
        "a=2\n",
        "a"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jp_tEEVs_g6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GsIdHzwm0dBU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_val = [x for x in range(1, 51)]\n",
        "plt.figure()\n",
        "plt.plot(x_val, acc,'bo', label= 'Training accuracy')\n",
        "plt.plot(x_val, val_acc,'b', label= 'Validation accuracy')\n",
        "plt.title('Training and Validation accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(x_val, loss,'bo', label= 'Training loss')\n",
        "plt.plot(x_val, val_loss,'b', label= 'Validation loss')\n",
        "plt.title('Training and Validation loss')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHxT_Rm-0i_S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "0c46049e-5d21-4075-c2fe-19e09c0f8bcd"
      },
      "source": [
        "plt.figure()\n",
        "plt.plot(x_values,train_accuracy_list,'bo',label= 'Training accuracy per run')\n",
        "plt.plot(x_values,val_accuracy_list,'b',label= 'Validation accuracy per run')\n",
        "plt.title('Training and Validation accuracy per run')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(x_values,train_loss_list,'bo',label= 'Training loss per run')\n",
        "plt.plot(x_values,val_loss_list,'b',label= 'Validation loss per run')\n",
        "plt.title('Training and Validation loss per run')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "average_train_loss = sum(train_loss_list, 0.0)/len(train_loss_list)\n",
        "average_train_accuracy = sum(train_accuracy_list, 0.0)/len(train_accuracy_list)\n",
        "print(\"Average train loss \" + average_train_loss.astype(str))\n",
        "print(\"Average train accuracy \" + average_train_accuracy.astype(str))\n",
        "\n",
        "average_val_loss = sum(val_loss_list, 0.0)/len(val_loss_list)\n",
        "average_val_accuracy = sum(val_accuracy_list, 0.0)/len(val_accuracy_list)\n",
        "print(\"Average val loss \" + average_val_loss.astype(str))\n",
        "print(\"Average val accuracy \" + average_val_accuracy.astype(str))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-2e80feb2b11f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_accuracy_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'bo'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m'Training accuracy per run'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_accuracy_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'b'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m'Validation accuracy per run'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training and Validation accuracy per run'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2809\u001b[0m     return gca().plot(\n\u001b[1;32m   2810\u001b[0m         *args, scalex=scalex, scaley=scaley, **({\"data\": data} if data\n\u001b[0;32m-> 2811\u001b[0;31m         is not None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2813\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1808\u001b[0m                         \u001b[0;34m\"the Matplotlib list!)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1810\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1812\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_alias_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1611\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1612\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m             \u001b[0mlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_grab_next_args\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    391\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    368\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_of\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_xy_from_xy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'plot'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_xy_from_xy\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m             raise ValueError(\"x and y must have same first dimension, but \"\n\u001b[0;32m--> 231\u001b[0;31m                              \"have shapes {} and {}\".format(x.shape, y.shape))\n\u001b[0m\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             raise ValueError(\"x and y can be no greater than 2-D, but have \"\n",
            "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (10,) and (1,)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4D_ZZl9e0jCk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2128f823-1e21-4e46-e4a6-123cc07e1100"
      },
      "source": [
        "a=2\n",
        "a"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkORNYSOXimC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}